{
  "version": 3,
  "sources": ["../node_modules/simple-statistics/src/linear_regression.js", "../node_modules/simple-statistics/src/linear_regression_line.js", "../node_modules/simple-statistics/src/sum.js", "../node_modules/simple-statistics/src/mean.js", "../node_modules/simple-statistics/src/sum_nth_power_deviations.js", "../node_modules/simple-statistics/src/variance.js", "../node_modules/simple-statistics/src/standard_deviation.js", "../node_modules/simple-statistics/src/r_squared.js", "../node_modules/simple-statistics/src/mode_sorted.js", "../node_modules/simple-statistics/src/numeric_sort.js", "../node_modules/simple-statistics/src/mode.js", "../node_modules/simple-statistics/src/mode_fast.js", "../node_modules/simple-statistics/src/min.js", "../node_modules/simple-statistics/src/max.js", "../node_modules/simple-statistics/src/extent.js", "../node_modules/simple-statistics/src/min_sorted.js", "../node_modules/simple-statistics/src/max_sorted.js", "../node_modules/simple-statistics/src/extent_sorted.js", "../node_modules/simple-statistics/src/sum_simple.js", "../node_modules/simple-statistics/src/product.js", "../node_modules/simple-statistics/src/quantile_sorted.js", "../node_modules/simple-statistics/src/quickselect.js", "../node_modules/simple-statistics/src/quantile.js", "../node_modules/simple-statistics/src/quantile_rank_sorted.js", "../node_modules/simple-statistics/src/quantile_rank.js", "../node_modules/simple-statistics/src/interquartile_range.js", "../node_modules/simple-statistics/src/median.js", "../node_modules/simple-statistics/src/median_absolute_deviation.js", "../node_modules/simple-statistics/src/chunk.js", "../node_modules/simple-statistics/src/sample_with_replacement.js", "../node_modules/simple-statistics/src/shuffle_in_place.js", "../node_modules/simple-statistics/src/shuffle.js", "../node_modules/simple-statistics/src/sample.js", "../node_modules/simple-statistics/src/make_matrix.js", "../node_modules/simple-statistics/src/unique_count_sorted.js", "../node_modules/simple-statistics/src/ckmeans.js", "../node_modules/simple-statistics/src/jenks_breaks.js", "../node_modules/simple-statistics/src/jenks_matrices.js", "../node_modules/simple-statistics/src/jenks.js", "../node_modules/simple-statistics/src/equal_interval_breaks.js", "../node_modules/simple-statistics/src/sample_covariance.js", "../node_modules/simple-statistics/src/sample_variance.js", "../node_modules/simple-statistics/src/sample_standard_deviation.js", "../node_modules/simple-statistics/src/sample_correlation.js", "../node_modules/simple-statistics/src/sample_rank_correlation.js", "../node_modules/simple-statistics/src/sample_skewness.js", "../node_modules/simple-statistics/src/sample_kurtosis.js", "../node_modules/simple-statistics/src/permutations_heap.js", "../node_modules/simple-statistics/src/combinations.js", "../node_modules/simple-statistics/src/combinations_replacement.js", "../node_modules/simple-statistics/src/add_to_mean.js", "../node_modules/simple-statistics/src/combine_means.js", "../node_modules/simple-statistics/src/combine_variances.js", "../node_modules/simple-statistics/src/geometric_mean.js", "../node_modules/simple-statistics/src/log_average.js", "../node_modules/simple-statistics/src/harmonic_mean.js", "../node_modules/simple-statistics/src/mean_simple.js", "../node_modules/simple-statistics/src/median_sorted.js", "../node_modules/simple-statistics/src/subtract_from_mean.js", "../node_modules/simple-statistics/src/root_mean_square.js", "../node_modules/simple-statistics/src/coefficient_of_variation.js", "../node_modules/simple-statistics/src/t_test.js", "../node_modules/simple-statistics/src/t_test_two_sample.js", "../node_modules/simple-statistics/src/wilcoxon_rank_sum.js", "../node_modules/simple-statistics/src/bayesian_classifier.js", "../node_modules/simple-statistics/src/perceptron.js", "../node_modules/simple-statistics/src/epsilon.js", "../node_modules/simple-statistics/src/factorial.js", "../node_modules/simple-statistics/src/gamma.js", "../node_modules/simple-statistics/src/gammaln.js", "../node_modules/simple-statistics/src/bernoulli_distribution.js", "../node_modules/simple-statistics/src/binomial_distribution.js", "../node_modules/simple-statistics/src/poisson_distribution.js", "../node_modules/simple-statistics/src/chi_squared_distribution_table.js", "../node_modules/simple-statistics/src/chi_squared_goodness_of_fit.js", "../node_modules/simple-statistics/src/kernel_density_estimation.js", "../node_modules/simple-statistics/src/z_score.js", "../node_modules/simple-statistics/src/standard_normal_table.js", "../node_modules/simple-statistics/src/cumulative_std_normal_probability.js", "../node_modules/simple-statistics/src/cumulative_std_logistic_probability.js", "../node_modules/simple-statistics/src/error_function.js", "../node_modules/simple-statistics/src/inverse_error_function.js", "../node_modules/simple-statistics/src/probit.js", "../node_modules/simple-statistics/src/logit.js", "../node_modules/simple-statistics/src/permutation_test.js", "../node_modules/simple-statistics/src/sign.js", "../node_modules/simple-statistics/src/bisect.js", "../node_modules/simple-statistics/src/euclidean_distance.js", "../node_modules/simple-statistics/src/k_means_cluster.js", "../node_modules/simple-statistics/src/silhouette.js", "../node_modules/simple-statistics/src/silhouette_metric.js", "../node_modules/simple-statistics/src/relative_error.js", "../node_modules/simple-statistics/src/approx_equal.js", "../node_modules/ml-xsadd/lib-es6/xsadd.js", "../node_modules/kollar-ts/src/utils/math.ts", "../node_modules/kollar-ts/src/utils/statistics.ts", "../node_modules/kollar-ts/src/utils/rle.ts", "../node_modules/kollar-ts/src/utils/rolling.ts", "../node_modules/kollar-ts/src/utils/validation.ts", "../node_modules/kollar-ts/src/preprocessing/interpolate.ts", "../node_modules/kollar-ts/src/preprocessing/preprocess.ts", "../node_modules/kollar-ts/src/preprocessing/rms.ts", "../node_modules/kollar-ts/src/preprocessing/downsample.ts", "../node_modules/kollar-ts/src/preprocessing/threshold.ts", "../node_modules/kollar-ts/src/core/fixation-utils.ts", "../node_modules/kollar-ts/src/core/algorithm-idt.ts", "../node_modules/kollar-ts/src/core/algorithm-ivt.ts", "../node_modules/kollar-ts/src/core/algorithm-i2mc.ts", "../node_modules/kollar-ts/src/core/algorithm-adaptive.ts", "../node_modules/kollar-ts/src/analysis/aoi.ts", "../src/workers/FixationWorker.ts"],
  "sourcesContent": ["/**\n * [Simple linear regression](http://en.wikipedia.org/wiki/Simple_linear_regression)\n * is a simple way to find a fitted line\n * between a set of coordinates. This algorithm finds the slope and y-intercept of a regression line\n * using the least sum of squares.\n *\n * @param {Array<Array<number>>} data an array of two-element of arrays,\n * like `[[0, 1], [2, 3]]`\n * @returns {Object} object containing slope and intersect of regression line\n * @example\n * linearRegression([[0, 0], [1, 1]]); // => { m: 1, b: 0 }\n */\nfunction linearRegression(data) {\n    let m;\n    let b;\n\n    // Store data length in a local variable to reduce\n    // repeated object property lookups\n    const dataLength = data.length;\n\n    //if there's only one point, arbitrarily choose a slope of 0\n    //and a y-intercept of whatever the y of the initial point is\n    if (dataLength === 1) {\n        m = 0;\n        b = data[0][1];\n    } else {\n        // Initialize our sums and scope the `m` and `b`\n        // variables that define the line.\n        let sumX = 0;\n        let sumY = 0;\n        let sumXX = 0;\n        let sumXY = 0;\n\n        // Use local variables to grab point values\n        // with minimal object property lookups\n        let point;\n        let x;\n        let y;\n\n        // Gather the sum of all x values, the sum of all\n        // y values, and the sum of x^2 and (x*y) for each\n        // value.\n        //\n        // In math notation, these would be SS_x, SS_y, SS_xx, and SS_xy\n        for (let i = 0; i < dataLength; i++) {\n            point = data[i];\n            x = point[0];\n            y = point[1];\n\n            sumX += x;\n            sumY += y;\n\n            sumXX += x * x;\n            sumXY += x * y;\n        }\n\n        // `m` is the slope of the regression line\n        m =\n            (dataLength * sumXY - sumX * sumY) /\n            (dataLength * sumXX - sumX * sumX);\n\n        // `b` is the y-intercept of the line.\n        b = sumY / dataLength - (m * sumX) / dataLength;\n    }\n\n    // Return both values as an object.\n    return {\n        m: m,\n        b: b\n    };\n}\n\nexport default linearRegression;\n", "/**\n * Given the output of `linearRegression`: an object\n * with `m` and `b` values indicating slope and intercept,\n * respectively, generate a line function that translates\n * x values into y values.\n *\n * @param {Object} mb object with `m` and `b` members, representing\n * slope and intersect of desired line\n * @returns {Function} method that computes y-value at any given\n * x-value on the line.\n * @example\n * var l = linearRegressionLine(linearRegression([[0, 0], [1, 1]]));\n * l(0) // = 0\n * l(2) // = 2\n * linearRegressionLine({ b: 0, m: 1 })(1); // => 1\n * linearRegressionLine({ b: 1, m: 1 })(1); // => 2\n */\nfunction linearRegressionLine(mb /*: { b: number, m: number }*/) {\n    // Return a function that computes a `y` value for each\n    // x value it is given, based on the values of `b` and `a`\n    // that we just computed.\n    return function (x) {\n        return mb.b + mb.m * x;\n    };\n}\n\nexport default linearRegressionLine;\n", "/**\n * Our default sum is the [Kahan-Babuska algorithm](https://pdfs.semanticscholar.org/1760/7d467cda1d0277ad272deb2113533131dc09.pdf).\n * This method is an improvement over the classical\n * [Kahan summation algorithm](https://en.wikipedia.org/wiki/Kahan_summation_algorithm).\n * It aims at computing the sum of a list of numbers while correcting for\n * floating-point errors. Traditionally, sums are calculated as many\n * successive additions, each one with its own floating-point roundoff. These\n * losses in precision add up as the number of numbers increases. This alternative\n * algorithm is more accurate than the simple way of calculating sums by simple\n * addition.\n *\n * This runs in `O(n)`, linear time, with respect to the length of the array.\n *\n * @param {Array<number>} x input\n * @return {number} sum of all input numbers\n * @example\n * sum([1, 2, 3]); // => 6\n */\nfunction sum(x) {\n    // If the array is empty, we needn't bother computing its sum\n    if (x.length === 0) {\n        return 0;\n    }\n\n    // Initializing the sum as the first number in the array\n    let sum = x[0];\n\n    // Keeping track of the floating-point error correction\n    let correction = 0;\n\n    let transition;\n\n    if (typeof sum !== \"number\") {\n        return Number.NaN;\n    }\n\n    for (let i = 1; i < x.length; i++) {\n        if (typeof x[i] !== \"number\") {\n            return Number.NaN;\n        }\n        transition = sum + x[i];\n\n        // Here we need to update the correction in a different fashion\n        // if the new absolute value is greater than the absolute sum\n        if (Math.abs(sum) >= Math.abs(x[i])) {\n            correction += sum - transition + x[i];\n        } else {\n            correction += x[i] - transition + sum;\n        }\n\n        sum = transition;\n    }\n\n    // Returning the corrected sum\n    return sum + correction;\n}\n\nexport default sum;\n", "import sum from \"./sum.js\";\n\n/**\n * The mean, _also known as average_,\n * is the sum of all values over the number of values.\n * This is a [measure of central tendency](https://en.wikipedia.org/wiki/Central_tendency):\n * a method of finding a typical or central value of a set of numbers.\n *\n * This runs in `O(n)`, linear time, with respect to the length of the array.\n *\n * @param {Array<number>} x sample of one or more data points\n * @throws {Error} if the length of x is less than one\n * @returns {number} mean\n * @example\n * mean([0, 10]); // => 5\n */\nfunction mean(x) {\n    if (x.length === 0) {\n        throw new Error(\"mean requires at least one data point\");\n    }\n\n    return sum(x) / x.length;\n}\n\nexport default mean;\n", "import mean from \"./mean.js\";\n\n/**\n * The sum of deviations to the Nth power.\n * When n=2 it's the sum of squared deviations.\n * When n=3 it's the sum of cubed deviations.\n *\n * @param {Array<number>} x\n * @param {number} n power\n * @returns {number} sum of nth power deviations\n *\n * @example\n * var input = [1, 2, 3];\n * // since the variance of a set is the mean squared\n * // deviations, we can calculate that with sumNthPowerDeviations:\n * sumNthPowerDeviations(input, 2) / input.length;\n */\nfunction sumNthPowerDeviations(x, n) {\n    const meanValue = mean(x);\n    let sum = 0;\n    let tempValue;\n    let i;\n\n    // This is an optimization: when n is 2 (we're computing a number squared),\n    // multiplying the number by itself is significantly faster than using\n    // the Math.pow method.\n    if (n === 2) {\n        for (i = 0; i < x.length; i++) {\n            tempValue = x[i] - meanValue;\n            sum += tempValue * tempValue;\n        }\n    } else {\n        for (i = 0; i < x.length; i++) {\n            sum += Math.pow(x[i] - meanValue, n);\n        }\n    }\n\n    return sum;\n}\n\nexport default sumNthPowerDeviations;\n", "import sumNthPowerDeviations from \"./sum_nth_power_deviations.js\";\n\n/**\n * The [variance](http://en.wikipedia.org/wiki/Variance)\n * is the sum of squared deviations from the mean.\n *\n * This is an implementation of variance, not sample variance:\n * see the `sampleVariance` method if you want a sample measure.\n *\n * @param {Array<number>} x a population of one or more data points\n * @returns {number} variance: a value greater than or equal to zero.\n * zero indicates that all values are identical.\n * @throws {Error} if x's length is 0\n * @example\n * variance([1, 2, 3, 4, 5, 6]); // => 2.9166666666666665\n */\nfunction variance(x) {\n    if (x.length === 0) {\n        throw new Error(\"variance requires at least one data point\");\n    }\n\n    // Find the mean of squared deviations between the\n    // mean value and each value.\n    return sumNthPowerDeviations(x, 2) / x.length;\n}\n\nexport default variance;\n", "import variance from \"./variance.js\";\n\n/**\n * The [standard deviation](http://en.wikipedia.org/wiki/Standard_deviation)\n * is the square root of the variance. This is also known as the population\n * standard deviation. It's useful for measuring the amount\n * of variation or dispersion in a set of values.\n *\n * Standard deviation is only appropriate for full-population knowledge: for\n * samples of a population, {@link sampleStandardDeviation} is\n * more appropriate.\n *\n * @param {Array<number>} x input\n * @returns {number} standard deviation\n * @example\n * variance([2, 4, 4, 4, 5, 5, 7, 9]); // => 4\n * standardDeviation([2, 4, 4, 4, 5, 5, 7, 9]); // => 2\n */\nfunction standardDeviation(x) {\n    if (x.length === 1) {\n        return 0;\n    }\n    const v = variance(x);\n    return Math.sqrt(v);\n}\n\nexport default standardDeviation;\n", "/**\n * The [R Squared](http://en.wikipedia.org/wiki/Coefficient_of_determination)\n * value of data compared with a function `f`\n * is the sum of the squared differences between the prediction\n * and the actual value.\n *\n * @param {Array<Array<number>>} x input data: this should be doubly-nested\n * @param {Function} func function called on `[i][0]` values within the dataset\n * @returns {number} r-squared value\n * @example\n * var samples = [[0, 0], [1, 1]];\n * var regressionLine = linearRegressionLine(linearRegression(samples));\n * rSquared(samples, regressionLine); // = 1 this line is a perfect fit\n */\nfunction rSquared(x, func) {\n    if (x.length < 2) {\n        return 1;\n    }\n\n    // Compute the average y value for the actual\n    // data set in order to compute the\n    // _total sum of squares_\n    let sum = 0;\n    for (let i = 0; i < x.length; i++) {\n        sum += x[i][1];\n    }\n    const average = sum / x.length;\n\n    // Compute the total sum of squares - the\n    // squared difference between each point\n    // and the average of all points.\n    let sumOfSquares = 0;\n    for (let j = 0; j < x.length; j++) {\n        sumOfSquares += Math.pow(average - x[j][1], 2);\n    }\n\n    // Finally estimate the error: the squared\n    // difference between the estimate and the actual data\n    // value at each point.\n    let err = 0;\n    for (let k = 0; k < x.length; k++) {\n        err += Math.pow(x[k][1] - func(x[k][0]), 2);\n    }\n\n    // As the error grows larger, its ratio to the\n    // sum of squares increases and the r squared\n    // value grows lower.\n    return 1 - err / sumOfSquares;\n}\n\nexport default rSquared;\n", "/**\n * The [mode](https://en.wikipedia.org/wiki/Mode_%28statistics%29) is the number\n * that appears in a list the highest number of times.\n * There can be multiple modes in a list: in the event of a tie, this\n * algorithm will return the most recently seen mode.\n *\n * This is a [measure of central tendency](https://en.wikipedia.org/wiki/Central_tendency):\n * a method of finding a typical or central value of a set of numbers.\n *\n * This runs in `O(n)` because the input is sorted.\n *\n * @param {Array<number>} sorted a sample of one or more data points\n * @returns {number} mode\n * @throws {Error} if sorted is empty\n * @example\n * modeSorted([0, 0, 1]); // => 0\n */\nfunction modeSorted(sorted) {\n    // Handle edge cases:\n    // The mode of an empty list is undefined\n    if (sorted.length === 0) {\n        throw new Error(\"mode requires at least one data point\");\n    }\n    if (sorted.length === 1) {\n        return sorted[0];\n    }\n\n    // This assumes it is dealing with an array of size > 1, since size\n    // 0 and 1 are handled immediately. Hence it starts at index 1 in the\n    // array.\n    let last = sorted[0];\n    // store the mode as we find new modes\n    let value = Number.NaN;\n    // store how many times we've seen the mode\n    let maxSeen = 0;\n    // how many times the current candidate for the mode\n    // has been seen\n    let seenThis = 1;\n\n    // end at sorted.length + 1 to fix the case in which the mode is\n    // the highest number that occurs in the sequence. the last iteration\n    // compares sorted[i], which is undefined, to the highest number\n    // in the series\n    for (let i = 1; i < sorted.length + 1; i++) {\n        // we're seeing a new number pass by\n        if (sorted[i] !== last) {\n            // the last number is the new mode since we saw it more\n            // often than the old one\n            if (seenThis > maxSeen) {\n                maxSeen = seenThis;\n                value = last;\n            }\n            seenThis = 1;\n            last = sorted[i];\n            // if this isn't a new number, it's one more occurrence of\n            // the potential mode\n        } else {\n            seenThis++;\n        }\n    }\n    return value;\n}\n\nexport default modeSorted;\n", "/**\n * Sort an array of numbers by their numeric value, ensuring that the\n * array is not changed in place.\n *\n * This is necessary because the default behavior of .sort\n * in JavaScript is to sort arrays as string values\n *\n *     [1, 10, 12, 102, 20].sort()\n *     // output\n *     [1, 10, 102, 12, 20]\n *\n * @param {Array<number>} x input array\n * @return {Array<number>} sorted array\n * @private\n * @example\n * numericSort([3, 2, 1]) // => [1, 2, 3]\n */\nfunction numericSort(x) {\n    return (\n        x\n            // ensure the array is not changed in-place\n            .slice()\n            // comparator function that treats input as numeric\n            .sort(function (a, b) {\n                return a - b;\n            })\n    );\n}\n\nexport default numericSort;\n", "import modeSorted from \"./mode_sorted.js\";\nimport numericSort from \"./numeric_sort.js\";\n\n/**\n * The [mode](https://en.wikipedia.org/wiki/Mode_%28statistics%29) is the number\n * that appears in a list the highest number of times.\n * There can be multiple modes in a list: in the event of a tie, this\n * algorithm will return the most recently seen mode.\n *\n * This is a [measure of central tendency](https://en.wikipedia.org/wiki/Central_tendency):\n * a method of finding a typical or central value of a set of numbers.\n *\n * This runs in `O(n log(n))` because it needs to sort the array internally\n * before running an `O(n)` search to find the mode.\n *\n * @param {Array<number>} x input\n * @returns {number} mode\n * @example\n * mode([0, 0, 1]); // => 0\n */\nfunction mode(x) {\n    // Sorting the array lets us iterate through it below and be sure\n    // that every time we see a new number it's new and we'll never\n    // see the same number twice\n    return modeSorted(numericSort(x));\n}\n\nexport default mode;\n", "/* globals Map: false */\n\n/**\n * The [mode](https://en.wikipedia.org/wiki/Mode_%28statistics%29) is the number\n * that appears in a list the highest number of times.\n * There can be multiple modes in a list: in the event of a tie, this\n * algorithm will return the most recently seen mode.\n *\n * modeFast uses a Map object to keep track of the mode, instead of the approach\n * used with `mode`, a sorted array. As a result, it is faster\n * than `mode` and supports any data type that can be compared with `==`.\n * It also requires a\n * [JavaScript environment with support for Map](https://kangax.github.io/compat-table/es6/#test-Map),\n * and will throw an error if Map is not available.\n *\n * This is a [measure of central tendency](https://en.wikipedia.org/wiki/Central_tendency):\n * a method of finding a typical or central value of a set of numbers.\n *\n * @param {Array<*>} x a sample of one or more data points\n * @returns {?*} mode\n * @throws {ReferenceError} if the JavaScript environment doesn't support Map\n * @throws {Error} if x is empty\n * @example\n * modeFast(['rabbits', 'rabbits', 'squirrels']); // => 'rabbits'\n */\nfunction modeFast(x) {\n    // This index will reflect the incidence of different values, indexing\n    // them like\n    // { value: count }\n    const index = new Map();\n\n    // A running `mode` and the number of times it has been encountered.\n    let mode;\n    let modeCount = 0;\n\n    for (let i = 0; i < x.length; i++) {\n        let newCount = index.get(x[i]);\n        if (newCount === undefined) {\n            newCount = 1;\n        } else {\n            newCount++;\n        }\n        if (newCount > modeCount) {\n            mode = x[i];\n            modeCount = newCount;\n        }\n        index.set(x[i], newCount);\n    }\n\n    if (modeCount === 0) {\n        throw new Error(\"mode requires at last one data point\");\n    }\n\n    return mode;\n}\n\nexport default modeFast;\n", "/**\n * The min is the lowest number in the array.\n * This runs in `O(n)`, linear time, with respect to the length of the array.\n *\n * @param {Array<number>} x sample of one or more data points\n * @throws {Error} if the length of x is less than one\n * @returns {number} minimum value\n * @example\n * min([1, 5, -10, 100, 2]); // => -10\n */\nfunction min(x) {\n    if (x.length === 0) {\n        throw new Error(\"min requires at least one data point\");\n    }\n\n    let value = x[0];\n    for (let i = 1; i < x.length; i++) {\n        if (x[i] < value) {\n            value = x[i];\n        }\n    }\n    return value;\n}\n\nexport default min;\n", "/**\n * This computes the maximum number in an array.\n *\n * This runs in `O(n)`, linear time, with respect to the length of the array.\n *\n * @param {Array<number>} x sample of one or more data points\n * @returns {number} maximum value\n * @throws {Error} if the length of x is less than one\n * @example\n * max([1, 2, 3, 4]);\n * // => 4\n */\nfunction max(x) {\n    if (x.length === 0) {\n        throw new Error(\"max requires at least one data point\");\n    }\n\n    let value = x[0];\n    for (let i = 1; i < x.length; i++) {\n        if (x[i] > value) {\n            value = x[i];\n        }\n    }\n    return value;\n}\n\nexport default max;\n", "/**\n * This computes the minimum & maximum number in an array.\n *\n * This runs in `O(n)`, linear time, with respect to the length of the array.\n *\n * @param {Array<number>} x sample of one or more data points\n * @returns {Array<number>} minimum & maximum value\n * @throws {Error} if the length of x is less than one\n * @example\n * extent([1, 2, 3, 4]);\n * // => [1, 4]\n */\nfunction extent(x) {\n    if (x.length === 0) {\n        throw new Error(\"extent requires at least one data point\");\n    }\n\n    let min = x[0];\n    let max = x[0];\n    for (let i = 1; i < x.length; i++) {\n        if (x[i] > max) {\n            max = x[i];\n        }\n        if (x[i] < min) {\n            min = x[i];\n        }\n    }\n    return [min, max];\n}\n\nexport default extent;\n", "/**\n * The minimum is the lowest number in the array. With a sorted array,\n * the first element in the array is always the smallest, so this calculation\n * can be done in one step, or constant time.\n *\n * @param {Array<number>} x input\n * @returns {number} minimum value\n * @example\n * minSorted([-100, -10, 1, 2, 5]); // => -100\n */\nfunction minSorted(x) {\n    return x[0];\n}\n\nexport default minSorted;\n", "/**\n * The maximum is the highest number in the array. With a sorted array,\n * the last element in the array is always the largest, so this calculation\n * can be done in one step, or constant time.\n *\n * @param {Array<number>} x input\n * @returns {number} maximum value\n * @example\n * maxSorted([-100, -10, 1, 2, 5]); // => 5\n */\nfunction maxSorted(x) {\n    return x[x.length - 1];\n}\n\nexport default maxSorted;\n", "/**\n * The extent is the lowest & highest number in the array. With a sorted array,\n * the first element in the array is always the lowest while the last element is always the largest, so this calculation\n * can be done in one step, or constant time.\n *\n * @param {Array<number>} x input\n * @returns {Array<number>} minimum & maximum value\n * @example\n * extentSorted([-100, -10, 1, 2, 5]); // => [-100, 5]\n */\nfunction extentSorted(x) {\n    return [x[0], x[x.length - 1]];\n}\n\nexport default extentSorted;\n", "/**\n * The simple [sum](https://en.wikipedia.org/wiki/Summation) of an array\n * is the result of adding all numbers together, starting from zero.\n *\n * This runs in `O(n)`, linear time, with respect to the length of the array.\n *\n * @param {Array<number>} x input\n * @return {number} sum of all input numbers\n * @example\n * sumSimple([1, 2, 3]); // => 6\n */\nfunction sumSimple(x) {\n    let value = 0;\n    for (let i = 0; i < x.length; i++) {\n        if (typeof x[i] !== \"number\") {\n            return Number.NaN;\n        }\n        value += x[i];\n    }\n    return value;\n}\n\nexport default sumSimple;\n", "/**\n * The [product](https://en.wikipedia.org/wiki/Product_(mathematics)) of an array\n * is the result of multiplying all numbers together, starting using one as the multiplicative identity.\n *\n * This runs in `O(n)`, linear time, with respect to the length of the array.\n *\n * @param {Array<number>} x input\n * @return {number} product of all input numbers\n * @example\n * product([1, 2, 3, 4]); // => 24\n */\nfunction product(x) {\n    let value = 1;\n    for (let i = 0; i < x.length; i++) {\n        value *= x[i];\n    }\n    return value;\n}\n\nexport default product;\n", "/**\n * This is the internal implementation of quantiles: when you know\n * that the order is sorted, you don't need to re-sort it, and the computations\n * are faster.\n *\n * @param {Array<number>} x sample of one or more data points\n * @param {number} p desired quantile: a number between 0 to 1, inclusive\n * @returns {number} quantile value\n * @throws {Error} if p ix outside of the range from 0 to 1\n * @throws {Error} if x is empty\n * @example\n * quantileSorted([3, 6, 7, 8, 8, 9, 10, 13, 15, 16, 20], 0.5); // => 9\n */\nfunction quantileSorted(x, p) {\n    const idx = x.length * p;\n    if (x.length === 0) {\n        throw new Error(\"quantile requires at least one data point.\");\n    } else if (p < 0 || p > 1) {\n        throw new Error(\"quantiles must be between 0 and 1\");\n    } else if (p === 1) {\n        // If p is 1, directly return the last element\n        return x[x.length - 1];\n    } else if (p === 0) {\n        // If p is 0, directly return the first element\n        return x[0];\n    } else if (idx % 1 !== 0) {\n        // If p is not integer, return the next element in array\n        return x[Math.ceil(idx) - 1];\n    } else if (x.length % 2 === 0) {\n        // If the list has even-length, we'll take the average of this number\n        // and the next value, if there is one\n        return (x[idx - 1] + x[idx]) / 2;\n    } else {\n        // Finally, in the simple case of an integer value\n        // with an odd-length list, return the x value at the index.\n        return x[idx];\n    }\n}\n\nexport default quantileSorted;\n", "/**\n * Rearrange items in `arr` so that all items in `[left, k]` range are the smallest.\n * The `k`-th element will have the `(k - left + 1)`-th smallest value in `[left, right]`.\n *\n * Implements Floyd-Rivest selection algorithm https://en.wikipedia.org/wiki/Floyd-Rivest_algorithm\n *\n * @param {Array<number>} arr input array\n * @param {number} k pivot index\n * @param {number} [left] left index\n * @param {number} [right] right index\n * @returns {void} mutates input array\n * @example\n * var arr = [65, 28, 59, 33, 21, 56, 22, 95, 50, 12, 90, 53, 28, 77, 39];\n * quickselect(arr, 8);\n * // = [39, 28, 28, 33, 21, 12, 22, 50, 53, 56, 59, 65, 90, 77, 95]\n */\nfunction quickselect(arr, k, left, right) {\n    left = left || 0;\n    right = right || arr.length - 1;\n\n    while (right > left) {\n        // 600 and 0.5 are arbitrary constants chosen in the original paper to minimize execution time\n        if (right - left > 600) {\n            const n = right - left + 1;\n            const m = k - left + 1;\n            const z = Math.log(n);\n            const s = 0.5 * Math.exp((2 * z) / 3);\n            let sd = 0.5 * Math.sqrt((z * s * (n - s)) / n);\n            if (m - n / 2 < 0) sd *= -1;\n            const newLeft = Math.max(left, Math.floor(k - (m * s) / n + sd));\n            const newRight = Math.min(\n                right,\n                Math.floor(k + ((n - m) * s) / n + sd)\n            );\n            quickselect(arr, k, newLeft, newRight);\n        }\n\n        const t = arr[k];\n        let i = left;\n        let j = right;\n\n        swap(arr, left, k);\n        if (arr[right] > t) swap(arr, left, right);\n\n        while (i < j) {\n            swap(arr, i, j);\n            i++;\n            j--;\n            while (arr[i] < t) i++;\n            while (arr[j] > t) j--;\n        }\n\n        if (arr[left] === t) swap(arr, left, j);\n        else {\n            j++;\n            swap(arr, j, right);\n        }\n\n        if (j <= k) left = j + 1;\n        if (k <= j) right = j - 1;\n    }\n}\n\nfunction swap(arr, i, j) {\n    const tmp = arr[i];\n    arr[i] = arr[j];\n    arr[j] = tmp;\n}\n\nexport default quickselect;\n", "import quantileSorted from \"./quantile_sorted.js\";\nimport quickselect from \"./quickselect.js\";\n\n/**\n * The [quantile](https://en.wikipedia.org/wiki/Quantile):\n * this is a population quantile, since we assume to know the entire\n * dataset in this library. This is an implementation of the\n * [Quantiles of a Population](http://en.wikipedia.org/wiki/Quantile#Quantiles_of_a_population)\n * algorithm from wikipedia.\n *\n * Sample is a one-dimensional array of numbers,\n * and p is either a decimal number from 0 to 1 or an array of decimal\n * numbers from 0 to 1.\n * In terms of a k/q quantile, p = k/q - it's just dealing with fractions or dealing\n * with decimal values.\n * When p is an array, the result of the function is also an array containing the appropriate\n * quantiles in input order\n *\n * @param {Array<number>} x sample of one or more numbers\n * @param {Array<number> | number} p the desired quantile, as a number between 0 and 1\n * @returns {number} quantile\n * @example\n * quantile([3, 6, 7, 8, 8, 9, 10, 13, 15, 16, 20], 0.5); // => 9\n */\nfunction quantile(x, p) {\n    const copy = x.slice();\n\n    if (Array.isArray(p)) {\n        // rearrange elements so that each element corresponding to a requested\n        // quantile is on a place it would be if the array was fully sorted\n        multiQuantileSelect(copy, p);\n        // Initialize the result array\n        const results = [];\n        // For each requested quantile\n        for (let i = 0; i < p.length; i++) {\n            results[i] = quantileSorted(copy, p[i]);\n        }\n        return results;\n    } else {\n        const idx = quantileIndex(copy.length, p);\n        quantileSelect(copy, idx, 0, copy.length - 1);\n        return quantileSorted(copy, p);\n    }\n}\n\nfunction quantileSelect(arr, k, left, right) {\n    if (k % 1 === 0) {\n        quickselect(arr, k, left, right);\n    } else {\n        k = Math.floor(k);\n        quickselect(arr, k, left, right);\n        quickselect(arr, k + 1, k + 1, right);\n    }\n}\n\nfunction multiQuantileSelect(arr, p) {\n    const indices = [0];\n    for (let i = 0; i < p.length; i++) {\n        indices.push(quantileIndex(arr.length, p[i]));\n    }\n    indices.push(arr.length - 1);\n    indices.sort(compare);\n\n    const stack = [0, indices.length - 1];\n\n    while (stack.length) {\n        const r = Math.ceil(stack.pop());\n        const l = Math.floor(stack.pop());\n        if (r - l <= 1) continue;\n\n        const m = Math.floor((l + r) / 2);\n        quantileSelect(\n            arr,\n            indices[m],\n            Math.floor(indices[l]),\n            Math.ceil(indices[r])\n        );\n\n        stack.push(l, m, m, r);\n    }\n}\n\nfunction compare(a, b) {\n    return a - b;\n}\n\nfunction quantileIndex(len, p) {\n    const idx = len * p;\n    if (p === 1) {\n        // If p is 1, directly return the last index\n        return len - 1;\n    } else if (p === 0) {\n        // If p is 0, directly return the first index\n        return 0;\n    } else if (idx % 1 !== 0) {\n        // If index is not integer, return the next index in array\n        return Math.ceil(idx) - 1;\n    } else if (len % 2 === 0) {\n        // If the list has even-length, we'll return the middle of two indices\n        // around quantile to indicate that we need an average value of the two\n        return idx - 0.5;\n    } else {\n        // Finally, in the simple case of an integer index\n        // with an odd-length list, return the index\n        return idx;\n    }\n}\n\nexport default quantile;\n", "/* eslint no-bitwise: 0 */\n\n/**\n * This function returns the quantile in which one would find the given value in\n * the given array. With a sorted array, leveraging binary search, we can find\n * this information in logarithmic time.\n *\n * @param {Array<number>} x input\n * @returns {number} value value\n * @example\n * quantileRankSorted([1, 2, 3, 4], 3); // => 0.75\n * quantileRankSorted([1, 2, 3, 3, 4], 3); // => 0.7\n * quantileRankSorted([1, 2, 3, 4], 6); // => 1\n * quantileRankSorted([1, 2, 3, 3, 5], 4); // => 0.8\n */\nfunction quantileRankSorted(x, value) {\n    // Value is lesser than any value in the array\n    if (value < x[0]) {\n        return 0;\n    }\n\n    // Value is greater than any value in the array\n    if (value > x[x.length - 1]) {\n        return 1;\n    }\n\n    let l = lowerBound(x, value);\n\n    // Value is not in the array\n    if (x[l] !== value) {\n        return l / x.length;\n    }\n\n    l++;\n\n    const u = upperBound(x, value);\n\n    // The value exists only once in the array\n    if (u === l) {\n        return l / x.length;\n    }\n\n    // Here, we are basically computing the mean of the range of indices\n    // containing our searched value. But, instead, of initializing an\n    // array and looping over it, there is a dedicated math formula that\n    // we apply below to get the result.\n    const r = u - l + 1;\n    const sum = (r * (u + l)) / 2;\n    const mean = sum / r;\n\n    return mean / x.length;\n}\n\nfunction lowerBound(x, value) {\n    let mid = 0;\n    let lo = 0;\n    let hi = x.length;\n\n    while (lo < hi) {\n        mid = (lo + hi) >>> 1;\n\n        if (value <= x[mid]) {\n            hi = mid;\n        } else {\n            lo = -~mid;\n        }\n    }\n\n    return lo;\n}\n\nfunction upperBound(x, value) {\n    let mid = 0;\n    let lo = 0;\n    let hi = x.length;\n\n    while (lo < hi) {\n        mid = (lo + hi) >>> 1;\n\n        if (value >= x[mid]) {\n            lo = -~mid;\n        } else {\n            hi = mid;\n        }\n    }\n\n    return lo;\n}\n\nexport default quantileRankSorted;\n", "import numericSort from \"./numeric_sort.js\";\nimport quantileRankSorted from \"./quantile_rank_sorted.js\";\n\n/**\n * This function returns the quantile in which one would find the given value in\n * the given array. It will copy and sort your array before each run, so\n * if you know your array is already sorted, you should use `quantileRankSorted`\n * instead.\n *\n * @param {Array<number>} x input\n * @returns {number} value value\n * @example\n * quantileRank([4, 3, 1, 2], 3); // => 0.75\n * quantileRank([4, 3, 2, 3, 1], 3); // => 0.7\n * quantileRank([2, 4, 1, 3], 6); // => 1\n * quantileRank([5, 3, 1, 2, 3], 4); // => 0.8\n */\nfunction quantileRank(x, value) {\n    // Cloning and sorting the array\n    const sortedCopy = numericSort(x);\n\n    return quantileRankSorted(sortedCopy, value);\n}\n\nexport default quantileRank;\n", "import quantile from \"./quantile.js\";\n\n/**\n * The [Interquartile range](http://en.wikipedia.org/wiki/Interquartile_range) is\n * a measure of statistical dispersion, or how scattered, spread, or\n * concentrated a distribution is. It's computed as the difference between\n * the third quartile and first quartile.\n *\n * @param {Array<number>} x sample of one or more numbers\n * @returns {number} interquartile range: the span between lower and upper quartile,\n * 0.25 and 0.75\n * @example\n * interquartileRange([0, 1, 2, 3]); // => 2\n */\nfunction interquartileRange(x) {\n    // Interquartile range is the span between the upper quartile,\n    // at `0.75`, and lower quartile, `0.25`\n    const q1 = quantile(x, 0.75);\n    const q2 = quantile(x, 0.25);\n\n    if (typeof q1 === \"number\" && typeof q2 === \"number\") {\n        return q1 - q2;\n    }\n}\n\nexport default interquartileRange;\n", "import quantile from \"./quantile.js\";\n\n/**\n * The [median](http://en.wikipedia.org/wiki/Median) is\n * the middle number of a list. This is often a good indicator of 'the middle'\n * when there are outliers that skew the `mean()` value.\n * This is a [measure of central tendency](https://en.wikipedia.org/wiki/Central_tendency):\n * a method of finding a typical or central value of a set of numbers.\n *\n * The median isn't necessarily one of the elements in the list: the value\n * can be the average of two elements if the list has an even length\n * and the two central values are different.\n *\n * @param {Array<number>} x input\n * @returns {number} median value\n * @example\n * median([10, 2, 5, 100, 2, 1]); // => 3.5\n */\nfunction median(x) {\n    return +quantile(x, 0.5);\n}\n\nexport default median;\n", "import median from \"./median.js\";\n\n/**\n * The [Median Absolute Deviation](http://en.wikipedia.org/wiki/Median_absolute_deviation) is\n * a robust measure of statistical\n * dispersion. It is more resilient to outliers than the standard deviation.\n *\n * @param {Array<number>} x input array\n * @returns {number} median absolute deviation\n * @example\n * medianAbsoluteDeviation([1, 1, 2, 2, 4, 6, 9]); // => 1\n */\nfunction medianAbsoluteDeviation(x) {\n    const medianValue = median(x);\n    const medianAbsoluteDeviations = [];\n\n    // Make a list of absolute deviations from the median\n    for (let i = 0; i < x.length; i++) {\n        medianAbsoluteDeviations.push(Math.abs(x[i] - medianValue));\n    }\n\n    // Find the median value of that list\n    return median(medianAbsoluteDeviations);\n}\n\nexport default medianAbsoluteDeviation;\n", "/**\n * Split an array into chunks of a specified size. This function\n * has the same behavior as [PHP's array_chunk](http://php.net/manual/en/function.array-chunk.php)\n * function, and thus will insert smaller-sized chunks at the end if\n * the input size is not divisible by the chunk size.\n *\n * `x` is expected to be an array, and `chunkSize` a number.\n * The `x` array can contain any kind of data.\n *\n * @param {Array} x a sample\n * @param {number} chunkSize size of each output array. must be a positive integer\n * @returns {Array<Array>} a chunked array\n * @throws {Error} if chunk size is less than 1 or not an integer\n * @example\n * chunk([1, 2, 3, 4, 5, 6], 2);\n * // => [[1, 2], [3, 4], [5, 6]]\n */\nfunction chunk(x, chunkSize) {\n    // a list of result chunks, as arrays in an array\n    const output = [];\n\n    // `chunkSize` must be zero or higher - otherwise the loop below,\n    // in which we call `start += chunkSize`, will loop infinitely.\n    // So, we'll detect and throw in that case to indicate\n    // invalid input.\n    if (chunkSize < 1) {\n        throw new Error(\"chunk size must be a positive number\");\n    }\n\n    if (Math.floor(chunkSize) !== chunkSize) {\n        throw new Error(\"chunk size must be an integer\");\n    }\n\n    // `start` is the index at which `.slice` will start selecting\n    // new array elements\n    for (let start = 0; start < x.length; start += chunkSize) {\n        // for each chunk, slice that part of the array and add it\n        // to the output. The `.slice` function does not change\n        // the original array.\n        output.push(x.slice(start, start + chunkSize));\n    }\n    return output;\n}\n\nexport default chunk;\n", "/**\n * Sampling with replacement is a type of sampling that allows the same\n * item to be picked out of a population more than once.\n *\n * @param {Array<*>} x an array of any kind of value\n * @param {number} n count of how many elements to take\n * @param {Function} [randomSource=Math.random] an optional entropy source that\n * returns numbers between 0 inclusive and 1 exclusive: the range [0, 1)\n * @return {Array} n sampled items from the population\n * @example\n * var values = [1, 2, 3, 4];\n * sampleWithReplacement(values, 2); // returns 2 random values, like [2, 4];\n */\nfunction sampleWithReplacement(x, n, randomSource) {\n    if (x.length === 0) {\n        return [];\n    }\n\n    // a custom random number source can be provided if you want to use\n    // a fixed seed or another random number generator, like\n    // [random-js](https://www.npmjs.org/package/random-js)\n    randomSource = randomSource || Math.random;\n\n    const length = x.length;\n    const sample = [];\n\n    for (let i = 0; i < n; i++) {\n        const index = Math.floor(randomSource() * length);\n\n        sample.push(x[index]);\n    }\n\n    return sample;\n}\n\nexport default sampleWithReplacement;\n", "/**\n * A [Fisher-Yates shuffle](http://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle)\n * in-place - which means that it **will change the order of the original\n * array by reference**.\n *\n * This is an algorithm that generates a random [permutation](https://en.wikipedia.org/wiki/Permutation)\n * of a set.\n *\n * @param {Array} x sample of one or more numbers\n * @param {Function} [randomSource=Math.random] an optional entropy source that\n * returns numbers between 0 inclusive and 1 exclusive: the range [0, 1)\n * @returns {Array} x\n * @example\n * var x = [1, 2, 3, 4];\n * shuffleInPlace(x);\n * // x is shuffled to a value like [2, 1, 4, 3]\n */\nfunction shuffleInPlace(x, randomSource) {\n    // a custom random number source can be provided if you want to use\n    // a fixed seed or another random number generator, like\n    // [random-js](https://www.npmjs.org/package/random-js)\n    randomSource = randomSource || Math.random;\n\n    // store the current length of the x to determine\n    // when no elements remain to shuffle.\n    let length = x.length;\n\n    // temporary is used to hold an item when it is being\n    // swapped between indices.\n    let temporary;\n\n    // The index to swap at each stage.\n    let index;\n\n    // While there are still items to shuffle\n    while (length > 0) {\n        // choose a random index within the subset of the array\n        // that is not yet shuffled\n        index = Math.floor(randomSource() * length--);\n\n        // store the value that we'll move temporarily\n        temporary = x[length];\n\n        // swap the value at `x[length]` with `x[index]`\n        x[length] = x[index];\n        x[index] = temporary;\n    }\n\n    return x;\n}\n\nexport default shuffleInPlace;\n", "import shuffleInPlace from \"./shuffle_in_place.js\";\n\n/**\n * A [Fisher-Yates shuffle](http://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle)\n * is a fast way to create a random permutation of a finite set. This is\n * a function around `shuffle_in_place` that adds the guarantee that\n * it will not modify its input.\n *\n * @param {Array} x sample of 0 or more numbers\n * @param {Function} [randomSource=Math.random] an optional entropy source that\n * returns numbers between 0 inclusive and 1 exclusive: the range [0, 1)\n * @return {Array} shuffled version of input\n * @example\n * var shuffled = shuffle([1, 2, 3, 4]);\n * shuffled; // = [2, 3, 1, 4] or any other random permutation\n */\nfunction shuffle(x, randomSource) {\n    // slice the original array so that it is not modified\n    const sample = x.slice();\n\n    // and then shuffle that shallow-copied array, in place\n    return shuffleInPlace(sample, randomSource);\n}\n\nexport default shuffle;\n", "import shuffle from \"./shuffle.js\";\n\n/**\n * Create a [simple random sample](http://en.wikipedia.org/wiki/Simple_random_sample)\n * from a given array of `n` elements.\n *\n * The sampled values will be in any order, not necessarily the order\n * they appear in the input.\n *\n * @param {Array<any>} x input array. can contain any type\n * @param {number} n count of how many elements to take\n * @param {Function} [randomSource=Math.random] an optional entropy source that\n * returns numbers between 0 inclusive and 1 exclusive: the range [0, 1)\n * @return {Array} subset of n elements in original array\n *\n * @example\n * var values = [1, 2, 4, 5, 6, 7, 8, 9];\n * sample(values, 3); // returns 3 random values, like [2, 5, 8];\n */\nfunction sample(x, n, randomSource) {\n    // shuffle the original array using a fisher-yates shuffle\n    const shuffled = shuffle(x, randomSource);\n\n    // and then return a subset of it - the first `n` elements.\n    return shuffled.slice(0, n);\n}\n\nexport default sample;\n", "/**\n * Create a new column x row matrix.\n *\n * @private\n * @param {number} columns\n * @param {number} rows\n * @return {Array<Array<number>>} matrix\n * @example\n * makeMatrix(10, 10);\n */\nfunction makeMatrix(columns, rows) {\n    const matrix = [];\n    for (let i = 0; i < columns; i++) {\n        const column = [];\n        for (let j = 0; j < rows; j++) {\n            column.push(0);\n        }\n        matrix.push(column);\n    }\n    return matrix;\n}\n\nexport default makeMatrix;\n", "/**\n * For a sorted input, counting the number of unique values\n * is possible in constant time and constant memory. This is\n * a simple implementation of the algorithm.\n *\n * Values are compared with `===`, so objects and non-primitive objects\n * are not handled in any special way.\n *\n * @param {Array<*>} x an array of any kind of value\n * @returns {number} count of unique values\n * @example\n * uniqueCountSorted([1, 2, 3]); // => 3\n * uniqueCountSorted([1, 1, 1]); // => 1\n */\nfunction uniqueCountSorted(x) {\n    let uniqueValueCount = 0;\n    let lastSeenValue;\n    for (let i = 0; i < x.length; i++) {\n        if (i === 0 || x[i] !== lastSeenValue) {\n            lastSeenValue = x[i];\n            uniqueValueCount++;\n        }\n    }\n    return uniqueValueCount;\n}\n\nexport default uniqueCountSorted;\n", "import makeMatrix from \"./make_matrix.js\";\nimport numericSort from \"./numeric_sort.js\";\nimport uniqueCountSorted from \"./unique_count_sorted.js\";\n\n/**\n * Generates incrementally computed values based on the sums and sums of\n * squares for the data array\n *\n * @private\n * @param {number} j\n * @param {number} i\n * @param {Array<number>} sums\n * @param {Array<number>} sumsOfSquares\n * @return {number}\n * @example\n * ssq(0, 1, [-1, 0, 2], [1, 1, 5]);\n */\nfunction ssq(j, i, sums, sumsOfSquares) {\n    let sji; // s(j, i)\n    if (j > 0) {\n        const muji = (sums[i] - sums[j - 1]) / (i - j + 1); // mu(j, i)\n        sji =\n            sumsOfSquares[i] - sumsOfSquares[j - 1] - (i - j + 1) * muji * muji;\n    } else {\n        sji = sumsOfSquares[i] - (sums[i] * sums[i]) / (i + 1);\n    }\n    if (sji < 0) {\n        return 0;\n    }\n    return sji;\n}\n\n/**\n * Function that recursively divides and conquers computations\n * for cluster j\n *\n * @private\n * @param {number} iMin Minimum index in cluster to be computed\n * @param {number} iMax Maximum index in cluster to be computed\n * @param {number} cluster Index of the cluster currently being computed\n * @param {Array<Array<number>>} matrix\n * @param {Array<Array<number>>} backtrackMatrix\n * @param {Array<number>} sums\n * @param {Array<number>} sumsOfSquares\n */\nfunction fillMatrixColumn(\n    iMin,\n    iMax,\n    cluster,\n    matrix,\n    backtrackMatrix,\n    sums,\n    sumsOfSquares\n) {\n    if (iMin > iMax) {\n        return;\n    }\n\n    // Start at midpoint between iMin and iMax\n    const i = Math.floor((iMin + iMax) / 2);\n\n    matrix[cluster][i] = matrix[cluster - 1][i - 1];\n    backtrackMatrix[cluster][i] = i;\n\n    let jlow = cluster; // the lower end for j\n\n    if (iMin > cluster) {\n        jlow = Math.max(jlow, backtrackMatrix[cluster][iMin - 1] || 0);\n    }\n    jlow = Math.max(jlow, backtrackMatrix[cluster - 1][i] || 0);\n\n    let jhigh = i - 1; // the upper end for j\n    if (iMax < matrix[0].length - 1) {\n        /* c8 ignore start */\n        jhigh = Math.min(jhigh, backtrackMatrix[cluster][iMax + 1] || 0);\n        /* c8 ignore end */\n    }\n\n    let sji;\n    let sjlowi;\n    let ssqjlow;\n    let ssqj;\n    for (let j = jhigh; j >= jlow; --j) {\n        sji = ssq(j, i, sums, sumsOfSquares);\n\n        if (sji + matrix[cluster - 1][jlow - 1] >= matrix[cluster][i]) {\n            break;\n        }\n\n        // Examine the lower bound of the cluster border\n        sjlowi = ssq(jlow, i, sums, sumsOfSquares);\n\n        ssqjlow = sjlowi + matrix[cluster - 1][jlow - 1];\n\n        if (ssqjlow < matrix[cluster][i]) {\n            // Shrink the lower bound\n            matrix[cluster][i] = ssqjlow;\n            backtrackMatrix[cluster][i] = jlow;\n        }\n        jlow++;\n\n        ssqj = sji + matrix[cluster - 1][j - 1];\n        if (ssqj < matrix[cluster][i]) {\n            matrix[cluster][i] = ssqj;\n            backtrackMatrix[cluster][i] = j;\n        }\n    }\n\n    fillMatrixColumn(\n        iMin,\n        i - 1,\n        cluster,\n        matrix,\n        backtrackMatrix,\n        sums,\n        sumsOfSquares\n    );\n    fillMatrixColumn(\n        i + 1,\n        iMax,\n        cluster,\n        matrix,\n        backtrackMatrix,\n        sums,\n        sumsOfSquares\n    );\n}\n\n/**\n * Initializes the main matrices used in Ckmeans and kicks\n * off the divide and conquer cluster computation strategy\n *\n * @private\n * @param {Array<number>} data sorted array of values\n * @param {Array<Array<number>>} matrix\n * @param {Array<Array<number>>} backtrackMatrix\n */\nfunction fillMatrices(data, matrix, backtrackMatrix) {\n    const nValues = matrix[0].length;\n\n    // Shift values by the median to improve numeric stability\n    const shift = data[Math.floor(nValues / 2)];\n\n    // Cumulative sum and cumulative sum of squares for all values in data array\n    const sums = [];\n    const sumsOfSquares = [];\n\n    // Initialize first column in matrix & backtrackMatrix\n    for (let i = 0, shiftedValue; i < nValues; ++i) {\n        shiftedValue = data[i] - shift;\n        if (i === 0) {\n            sums.push(shiftedValue);\n            sumsOfSquares.push(shiftedValue * shiftedValue);\n        } else {\n            sums.push(sums[i - 1] + shiftedValue);\n            sumsOfSquares.push(\n                sumsOfSquares[i - 1] + shiftedValue * shiftedValue\n            );\n        }\n\n        // Initialize for cluster = 0\n        matrix[0][i] = ssq(0, i, sums, sumsOfSquares);\n        backtrackMatrix[0][i] = 0;\n    }\n\n    // Initialize the rest of the columns\n    let iMin;\n    for (let cluster = 1; cluster < matrix.length; ++cluster) {\n        if (cluster < matrix.length - 1) {\n            iMin = cluster;\n        } else {\n            // No need to compute matrix[K-1][0] ... matrix[K-1][N-2]\n            iMin = nValues - 1;\n        }\n\n        fillMatrixColumn(\n            iMin,\n            nValues - 1,\n            cluster,\n            matrix,\n            backtrackMatrix,\n            sums,\n            sumsOfSquares\n        );\n    }\n}\n\n/**\n * Ckmeans clustering is an improvement on heuristic-based clustering\n * approaches like Jenks. The algorithm was developed in\n * [Haizhou Wang and Mingzhou Song](http://journal.r-project.org/archive/2011-2/RJournal_2011-2_Wang+Song.pdf)\n * as a [dynamic programming](https://en.wikipedia.org/wiki/Dynamic_programming) approach\n * to the problem of clustering numeric data into groups with the least\n * within-group sum-of-squared-deviations.\n *\n * Minimizing the difference within groups - what Wang & Song refer to as\n * `withinss`, or within sum-of-squares, means that groups are optimally\n * homogenous within and the data is split into representative groups.\n * This is very useful for visualization, where you may want to represent\n * a continuous variable in discrete color or style groups. This function\n * can provide groups that emphasize differences between data.\n *\n * Being a dynamic approach, this algorithm is based on two matrices that\n * store incrementally-computed values for squared deviations and backtracking\n * indexes.\n *\n * This implementation is based on Ckmeans 3.4.6, which introduced a new divide\n * and conquer approach that improved runtime from O(kn^2) to O(kn log(n)).\n *\n * Unlike the [original implementation](https://cran.r-project.org/web/packages/Ckmeans.1d.dp/index.html),\n * this implementation does not include any code to automatically determine\n * the optimal number of clusters: this information needs to be explicitly\n * provided.\n *\n * ### References\n * _Ckmeans.1d.dp: Optimal k-means Clustering in One Dimension by Dynamic\n * Programming_ Haizhou Wang and Mingzhou Song ISSN 2073-4859\n *\n * from The R Journal Vol. 3/2, December 2011\n * @param {Array<number>} x input data, as an array of number values\n * @param {number} nClusters number of desired classes. This cannot be\n * greater than the number of values in the data array.\n * @returns {Array<Array<number>>} clustered input\n * @throws {Error} if the number of requested clusters is higher than the size of the data\n * @example\n * ckmeans([-1, 2, -1, 2, 4, 5, 6, -1, 2, -1], 3);\n * // The input, clustered into groups of similar numbers.\n * //= [[-1, -1, -1, -1], [2, 2, 2], [4, 5, 6]]);\n */\nfunction ckmeans(x, nClusters) {\n    if (nClusters > x.length) {\n        throw new Error(\n            \"cannot generate more classes than there are data values\"\n        );\n    }\n\n    const sorted = numericSort(x);\n    // we'll use this as the maximum number of clusters\n    const uniqueCount = uniqueCountSorted(sorted);\n\n    // if all of the input values are identical, there's one cluster\n    // with all of the input in it.\n    if (uniqueCount === 1) {\n        return [sorted];\n    }\n\n    // named 'S' originally\n    const matrix = makeMatrix(nClusters, sorted.length);\n    // named 'J' originally\n    const backtrackMatrix = makeMatrix(nClusters, sorted.length);\n\n    // This is a dynamic programming way to solve the problem of minimizing\n    // within-cluster sum of squares. It's similar to linear regression\n    // in this way, and this calculation incrementally computes the\n    // sum of squares that are later read.\n    fillMatrices(sorted, matrix, backtrackMatrix);\n\n    // The real work of Ckmeans clustering happens in the matrix generation:\n    // the generated matrices encode all possible clustering combinations, and\n    // once they're generated we can solve for the best clustering groups\n    // very quickly.\n    const clusters = [];\n    let clusterRight = backtrackMatrix[0].length - 1;\n\n    // Backtrack the clusters from the dynamic programming matrix. This\n    // starts at the bottom-right corner of the matrix (if the top-left is 0, 0),\n    // and moves the cluster target with the loop.\n    for (let cluster = backtrackMatrix.length - 1; cluster >= 0; cluster--) {\n        const clusterLeft = backtrackMatrix[cluster][clusterRight];\n\n        // fill the cluster from the sorted input by taking a slice of the\n        // array. the backtrack matrix makes this easy - it stores the\n        // indexes where the cluster should start and end.\n        clusters[cluster] = sorted.slice(clusterLeft, clusterRight + 1);\n\n        if (cluster > 0) {\n            clusterRight = clusterLeft - 1;\n        }\n    }\n\n    return clusters;\n}\n\nexport default ckmeans;\n", "/*\n * Pull Breaks Values for Jenks\n *\n * the second part of the jenks recipe: take the calculated matrices\n * and derive an array of n breaks.\n *\n * @private\n */\nfunction jenksBreaks(data, lowerClassLimits, nClasses) {\n    let k = data.length;\n    const kclass = [];\n    let countNum = nClasses;\n\n    // the calculation of classes will never include the upper\n    // bound, so we need to explicitly set it\n    kclass[nClasses] = data[data.length - 1];\n\n    // the lowerClassLimits matrix is used as indices into itself\n    // here: the `k` variable is reused in each iteration.\n    while (countNum > 0) {\n        kclass[countNum - 1] = data[lowerClassLimits[k][countNum] - 1];\n        k = lowerClassLimits[k][countNum] - 1;\n        countNum--;\n    }\n\n    return kclass;\n}\n\nexport default jenksBreaks;\n", "/*\n * Compute Matrices for Jenks\n *\n * Compute the matrices required for Jenks breaks. These matrices\n * can be used for any classing of data with `classes <= nClasses`\n *\n * @private\n */\nfunction jenksMatrices(data, nClasses) {\n    // in the original implementation, these matrices are referred to\n    // as `LC` and `OP`\n    //\n    // * lowerClassLimits (LC): optimal lower class limits\n    // * varianceCombinations (OP): optimal variance combinations for all classes\n    const lowerClassLimits = [];\n    const varianceCombinations = [];\n    // loop counters\n    let i;\n    let j;\n    // the variance, as computed at each step in the calculation\n    let variance = 0;\n\n    // Initialize and fill each matrix with zeroes\n    for (i = 0; i < data.length + 1; i++) {\n        const tmp1 = [];\n        const tmp2 = [];\n        // despite these arrays having the same values, we need\n        // to keep them separate so that changing one does not change\n        // the other\n        for (j = 0; j < nClasses + 1; j++) {\n            tmp1.push(0);\n            tmp2.push(0);\n        }\n        lowerClassLimits.push(tmp1);\n        varianceCombinations.push(tmp2);\n    }\n\n    for (i = 1; i < nClasses + 1; i++) {\n        lowerClassLimits[1][i] = 1;\n        varianceCombinations[1][i] = 0;\n        // in the original implementation, 9999999 is used but\n        // since Javascript has `Infinity`, we use that.\n        for (j = 2; j < data.length + 1; j++) {\n            varianceCombinations[j][i] = Number.POSITIVE_INFINITY;\n        }\n    }\n\n    for (let l = 2; l < data.length + 1; l++) {\n        // `SZ` originally. this is the sum of the values seen thus\n        // far when calculating variance.\n        let sum = 0;\n        // `ZSQ` originally. the sum of squares of values seen\n        // thus far\n        let sumSquares = 0;\n        // `WT` originally. This is the number of\n        let w = 0;\n        // `IV` originally\n        let i4 = 0;\n\n        // in several instances, you could say `Math.pow(x, 2)`\n        // instead of `x * x`, but this is slower in some browsers\n        // introduces an unnecessary concept.\n        for (let m = 1; m < l + 1; m++) {\n            // `III` originally\n            const lowerClassLimit = l - m + 1;\n            const val = data[lowerClassLimit - 1];\n\n            // here we're estimating variance for each potential classing\n            // of the data, for each potential number of classes. `w`\n            // is the number of data points considered so far.\n            w++;\n\n            // increase the current sum and sum-of-squares\n            sum += val;\n            sumSquares += val * val;\n\n            // the variance at this point in the sequence is the difference\n            // between the sum of squares and the total x 2, over the number\n            // of samples.\n            variance = sumSquares - (sum * sum) / w;\n\n            i4 = lowerClassLimit - 1;\n\n            if (i4 !== 0) {\n                for (j = 2; j < nClasses + 1; j++) {\n                    // if adding this element to an existing class\n                    // will increase its variance beyond the limit, break\n                    // the class at this point, setting the `lowerClassLimit`\n                    // at this point.\n                    if (\n                        varianceCombinations[l][j] >=\n                        variance + varianceCombinations[i4][j - 1]\n                    ) {\n                        lowerClassLimits[l][j] = lowerClassLimit;\n                        varianceCombinations[l][j] =\n                            variance + varianceCombinations[i4][j - 1];\n                    }\n                }\n            }\n        }\n\n        lowerClassLimits[l][1] = 1;\n        varianceCombinations[l][1] = variance;\n    }\n\n    // return the two matrices. for just providing breaks, only\n    // `lowerClassLimits` is needed, but variances can be useful to\n    // evaluate goodness of fit.\n    return {\n        lowerClassLimits: lowerClassLimits,\n        varianceCombinations: varianceCombinations\n    };\n}\n\nexport default jenksMatrices;\n", "import jenksBreaks from \"./jenks_breaks.js\";\nimport jenksMatrices from \"./jenks_matrices.js\";\n\n/**\n * The **[jenks natural breaks optimization](http://en.wikipedia.org/wiki/Jenks_natural_breaks_optimization)**\n * is an algorithm commonly used in cartography and visualization to decide\n * upon groupings of data values that minimize variance within themselves\n * and maximize variation between themselves.\n *\n * For instance, cartographers often use jenks in order to choose which\n * values are assigned to which colors in a [choropleth](https://en.wikipedia.org/wiki/Choropleth_map)\n * map.\n *\n * @param {Array<number>} data input data, as an array of number values\n * @param {number} nClasses number of desired classes\n * @returns {Array<number>} array of class break positions\n * // split data into 3 break points\n * jenks([1, 2, 4, 5, 7, 9, 10, 20], 3) // = [1, 7, 20, 20]\n */\nfunction jenks(data, nClasses) {\n    if (nClasses > data.length) {\n        return null;\n    }\n\n    // sort data in numerical order, since this is expected\n    // by the matrices function\n    data = data.slice().sort(function (a, b) {\n        return a - b;\n    });\n\n    // get our basic matrices\n    const matrices = jenksMatrices(data, nClasses);\n    // we only need lower class limits here\n    const lowerClassLimits = matrices.lowerClassLimits;\n\n    // extract nClasses out of the computed matrices\n    return jenksBreaks(data, lowerClassLimits, nClasses);\n}\n\nexport default jenks;\n", "import max from \"./max.js\";\nimport min from \"./min.js\";\n\n/**\n * Given an array of x, this will find the extent of the\n * x and return an array of breaks that can be used\n * to categorize the x into a number of classes. The\n * returned array will always be 1 longer than the number of\n * classes because it includes the minimum value.\n *\n * @param {Array<number>} x an array of number values\n * @param {number} nClasses number of desired classes\n * @returns {Array<number>} array of class break positions\n * @example\n * equalIntervalBreaks([1, 2, 3, 4, 5, 6], 4); // => [1, 2.25, 3.5, 4.75, 6]\n */\nfunction equalIntervalBreaks(x, nClasses) {\n    if (x.length < 2) {\n        return x;\n    }\n\n    const theMin = min(x);\n    const theMax = max(x);\n\n    // the first break will always be the minimum value\n    // in the xset\n    const breaks = [theMin];\n\n    // The size of each break is the full range of the x\n    // divided by the number of classes requested\n    const breakSize = (theMax - theMin) / nClasses;\n\n    // In the case of nClasses = 1, this loop won't run\n    // and the returned breaks will be [min, max]\n    for (let i = 1; i < nClasses; i++) {\n        breaks.push(breaks[0] + breakSize * i);\n    }\n\n    // the last break will always be the\n    // maximum.\n    breaks.push(theMax);\n\n    return breaks;\n}\n\nexport default equalIntervalBreaks;\n", "import mean from \"./mean.js\";\n\n/**\n * [Sample covariance](https://en.wikipedia.org/wiki/Sample_mean_and_covariance) of two datasets:\n * how much do the two datasets move together?\n * x and y are two datasets, represented as arrays of numbers.\n *\n * @param {Array<number>} x a sample of two or more data points\n * @param {Array<number>} y a sample of two or more data points\n * @throws {Error} if x and y do not have equal lengths\n * @throws {Error} if x or y have length of one or less\n * @returns {number} sample covariance\n * @example\n * sampleCovariance([1, 2, 3, 4, 5, 6], [6, 5, 4, 3, 2, 1]); // => -3.5\n */\nfunction sampleCovariance(x, y) {\n    // The two datasets must have the same length which must be more than 1\n    if (x.length !== y.length) {\n        throw new Error(\"sampleCovariance requires samples with equal lengths\");\n    }\n\n    if (x.length < 2) {\n        throw new Error(\n            \"sampleCovariance requires at least two data points in each sample\"\n        );\n    }\n\n    // determine the mean of each dataset so that we can judge each\n    // value of the dataset fairly as the difference from the mean. this\n    // way, if one dataset is [1, 2, 3] and [2, 3, 4], their covariance\n    // does not suffer because of the difference in absolute values\n    const xmean = mean(x);\n    const ymean = mean(y);\n    let sum = 0;\n\n    // for each pair of values, the covariance increases when their\n    // difference from the mean is associated - if both are well above\n    // or if both are well below\n    // the mean, the covariance increases significantly.\n    for (let i = 0; i < x.length; i++) {\n        sum += (x[i] - xmean) * (y[i] - ymean);\n    }\n\n    // this is Bessels' Correction: an adjustment made to sample statistics\n    // that allows for the reduced degree of freedom entailed in calculating\n    // values from samples rather than complete populations.\n    const besselsCorrection = x.length - 1;\n\n    // the covariance is weighted by the length of the datasets.\n    return sum / besselsCorrection;\n}\n\nexport default sampleCovariance;\n", "import sumNthPowerDeviations from \"./sum_nth_power_deviations.js\";\n\n/**\n * The [sample variance](https://en.wikipedia.org/wiki/Variance#Sample_variance)\n * is the sum of squared deviations from the mean. The sample variance\n * is distinguished from the variance by the usage of [Bessel's Correction](https://en.wikipedia.org/wiki/Bessel's_correction):\n * instead of dividing the sum of squared deviations by the length of the input,\n * it is divided by the length minus one. This corrects the bias in estimating\n * a value from a set that you don't know if full.\n *\n * References:\n * * [Wolfram MathWorld on Sample Variance](http://mathworld.wolfram.com/SampleVariance.html)\n *\n * @param {Array<number>} x a sample of two or more data points\n * @throws {Error} if the length of x is less than 2\n * @return {number} sample variance\n * @example\n * sampleVariance([1, 2, 3, 4, 5]); // => 2.5\n */\nfunction sampleVariance(x) {\n    if (x.length < 2) {\n        throw new Error(\"sampleVariance requires at least two data points\");\n    }\n\n    const sumSquaredDeviationsValue = sumNthPowerDeviations(x, 2);\n\n    // this is Bessels' Correction: an adjustment made to sample statistics\n    // that allows for the reduced degree of freedom entailed in calculating\n    // values from samples rather than complete populations.\n    const besselsCorrection = x.length - 1;\n\n    // Find the mean value of that list\n    return sumSquaredDeviationsValue / besselsCorrection;\n}\n\nexport default sampleVariance;\n", "import sampleVariance from \"./sample_variance.js\";\n\n/**\n * The [sample standard deviation](http://en.wikipedia.org/wiki/Standard_deviation#Sample_standard_deviation)\n * is the square root of the sample variance.\n *\n * @param {Array<number>} x input array\n * @returns {number} sample standard deviation\n * @example\n * sampleStandardDeviation([2, 4, 4, 4, 5, 5, 7, 9]).toFixed(2);\n * // => '2.14'\n */\nfunction sampleStandardDeviation(x) {\n    const sampleVarianceX = sampleVariance(x);\n    return Math.sqrt(sampleVarianceX);\n}\n\nexport default sampleStandardDeviation;\n", "import sampleCovariance from \"./sample_covariance.js\";\nimport sampleStandardDeviation from \"./sample_standard_deviation.js\";\n\n/**\n * The [correlation](http://en.wikipedia.org/wiki/Correlation_and_dependence) is\n * a measure of how correlated two datasets are, between -1 and 1\n *\n * @param {Array<number>} x first input\n * @param {Array<number>} y second input\n * @returns {number} sample correlation\n * @example\n * sampleCorrelation([1, 2, 3, 4, 5, 6], [2, 2, 3, 4, 5, 60]).toFixed(2);\n * // => '0.69'\n */\nfunction sampleCorrelation(x, y) {\n    const cov = sampleCovariance(x, y);\n    const xstd = sampleStandardDeviation(x);\n    const ystd = sampleStandardDeviation(y);\n\n    return cov / xstd / ystd;\n}\n\nexport default sampleCorrelation;\n", "import sampleCorrelation from \"./sample_correlation.js\";\n\n/**\n * The [rank correlation](https://en.wikipedia.org/wiki/Rank_correlation) is\n * a measure of the strength of monotonic relationship between two arrays\n *\n * @param {Array<number>} x first input\n * @param {Array<number>} y second input\n * @returns {number} sample rank correlation\n */\nfunction sampleRankCorrelation(x, y) {\n    const xIndexes = x\n        .map((value, index) => [value, index])\n        .sort((a, b) => a[0] - b[0])\n        .map((pair) => pair[1]);\n    const yIndexes = y\n        .map((value, index) => [value, index])\n        .sort((a, b) => a[0] - b[0])\n        .map((pair) => pair[1]);\n\n    // At this step, we have an array of indexes\n    // that map from sorted numbers to their original indexes. We reverse\n    // that so that it is an array of the sorted destination index.\n    const xRanks = Array(xIndexes.length);\n    const yRanks = Array(xIndexes.length);\n    for (let i = 0; i < xIndexes.length; i++) {\n        xRanks[xIndexes[i]] = i;\n        yRanks[yIndexes[i]] = i;\n    }\n\n    return sampleCorrelation(xRanks, yRanks);\n}\n\nexport default sampleRankCorrelation;\n", "import mean from \"./mean.js\";\n\n/**\n * [Skewness](http://en.wikipedia.org/wiki/Skewness) is\n * a measure of the extent to which a probability distribution of a\n * real-valued random variable \"leans\" to one side of the mean.\n * The skewness value can be positive or negative, or even undefined.\n *\n * Implementation is based on the adjusted Fisher-Pearson standardized\n * moment coefficient, which is the version found in Excel and several\n * statistical packages including Minitab, SAS and SPSS.\n *\n * @since 4.1.0\n * @param {Array<number>} x a sample of 3 or more data points\n * @returns {number} sample skewness\n * @throws {Error} if x has length less than 3\n * @example\n * sampleSkewness([2, 4, 6, 3, 1]); // => 0.590128656384365\n */\nfunction sampleSkewness(x) {\n    if (x.length < 3) {\n        throw new Error(\"sampleSkewness requires at least three data points\");\n    }\n\n    const meanValue = mean(x);\n    let tempValue;\n    let sumSquaredDeviations = 0;\n    let sumCubedDeviations = 0;\n\n    for (let i = 0; i < x.length; i++) {\n        tempValue = x[i] - meanValue;\n        sumSquaredDeviations += tempValue * tempValue;\n        sumCubedDeviations += tempValue * tempValue * tempValue;\n    }\n\n    // this is Bessels' Correction: an adjustment made to sample statistics\n    // that allows for the reduced degree of freedom entailed in calculating\n    // values from samples rather than complete populations.\n    const besselsCorrection = x.length - 1;\n\n    // Find the mean value of that list\n    const theSampleStandardDeviation = Math.sqrt(\n        sumSquaredDeviations / besselsCorrection\n    );\n\n    const n = x.length;\n    const cubedS = Math.pow(theSampleStandardDeviation, 3);\n\n    return (n * sumCubedDeviations) / ((n - 1) * (n - 2) * cubedS);\n}\n\nexport default sampleSkewness;\n", "import mean from \"./mean.js\";\n\n/**\n * [Kurtosis](http://en.wikipedia.org/wiki/Kurtosis) is\n * a measure of the heaviness of a distribution's tails relative to its\n * variance. The kurtosis value can be positive or negative, or even undefined.\n *\n * Implementation is based on Fisher's excess kurtosis definition and uses\n * unbiased moment estimators. This is the version found in Excel and available\n * in several statistical packages, including SAS and SciPy.\n *\n * @param {Array<number>} x a sample of 4 or more data points\n * @returns {number} sample kurtosis\n * @throws {Error} if x has length less than 4\n * @example\n * sampleKurtosis([1, 2, 2, 3, 5]); // => 1.4555765595463122\n */\nfunction sampleKurtosis(x) {\n    const n = x.length;\n\n    if (n < 4) {\n        throw new Error(\"sampleKurtosis requires at least four data points\");\n    }\n\n    const meanValue = mean(x);\n    let tempValue;\n    let secondCentralMoment = 0;\n    let fourthCentralMoment = 0;\n\n    for (let i = 0; i < n; i++) {\n        tempValue = x[i] - meanValue;\n        secondCentralMoment += tempValue * tempValue;\n        fourthCentralMoment += tempValue * tempValue * tempValue * tempValue;\n    }\n\n    return (\n        ((n - 1) / ((n - 2) * (n - 3))) *\n        ((n * (n + 1) * fourthCentralMoment) /\n            (secondCentralMoment * secondCentralMoment) -\n            3 * (n - 1))\n    );\n}\n\nexport default sampleKurtosis;\n", "/**\n * Implementation of [Heap's Algorithm](https://en.wikipedia.org/wiki/Heap%27s_algorithm)\n * for generating permutations.\n *\n * @param {Array} elements any type of data\n * @returns {Array<Array>} array of permutations\n */\nfunction permutationsHeap(elements) {\n    const indexes = new Array(elements.length);\n    const permutations = [elements.slice()];\n\n    for (let i = 0; i < elements.length; i++) {\n        indexes[i] = 0;\n    }\n\n    for (let i = 0; i < elements.length; ) {\n        if (indexes[i] < i) {\n            // At odd indexes, swap from indexes[i] instead\n            // of from the beginning of the array\n            let swapFrom = 0;\n            if (i % 2 !== 0) {\n                swapFrom = indexes[i];\n            }\n\n            // swap between swapFrom and i, using\n            // a temporary variable as storage.\n            const temp = elements[swapFrom];\n            elements[swapFrom] = elements[i];\n            elements[i] = temp;\n\n            permutations.push(elements.slice());\n            indexes[i]++;\n            i = 0;\n        } else {\n            indexes[i] = 0;\n            i++;\n        }\n    }\n\n    return permutations;\n}\n\nexport default permutationsHeap;\n", "/**\n * Implementation of Combinations\n * Combinations are unique subsets of a collection - in this case, k x from a collection at a time.\n * https://en.wikipedia.org/wiki/Combination\n * @param {Array} x any type of data\n * @param {int} k the number of objects in each group (without replacement)\n * @returns {Array<Array>} array of permutations\n * @example\n * combinations([1, 2, 3], 2); // => [[1,2], [1,3], [2,3]]\n */\n\nfunction combinations(x, k) {\n    let i;\n    let subI;\n    const combinationList = [];\n    let subsetCombinations;\n    let next;\n\n    for (i = 0; i < x.length; i++) {\n        if (k === 1) {\n            combinationList.push([x[i]]);\n        } else {\n            subsetCombinations = combinations(x.slice(i + 1, x.length), k - 1);\n            for (subI = 0; subI < subsetCombinations.length; subI++) {\n                next = subsetCombinations[subI];\n                next.unshift(x[i]);\n                combinationList.push(next);\n            }\n        }\n    }\n    return combinationList;\n}\n\nexport default combinations;\n", "/**\n * Implementation of [Combinations](https://en.wikipedia.org/wiki/Combination) with replacement\n * Combinations are unique subsets of a collection - in this case, k x from a collection at a time.\n * 'With replacement' means that a given element can be chosen multiple times.\n * Unlike permutation, order doesn't matter for combinations.\n *\n * @param {Array} x any type of data\n * @param {int} k the number of objects in each group (without replacement)\n * @returns {Array<Array>} array of permutations\n * @example\n * combinationsReplacement([1, 2], 2); // => [[1, 1], [1, 2], [2, 2]]\n */\nfunction combinationsReplacement(x, k) {\n    const combinationList = [];\n\n    for (let i = 0; i < x.length; i++) {\n        if (k === 1) {\n            // If we're requested to find only one element, we don't need\n            // to recurse: just push `x[i]` onto the list of combinations.\n            combinationList.push([x[i]]);\n        } else {\n            // Otherwise, recursively find combinations, given `k - 1`. Note that\n            // we request `k - 1`, so if you were looking for k=3 combinations, we're\n            // requesting k=2. This -1 gets reversed in the for loop right after this\n            // code, since we concatenate `x[i]` onto the selected combinations,\n            // bringing `k` back up to your requested level.\n            // This recursion may go many levels deep, since it only stops once\n            // k=1.\n            const subsetCombinations = combinationsReplacement(\n                x.slice(i, x.length),\n                k - 1\n            );\n\n            for (let j = 0; j < subsetCombinations.length; j++) {\n                combinationList.push([x[i]].concat(subsetCombinations[j]));\n            }\n        }\n    }\n\n    return combinationList;\n}\n\nexport default combinationsReplacement;\n", "/**\n * When adding a new value to a list, one does not have to necessary\n * recompute the mean of the list in linear time. They can instead use\n * this function to compute the new mean by providing the current mean,\n * the number of elements in the list that produced it and the new\n * value to add.\n *\n * @since 2.5.0\n * @param {number} mean current mean\n * @param {number} n number of items in the list\n * @param {number} newValue the added value\n * @returns {number} the new mean\n *\n * @example\n * addToMean(14, 5, 53); // => 20.5\n */\nfunction addToMean(mean, n, newValue) {\n    return mean + (newValue - mean) / (n + 1);\n}\n\nexport default addToMean;\n", "/**\n * When combining two lists of values for which one already knows the means,\n * one does not have to necessary recompute the mean of the combined lists in\n * linear time. They can instead use this function to compute the combined\n * mean by providing the mean & number of values of the first list and the mean\n * & number of values of the second list.\n *\n * @since 3.0.0\n * @param {number} mean1 mean of the first list\n * @param {number} n1 number of items in the first list\n * @param {number} mean2 mean of the second list\n * @param {number} n2 number of items in the second list\n * @returns {number} the combined mean\n *\n * @example\n * combineMeans(5, 3, 4, 3); // => 4.5\n */\nfunction combineMeans(mean1, n1, mean2, n2) {\n    return (mean1 * n1 + mean2 * n2) / (n1 + n2);\n}\n\nexport default combineMeans;\n", "import combineMeans from \"./combine_means.js\";\n\n/**\n * When combining two lists of values for which one already knows the variances,\n * one does not have to necessary recompute the variance of the combined lists\n * in linear time. They can instead use this function to compute the combined\n * variance by providing the variance, mean & number of values of the first list\n * and the variance, mean & number of values of the second list.\n *\n * @since 3.0.0\n * @param {number} variance1 variance of the first list\n * @param {number} mean1 mean of the first list\n * @param {number} n1 number of items in the first list\n * @param {number} variance2 variance of the second list\n * @param {number} mean2 mean of the second list\n * @param {number} n2 number of items in the second list\n * @returns {number} the combined mean\n *\n * @example\n * combineVariances(14 / 3, 5, 3, 8 / 3, 4, 3); // => 47 / 12\n */\nfunction combineVariances(variance1, mean1, n1, variance2, mean2, n2) {\n    const newMean = combineMeans(mean1, n1, mean2, n2);\n\n    return (\n        (n1 * (variance1 + Math.pow(mean1 - newMean, 2)) +\n            n2 * (variance2 + Math.pow(mean2 - newMean, 2))) /\n        (n1 + n2)\n    );\n}\n\nexport default combineVariances;\n", "/**\n * The [Geometric Mean](https://en.wikipedia.org/wiki/Geometric_mean) is\n * a mean function that is more useful for numbers in different\n * ranges.\n *\n * This is the nth root of the input numbers multiplied by each other.\n *\n * The geometric mean is often useful for\n * **[proportional growth](https://en.wikipedia.org/wiki/Geometric_mean#Proportional_growth)**: given\n * growth rates for multiple years, like _80%, 16.66% and 42.85%_, a simple\n * mean will incorrectly estimate an average growth rate, whereas a geometric\n * mean will correctly estimate a growth rate that, over those years,\n * will yield the same end value.\n *\n * This runs in `O(n)`, linear time, with respect to the length of the array.\n *\n * @param {Array<number>} x sample of one or more data points\n * @returns {number} geometric mean\n * @throws {Error} if x is empty\n * @throws {Error} if x contains a negative number\n * @example\n * var growthRates = [1.80, 1.166666, 1.428571];\n * var averageGrowth = ss.geometricMean(growthRates);\n * var averageGrowthRates = [averageGrowth, averageGrowth, averageGrowth];\n * var startingValue = 10;\n * var startingValueMean = 10;\n * growthRates.forEach(function(rate) {\n *   startingValue *= rate;\n * });\n * averageGrowthRates.forEach(function(rate) {\n *   startingValueMean *= rate;\n * });\n * startingValueMean === startingValue;\n */\nfunction geometricMean(x) {\n    if (x.length === 0) {\n        throw new Error(\"geometricMean requires at least one data point\");\n    }\n\n    // the starting value.\n    let value = 1;\n\n    for (let i = 0; i < x.length; i++) {\n        // the geometric mean is only valid for positive numbers\n        if (x[i] < 0) {\n            throw new Error(\n                \"geometricMean requires only non-negative numbers as input\"\n            );\n        }\n\n        // repeatedly multiply the value by each number\n        value *= x[i];\n    }\n\n    return Math.pow(value, 1 / x.length);\n}\n\nexport default geometricMean;\n", "/**\n * The [log average](https://en.wikipedia.org/wiki/https://en.wikipedia.org/wiki/Geometric_mean#Relationship_with_logarithms)\n * is an equivalent way of computing the geometric mean of an array suitable for large or small products.\n *\n * It's found by calculating the average logarithm of the elements and exponentiating.\n *\n * @param {Array<number>} x sample of one or more data points\n * @returns {number} geometric mean\n * @throws {Error} if x is empty\n * @throws {Error} if x contains a negative number\n */\nfunction logAverage(x) {\n    if (x.length === 0) {\n        throw new Error(\"logAverage requires at least one data point\");\n    }\n\n    let value = 0;\n    for (let i = 0; i < x.length; i++) {\n        if (x[i] < 0) {\n            throw new Error(\n                \"logAverage requires only non-negative numbers as input\"\n            );\n        }\n        value += Math.log(x[i]);\n    }\n\n    return Math.exp(value / x.length);\n}\n\nexport default logAverage;\n", "/**\n * The [Harmonic Mean](https://en.wikipedia.org/wiki/Harmonic_mean) is\n * a mean function typically used to find the average of rates.\n * This mean is calculated by taking the reciprocal of the arithmetic mean\n * of the reciprocals of the input numbers.\n *\n * This is a [measure of central tendency](https://en.wikipedia.org/wiki/Central_tendency):\n * a method of finding a typical or central value of a set of numbers.\n *\n * This runs in `O(n)`, linear time, with respect to the length of the array.\n *\n * @param {Array<number>} x sample of one or more data points\n * @returns {number} harmonic mean\n * @throws {Error} if x is empty\n * @throws {Error} if x contains a negative number\n * @example\n * harmonicMean([2, 3]).toFixed(2) // => '2.40'\n */\nfunction harmonicMean(x) {\n    if (x.length === 0) {\n        throw new Error(\"harmonicMean requires at least one data point\");\n    }\n\n    let reciprocalSum = 0;\n\n    for (let i = 0; i < x.length; i++) {\n        // the harmonic mean is only valid for positive numbers\n        if (x[i] <= 0) {\n            throw new Error(\n                \"harmonicMean requires only positive numbers as input\"\n            );\n        }\n\n        reciprocalSum += 1 / x[i];\n    }\n\n    // divide n by the reciprocal sum\n    return x.length / reciprocalSum;\n}\n\nexport default harmonicMean;\n", "import sumSimple from \"./sum_simple.js\";\n\n/**\n * The mean, _also known as average_,\n * is the sum of all values over the number of values.\n * This is a [measure of central tendency](https://en.wikipedia.org/wiki/Central_tendency):\n * a method of finding a typical or central value of a set of numbers.\n *\n * The simple mean uses the successive addition method internally\n * to calculate it's result. Errors in floating-point addition are\n * not accounted for, so if precision is required, the standard {@link mean}\n * method should be used instead.\n *\n * This runs in `O(n)`, linear time, with respect to the length of the array.\n *\n *\n * @param {Array<number>} x sample of one or more data points\n * @throws {Error} if the length of x is less than one\n * @returns {number} mean\n * @example\n * mean([0, 10]); // => 5\n */\nfunction meanSimple(x) {\n    if (x.length === 0) {\n        throw new Error(\"meanSimple requires at least one data point\");\n    }\n\n    return sumSimple(x) / x.length;\n}\n\nexport default meanSimple;\n", "import quantileSorted from \"./quantile_sorted.js\";\n\n/**\n * The [median](http://en.wikipedia.org/wiki/Median) is\n * the middle number of a list. This is often a good indicator of 'the middle'\n * when there are outliers that skew the `mean()` value.\n * This is a [measure of central tendency](https://en.wikipedia.org/wiki/Central_tendency):\n * a method of finding a typical or central value of a set of numbers.\n *\n * The median isn't necessarily one of the elements in the list: the value\n * can be the average of two elements if the list has an even length\n * and the two central values are different.\n *\n * @param {Array<number>} sorted input\n * @returns {number} median value\n * @example\n * medianSorted([10, 2, 5, 100, 2, 1]); // => 52.5\n */\nfunction medianSorted(sorted) {\n    return quantileSorted(sorted, 0.5);\n}\n\nexport default medianSorted;\n", "/**\n * When removing a value from a list, one does not have to necessary\n * recompute the mean of the list in linear time. They can instead use\n * this function to compute the new mean by providing the current mean,\n * the number of elements in the list that produced it and the value to remove.\n *\n * @since 3.0.0\n * @param {number} mean current mean\n * @param {number} n number of items in the list\n * @param {number} value the value to remove\n * @returns {number} the new mean\n *\n * @example\n * subtractFromMean(20.5, 6, 53); // => 14\n */\nfunction subtractFromMean(mean, n, value) {\n    return (mean * n - value) / (n - 1);\n}\n\nexport default subtractFromMean;\n", "/**\n * The Root Mean Square (RMS) is\n * a mean function used as a measure of the magnitude of a set\n * of numbers, regardless of their sign.\n * This is the square root of the mean of the squares of the\n * input numbers.\n * This runs in `O(n)`, linear time, with respect to the length of the array.\n *\n * @param {Array<number>} x a sample of one or more data points\n * @returns {number} root mean square\n * @throws {Error} if x is empty\n * @example\n * rootMeanSquare([-1, 1, -1, 1]); // => 1\n */\nfunction rootMeanSquare(x) {\n    if (x.length === 0) {\n        throw new Error(\"rootMeanSquare requires at least one data point\");\n    }\n\n    let sumOfSquares = 0;\n    for (let i = 0; i < x.length; i++) {\n        sumOfSquares += Math.pow(x[i], 2);\n    }\n\n    return Math.sqrt(sumOfSquares / x.length);\n}\n\nexport default rootMeanSquare;\n", "import mean from \"./mean.js\";\nimport sampleStandardDeviation from \"./sample_standard_deviation.js\";\n\n/**\n * The`coefficient of variation`_ is the ratio of the standard deviation to the mean.\n * .._`coefficient of variation`: https://en.wikipedia.org/wiki/Coefficient_of_variation\n *\n *\n * @param {Array} x input\n * @returns {number} coefficient of variation\n * @example\n * coefficientOfVariation([1, 2, 3, 4]).toFixed(3); // => 0.516\n * coefficientOfVariation([1, 2, 3, 4, 5]).toFixed(3); // => 0.527\n * coefficientOfVariation([-1, 0, 1, 2, 3, 4]).toFixed(3); // => 1.247\n */\nfunction coefficientOfVariation(x) {\n    return sampleStandardDeviation(x) / mean(x);\n}\n\nexport default coefficientOfVariation;\n", "import mean from \"./mean.js\";\nimport standardDeviation from \"./standard_deviation.js\";\n\n/**\n * This is to compute [a one-sample t-test](https://en.wikipedia.org/wiki/Student%27s_t-test#One-sample_t-test), comparing the mean\n * of a sample to a known value, x.\n *\n * in this case, we're trying to determine whether the\n * population mean is equal to the value that we know, which is `x`\n * here. Usually the results here are used to look up a\n * [p-value](http://en.wikipedia.org/wiki/P-value), which, for\n * a certain level of significance, will let you determine that the\n * null hypothesis can or cannot be rejected.\n *\n * @param {Array<number>} x sample of one or more numbers\n * @param {number} expectedValue expected value of the population mean\n * @returns {number} value\n * @example\n * tTest([1, 2, 3, 4, 5, 6], 3.385).toFixed(2); // => '0.16'\n */\nfunction tTest(x, expectedValue) {\n    // The mean of the sample\n    const sampleMean = mean(x);\n\n    // The standard deviation of the sample\n    const sd = standardDeviation(x);\n\n    // Square root the length of the sample\n    const rootN = Math.sqrt(x.length);\n\n    // returning the t value\n    return (sampleMean - expectedValue) / (sd / rootN);\n}\n\nexport default tTest;\n", "import mean from \"./mean.js\";\nimport sampleVariance from \"./sample_variance.js\";\n\n/**\n * This is to compute [two sample t-test](http://en.wikipedia.org/wiki/Student's_t-test).\n * Tests whether \"mean(X)-mean(Y) = difference\", (\n * in the most common case, we often have `difference == 0` to test if two samples\n * are likely to be taken from populations with the same mean value) with\n * no prior knowledge on standard deviations of both samples\n * other than the fact that they have the same standard deviation.\n *\n * Usually the results here are used to look up a\n * [p-value](http://en.wikipedia.org/wiki/P-value), which, for\n * a certain level of significance, will let you determine that the\n * null hypothesis can or cannot be rejected.\n *\n * `diff` can be omitted if it equals 0.\n *\n * [This is used to reject](https://en.wikipedia.org/wiki/Exclusion_of_the_null_hypothesis)\n * a null hypothesis that the two populations that have been sampled into\n * `sampleX` and `sampleY` are equal to each other.\n *\n * @param {Array<number>} sampleX a sample as an array of numbers\n * @param {Array<number>} sampleY a sample as an array of numbers\n * @param {number} [difference=0]\n * @returns {number|null} test result\n *\n * @example\n * tTestTwoSample([1, 2, 3, 4], [3, 4, 5, 6], 0); // => -2.1908902300206643\n */\nfunction tTestTwoSample(sampleX, sampleY, difference) {\n    const n = sampleX.length;\n    const m = sampleY.length;\n\n    // If either sample doesn't actually have any values, we can't\n    // compute this at all, so we return `null`.\n    if (!n || !m) {\n        return null;\n    }\n\n    // default difference (mu) is zero\n    if (!difference) {\n        difference = 0;\n    }\n\n    const meanX = mean(sampleX);\n    const meanY = mean(sampleY);\n    const sampleVarianceX = sampleVariance(sampleX);\n    const sampleVarianceY = sampleVariance(sampleY);\n\n    if (\n        typeof meanX === \"number\" &&\n        typeof meanY === \"number\" &&\n        typeof sampleVarianceX === \"number\" &&\n        typeof sampleVarianceY === \"number\"\n    ) {\n        const weightedVariance =\n            ((n - 1) * sampleVarianceX + (m - 1) * sampleVarianceY) /\n            (n + m - 2);\n\n        return (\n            (meanX - meanY - difference) /\n            Math.sqrt(weightedVariance * (1 / n + 1 / m))\n        );\n    }\n}\n\nexport default tTestTwoSample;\n", "/**\n * This function calculates the Wilcoxon rank sum statistic for the first sample\n * with respect to the second. The Wilcoxon rank sum test is a non-parametric\n * alternative to the t-test which is equivalent to the\n * [Mann-Whitney U test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test).\n * The statistic is calculated by pooling all the observations together, ranking them,\n * and then summing the ranks associated with one of the samples. If this rank sum is\n * sufficiently large or small we reject the hypothesis that the two samples come\n * from the same distribution in favor of the alternative that one is shifted with\n * respect to the other.\n *\n * @param {Array<number>} sampleX a sample as an array of numbers\n * @param {Array<number>} sampleY a sample as an array of numbers\n * @returns {number} rank sum for sampleX\n *\n * @example\n * wilcoxonRankSum([1, 4, 8], [9, 12, 15]); // => 6\n */\nfunction wilcoxonRankSum(sampleX, sampleY) {\n    if (!sampleX.length || !sampleY.length) {\n        throw new Error(\"Neither sample can be empty\");\n    }\n\n    const pooledSamples = sampleX\n        .map((x) => ({ label: \"x\", value: x }))\n        .concat(sampleY.map((y) => ({ label: \"y\", value: y })))\n        .sort((a, b) => a.value - b.value);\n\n    for (let rank = 0; rank < pooledSamples.length; rank++) {\n        pooledSamples[rank].rank = rank;\n    }\n\n    let tiedRanks = [pooledSamples[0].rank];\n    for (let i = 1; i < pooledSamples.length; i++) {\n        if (pooledSamples[i].value === pooledSamples[i - 1].value) {\n            tiedRanks.push(pooledSamples[i].rank);\n            if (i === pooledSamples.length - 1) {\n                replaceRanksInPlace(pooledSamples, tiedRanks);\n            }\n        } else if (tiedRanks.length > 1) {\n            replaceRanksInPlace(pooledSamples, tiedRanks);\n        } else {\n            tiedRanks = [pooledSamples[i].rank];\n        }\n    }\n\n    function replaceRanksInPlace(pooledSamples, tiedRanks) {\n        const average = (tiedRanks[0] + tiedRanks[tiedRanks.length - 1]) / 2;\n        for (let i = 0; i < tiedRanks.length; i++) {\n            pooledSamples[tiedRanks[i]].rank = average;\n        }\n    }\n\n    let rankSum = 0;\n\n    for (let i = 0; i < pooledSamples.length; i++) {\n        const sample = pooledSamples[i];\n        if (sample.label === \"x\") {\n            rankSum += sample.rank + 1;\n        }\n    }\n\n    return rankSum;\n}\n\nexport default wilcoxonRankSum;\n", "/**\n * [Bayesian Classifier](http://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n *\n * This is a nave bayesian classifier that takes\n * singly-nested objects.\n *\n * @class\n * @example\n * var bayes = new BayesianClassifier();\n * bayes.train({\n *   species: 'Cat'\n * }, 'animal');\n * var result = bayes.score({\n *   species: 'Cat'\n * })\n * // result\n * // {\n * //   animal: 1\n * // }\n */\nclass BayesianClassifier {\n    /*:: totalCount: number */\n    /*:: data: Object */\n    constructor() {\n        // The number of items that are currently\n        // classified in the model\n        this.totalCount = 0;\n        // Every item classified in the model\n        this.data = {};\n    }\n\n    /**\n     * Train the classifier with a new item, which has a single\n     * dimension of Javascript literal keys and values.\n     *\n     * @param {Object} item an object with singly-deep properties\n     * @param {string} category the category this item belongs to\n     * @return {undefined} adds the item to the classifier\n     */\n    train(item, category) {\n        // If the data object doesn't have any values\n        // for this category, create a new object for it.\n        if (!this.data[category]) {\n            this.data[category] = {};\n        }\n\n        // Iterate through each key in the item.\n        for (const k in item) {\n            const v = item[k];\n            // Initialize the nested object `data[category][k][item[k]]`\n            // with an object of keys that equal 0.\n            if (this.data[category][k] === undefined) {\n                this.data[category][k] = {};\n            }\n            if (this.data[category][k][v] === undefined) {\n                this.data[category][k][v] = 0;\n            }\n\n            // And increment the key for this key/value combination.\n            this.data[category][k][v]++;\n        }\n\n        // Increment the number of items classified\n        this.totalCount++;\n    }\n\n    /**\n     * Generate a score of how well this item matches all\n     * possible categories based on its attributes\n     *\n     * @param {Object} item an item in the same format as with train\n     * @returns {Object} of probabilities that this item belongs to a\n     * given category.\n     */\n    score(item) {\n        // Initialize an empty array of odds per category.\n        const odds = {};\n        let category;\n        // Iterate through each key in the item,\n        // then iterate through each category that has been used\n        // in previous calls to `.train()`\n        for (const k in item) {\n            const v = item[k];\n            for (category in this.data) {\n                // Create an empty object for storing key - value combinations\n                // for this category.\n                odds[category] = {};\n\n                // If this item doesn't even have a property, it counts for nothing,\n                // but if it does have the property that we're looking for from\n                // the item to categorize, it counts based on how popular it is\n                // versus the whole population.\n                if (this.data[category][k]) {\n                    odds[category][k + \"_\" + v] =\n                        (this.data[category][k][v] || 0) / this.totalCount;\n                } else {\n                    odds[category][k + \"_\" + v] = 0;\n                }\n            }\n        }\n\n        // Set up a new object that will contain sums of these odds by category\n        const oddsSums = {};\n\n        for (category in odds) {\n            // Tally all of the odds for each category-combination pair -\n            // the non-existence of a category does not add anything to the\n            // score.\n            oddsSums[category] = 0;\n            for (const combination in odds[category]) {\n                oddsSums[category] += odds[category][combination];\n            }\n        }\n\n        return oddsSums;\n    }\n}\n\nexport default BayesianClassifier;\n", "/**\n * This is a single-layer [Perceptron Classifier](http://en.wikipedia.org/wiki/Perceptron) that takes\n * arrays of numbers and predicts whether they should be classified\n * as either 0 or 1 (negative or positive examples).\n * @class\n * @example\n * // Create the model\n * var p = new PerceptronModel();\n * // Train the model with input with a diagonal boundary.\n * for (var i = 0; i < 5; i++) {\n *     p.train([1, 1], 1);\n *     p.train([0, 1], 0);\n *     p.train([1, 0], 0);\n *     p.train([0, 0], 0);\n * }\n * p.predict([0, 0]); // 0\n * p.predict([0, 1]); // 0\n * p.predict([1, 0]); // 0\n * p.predict([1, 1]); // 1\n */\nclass PerceptronModel {\n    /*:: bias: number */\n    /*:: weights: Array<number> */\n    constructor() {\n        // The weights, or coefficients of the model;\n        // weights are only populated when training with data.\n        this.weights = [];\n        // The bias term, or intercept; it is also a weight but\n        // it's stored separately for convenience as it is always\n        // multiplied by one.\n        this.bias = 0;\n    }\n    /**\n     * **Predict**: Use an array of features with the weight array and bias\n     * to predict whether an example is labeled 0 or 1.\n     *\n     * @param {Array<number>} features an array of features as numbers\n     * @returns {number} 1 if the score is over 0, otherwise 0\n     */\n    predict(features) {\n        // Only predict if previously trained\n        // on the same size feature array(s).\n        if (features.length !== this.weights.length) {\n            return null;\n        }\n\n        // Calculate the sum of features times weights,\n        // with the bias added (implicitly times one).\n        let score = 0;\n        for (let i = 0; i < this.weights.length; i++) {\n            score += this.weights[i] * features[i];\n        }\n        score += this.bias;\n\n        // Classify as 1 if the score is over 0, otherwise 0.\n        if (score > 0) {\n            return 1;\n        } else {\n            return 0;\n        }\n    }\n\n    /**\n     * **Train** the classifier with a new example, which is\n     * a numeric array of features and a 0 or 1 label.\n     *\n     * @param {Array<number>} features an array of features as numbers\n     * @param {number} label either 0 or 1\n     * @returns {PerceptronModel} this\n     */\n    train(features, label) {\n        // Require that only labels of 0 or 1 are considered.\n        if (label !== 0 && label !== 1) {\n            return null;\n        }\n        // The length of the feature array determines\n        // the length of the weight array.\n        // The perceptron will continue learning as long as\n        // it keeps seeing feature arrays of the same length.\n        // When it sees a new data shape, it initializes.\n        if (features.length !== this.weights.length) {\n            this.weights = features;\n            this.bias = 1;\n        }\n        // Make a prediction based on current weights.\n        const prediction = this.predict(features);\n        // Update the weights if the prediction is wrong.\n        if (typeof prediction === \"number\" && prediction !== label) {\n            const gradient = label - prediction;\n            for (let i = 0; i < this.weights.length; i++) {\n                this.weights[i] += gradient * features[i];\n            }\n            this.bias += gradient;\n        }\n        return this;\n    }\n}\n\nexport default PerceptronModel;\n", "/**\n * We use ``, epsilon, as a stopping criterion when we want to iterate\n * until we're \"close enough\". Epsilon is a very small number: for\n * simple statistics, that number is **0.0001**\n *\n * This is used in calculations like the binomialDistribution, in which\n * the process of finding a value is [iterative](https://en.wikipedia.org/wiki/Iterative_method):\n * it progresses until it is close enough.\n *\n * Below is an example of using epsilon in [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent),\n * where we're trying to find a local minimum of a function's derivative,\n * given by the `fDerivative` method.\n *\n * @example\n * // From calculation, we expect that the local minimum occurs at x=9/4\n * var x_old = 0;\n * // The algorithm starts at x=6\n * var x_new = 6;\n * var stepSize = 0.01;\n *\n * function fDerivative(x) {\n *   return 4 * Math.pow(x, 3) - 9 * Math.pow(x, 2);\n * }\n *\n * // The loop runs until the difference between the previous\n * // value and the current value is smaller than epsilon - a rough\n * // meaure of 'close enough'\n * while (Math.abs(x_new - x_old) > ss.epsilon) {\n *   x_old = x_new;\n *   x_new = x_old - stepSize * fDerivative(x_old);\n * }\n *\n * console.log('Local minimum occurs at', x_new);\n */\nconst epsilon = 0.0001;\n\nexport default epsilon;\n", "/**\n * A [Factorial](https://en.wikipedia.org/wiki/Factorial), usually written n!, is the product of all positive\n * integers less than or equal to n. Often factorial is implemented\n * recursively, but this iterative approach is significantly faster\n * and simpler.\n *\n * @param {number} n input, must be an integer number 1 or greater\n * @returns {number} factorial: n!\n * @throws {Error} if n is less than 0 or not an integer\n * @example\n * factorial(5); // => 120\n */\nfunction factorial(n) {\n    // factorial is mathematically undefined for negative numbers\n    if (n < 0) {\n        throw new Error(\"factorial requires a non-negative value\");\n    }\n\n    if (Math.floor(n) !== n) {\n        throw new Error(\"factorial requires an integer input\");\n    }\n\n    // typically you'll expand the factorial function going down, like\n    // 5! = 5 * 4 * 3 * 2 * 1. This is going in the opposite direction,\n    // counting from 2 up to the number in question, and since anything\n    // multiplied by 1 is itself, the loop only needs to start at 2.\n    let accumulator = 1;\n    for (let i = 2; i <= n; i++) {\n        // for each number up to and including the number `n`, multiply\n        // the accumulator my that number.\n        accumulator *= i;\n    }\n    return accumulator;\n}\n\nexport default factorial;\n", "import factorial from \"./factorial.js\";\n\n/**\n * Compute the [gamma function](https://en.wikipedia.org/wiki/Gamma_function) of a value using Nemes' approximation.\n * The gamma of n is equivalent to (n-1)!, but unlike the factorial function, gamma is defined for all real n except zero\n * and negative integers (where NaN is returned). Note, the gamma function is also well-defined for complex numbers,\n * though this implementation currently does not handle complex numbers as input values.\n * Nemes' approximation is defined [here](https://arxiv.org/abs/1003.6020) as Theorem 2.2.\n * Negative values use [Euler's reflection formula](https://en.wikipedia.org/wiki/Gamma_function#Properties) for computation.\n *\n * @param {number} n Any real number except for zero and negative integers.\n * @returns {number} The gamma of the input value.\n *\n * @example\n * gamma(11.5); // 11899423.084037038\n * gamma(-11.5); // 2.29575810481609e-8\n * gamma(5); // 24\n */\nfunction gamma(n) {\n    if (Number.isInteger(n)) {\n        if (n <= 0) {\n            // gamma not defined for zero or negative integers\n            return Number.NaN;\n        } else {\n            // use factorial for integer inputs\n            return factorial(n - 1);\n        }\n    }\n\n    // Decrement n, because approximation is defined for n - 1\n    n--;\n\n    if (n < 0) {\n        // Use Euler's reflection formula for negative inputs\n        // see:  https://en.wikipedia.org/wiki/Gamma_function#Properties\n        return Math.PI / (Math.sin(Math.PI * -n) * gamma(-n));\n    } else {\n        // Nemes' expansion approximation\n        const seriesCoefficient =\n            Math.pow(n / Math.E, n) * Math.sqrt(2 * Math.PI * (n + 1 / 6));\n\n        const seriesDenom = n + 1 / 4;\n\n        const seriesExpansion =\n            1 +\n            1 / 144 / Math.pow(seriesDenom, 2) -\n            1 / 12960 / Math.pow(seriesDenom, 3) -\n            257 / 207360 / Math.pow(seriesDenom, 4) -\n            52 / 2612736 / Math.pow(seriesDenom, 5) +\n            5741173 / 9405849600 / Math.pow(seriesDenom, 6) +\n            37529 / 18811699200 / Math.pow(seriesDenom, 7);\n\n        return seriesCoefficient * seriesExpansion;\n    }\n}\n\nexport default gamma;\n", "// Define series coefficients\nconst COEFFICIENTS = [\n    0.99999999999999709182, 57.156235665862923517, -59.597960355475491248,\n    14.136097974741747174, -0.49191381609762019978, 0.33994649984811888699e-4,\n    0.46523628927048575665e-4, -0.98374475304879564677e-4,\n    0.15808870322491248884e-3, -0.21026444172410488319e-3,\n    0.2174396181152126432e-3, -0.16431810653676389022e-3,\n    0.84418223983852743293e-4, -0.2619083840158140867e-4,\n    0.36899182659531622704e-5\n];\n\nconst g = 607 / 128;\nconst LOGSQRT2PI = Math.log(Math.sqrt(2 * Math.PI));\n\n/**\n * Compute the logarithm of the [gamma function](https://en.wikipedia.org/wiki/Gamma_function) of a value using Lanczos' approximation.\n * This function takes as input any real-value n greater than 0.\n * This function is useful for values of n too large for the normal gamma function (n > 165).\n * The code is based on Lanczo's Gamma approximation, defined [here](http://my.fit.edu/~gabdo/gamma.txt).\n *\n * @param {number} n Any real number greater than zero.\n * @returns {number} The logarithm of gamma of the input value.\n *\n * @example\n * gammaln(500); // 2605.1158503617335\n * gammaln(2.4); // 0.21685932244884043\n */\nfunction gammaln(n) {\n    // Return infinity if value not in domain\n    if (n <= 0) {\n        return Number.POSITIVE_INFINITY;\n    }\n\n    // Decrement n, because approximation is defined for n - 1\n    n--;\n\n    // Create series approximation\n    let a = COEFFICIENTS[0];\n\n    for (let i = 1; i < 15; i++) {\n        a += COEFFICIENTS[i] / (n + i);\n    }\n\n    const tmp = g + 0.5 + n;\n\n    // Return natural logarithm of gamma(n)\n    return LOGSQRT2PI + Math.log(a) - tmp + (n + 0.5) * Math.log(tmp);\n}\n\nexport default gammaln;\n", "/**\n * The [Bernoulli distribution](http://en.wikipedia.org/wiki/Bernoulli_distribution)\n * is the probability discrete\n * distribution of a random variable which takes value 1 with success\n * probability `p` and value 0 with failure\n * probability `q` = 1 - `p`. It can be used, for example, to represent the\n * toss of a coin, where \"1\" is defined to mean \"heads\" and \"0\" is defined\n * to mean \"tails\" (or vice versa). It is\n * a special case of a Binomial Distribution\n * where `n` = 1.\n *\n * @param {number} p input value, between 0 and 1 inclusive\n * @returns {number[]} values of bernoulli distribution at this point\n * @throws {Error} if p is outside 0 and 1\n * @example\n * bernoulliDistribution(0.3); // => [0.7, 0.3]\n */\nfunction bernoulliDistribution(p) /*: number[] */ {\n    // Check that `p` is a valid probability (0  p  1)\n    if (p < 0 || p > 1) {\n        throw new Error(\n            \"bernoulliDistribution requires probability to be between 0 and 1 inclusive\"\n        );\n    }\n\n    return [1 - p, p];\n}\n\nexport default bernoulliDistribution;\n", "import epsilon from \"./epsilon.js\";\n\n/**\n * The [Binomial Distribution](http://en.wikipedia.org/wiki/Binomial_distribution) is the discrete probability\n * distribution of the number of successes in a sequence of n independent yes/no experiments, each of which yields\n * success with probability `probability`. Such a success/failure experiment is also called a Bernoulli experiment or\n * Bernoulli trial; when trials = 1, the Binomial Distribution is a Bernoulli Distribution.\n *\n * @param {number} trials number of trials to simulate\n * @param {number} probability\n * @returns {number[]} output\n */\nfunction binomialDistribution(trials, probability) /*: ?number[] */ {\n    // Check that `p` is a valid probability (0  p  1),\n    // that `n` is an integer, strictly positive.\n    if (probability < 0 || probability > 1 || trials <= 0 || trials % 1 !== 0) {\n        return undefined;\n    }\n\n    // We initialize `x`, the random variable, and `accumulator`, an accumulator\n    // for the cumulative distribution function to 0. `distribution_functions`\n    // is the object we'll return with the `probability_of_x` and the\n    // `cumulativeProbability_of_x`, as well as the calculated mean &\n    // variance. We iterate until the `cumulativeProbability_of_x` is\n    // within `epsilon` of 1.0.\n    let x = 0;\n    let cumulativeProbability = 0;\n    const cells = [];\n    let binomialCoefficient = 1;\n\n    // This algorithm iterates through each potential outcome,\n    // until the `cumulativeProbability` is very close to 1, at\n    // which point we've defined the vast majority of outcomes\n    do {\n        // a [probability mass function](https://en.wikipedia.org/wiki/Probability_mass_function)\n        cells[x] =\n            binomialCoefficient *\n            Math.pow(probability, x) *\n            Math.pow(1 - probability, trials - x);\n        cumulativeProbability += cells[x];\n        x++;\n        binomialCoefficient = (binomialCoefficient * (trials - x + 1)) / x;\n        // when the cumulativeProbability is nearly 1, we've calculated\n        // the useful range of this distribution\n    } while (cumulativeProbability < 1 - epsilon);\n\n    return cells;\n}\n\nexport default binomialDistribution;\n", "import epsilon from \"./epsilon.js\";\n\n/**\n * The [Poisson Distribution](http://en.wikipedia.org/wiki/Poisson_distribution)\n * is a discrete probability distribution that expresses the probability\n * of a given number of events occurring in a fixed interval of time\n * and/or space if these events occur with a known average rate and\n * independently of the time since the last event.\n *\n * The Poisson Distribution is characterized by the strictly positive\n * mean arrival or occurrence rate, ``.\n *\n * @param {number} lambda location poisson distribution\n * @returns {number[]} values of poisson distribution at that point\n */\nfunction poissonDistribution(lambda) /*: ?number[] */ {\n    // Check that lambda is strictly positive\n    if (lambda <= 0) {\n        return undefined;\n    }\n\n    // our current place in the distribution\n    let x = 0;\n    // and we keep track of the current cumulative probability, in\n    // order to know when to stop calculating chances.\n    let cumulativeProbability = 0;\n    // the calculated cells to be returned\n    const cells = [];\n    let factorialX = 1;\n\n    // This algorithm iterates through each potential outcome,\n    // until the `cumulativeProbability` is very close to 1, at\n    // which point we've defined the vast majority of outcomes\n    do {\n        // a [probability mass function](https://en.wikipedia.org/wiki/Probability_mass_function)\n        cells[x] = (Math.exp(-lambda) * Math.pow(lambda, x)) / factorialX;\n        cumulativeProbability += cells[x];\n        x++;\n        factorialX *= x;\n        // when the cumulativeProbability is nearly 1, we've calculated\n        // the useful range of this distribution\n    } while (cumulativeProbability < 1 - epsilon);\n\n    return cells;\n}\n\nexport default poissonDistribution;\n", "/**\n * **Percentage Points of the 2 (Chi-Squared) Distribution**\n *\n * The [2 (Chi-Squared) Distribution](http://en.wikipedia.org/wiki/Chi-squared_distribution) is used in the common\n * chi-squared tests for goodness of fit of an observed distribution to a theoretical one, the independence of two\n * criteria of classification of qualitative data, and in confidence interval estimation for a population standard\n * deviation of a normal distribution from a sample standard deviation.\n *\n * Values from Appendix 1, Table III of William W. Hines & Douglas C. Montgomery, \"Probability and Statistics in\n * Engineering and Management Science\", Wiley (1980).\n */\nconst chiSquaredDistributionTable = {\n    1: {\n        0.995: 0,\n        0.99: 0,\n        0.975: 0,\n        0.95: 0,\n        0.9: 0.02,\n        0.5: 0.45,\n        0.1: 2.71,\n        0.05: 3.84,\n        0.025: 5.02,\n        0.01: 6.63,\n        0.005: 7.88\n    },\n    2: {\n        0.995: 0.01,\n        0.99: 0.02,\n        0.975: 0.05,\n        0.95: 0.1,\n        0.9: 0.21,\n        0.5: 1.39,\n        0.1: 4.61,\n        0.05: 5.99,\n        0.025: 7.38,\n        0.01: 9.21,\n        0.005: 10.6\n    },\n    3: {\n        0.995: 0.07,\n        0.99: 0.11,\n        0.975: 0.22,\n        0.95: 0.35,\n        0.9: 0.58,\n        0.5: 2.37,\n        0.1: 6.25,\n        0.05: 7.81,\n        0.025: 9.35,\n        0.01: 11.34,\n        0.005: 12.84\n    },\n    4: {\n        0.995: 0.21,\n        0.99: 0.3,\n        0.975: 0.48,\n        0.95: 0.71,\n        0.9: 1.06,\n        0.5: 3.36,\n        0.1: 7.78,\n        0.05: 9.49,\n        0.025: 11.14,\n        0.01: 13.28,\n        0.005: 14.86\n    },\n    5: {\n        0.995: 0.41,\n        0.99: 0.55,\n        0.975: 0.83,\n        0.95: 1.15,\n        0.9: 1.61,\n        0.5: 4.35,\n        0.1: 9.24,\n        0.05: 11.07,\n        0.025: 12.83,\n        0.01: 15.09,\n        0.005: 16.75\n    },\n    6: {\n        0.995: 0.68,\n        0.99: 0.87,\n        0.975: 1.24,\n        0.95: 1.64,\n        0.9: 2.2,\n        0.5: 5.35,\n        0.1: 10.65,\n        0.05: 12.59,\n        0.025: 14.45,\n        0.01: 16.81,\n        0.005: 18.55\n    },\n    7: {\n        0.995: 0.99,\n        0.99: 1.25,\n        0.975: 1.69,\n        0.95: 2.17,\n        0.9: 2.83,\n        0.5: 6.35,\n        0.1: 12.02,\n        0.05: 14.07,\n        0.025: 16.01,\n        0.01: 18.48,\n        0.005: 20.28\n    },\n    8: {\n        0.995: 1.34,\n        0.99: 1.65,\n        0.975: 2.18,\n        0.95: 2.73,\n        0.9: 3.49,\n        0.5: 7.34,\n        0.1: 13.36,\n        0.05: 15.51,\n        0.025: 17.53,\n        0.01: 20.09,\n        0.005: 21.96\n    },\n    9: {\n        0.995: 1.73,\n        0.99: 2.09,\n        0.975: 2.7,\n        0.95: 3.33,\n        0.9: 4.17,\n        0.5: 8.34,\n        0.1: 14.68,\n        0.05: 16.92,\n        0.025: 19.02,\n        0.01: 21.67,\n        0.005: 23.59\n    },\n    10: {\n        0.995: 2.16,\n        0.99: 2.56,\n        0.975: 3.25,\n        0.95: 3.94,\n        0.9: 4.87,\n        0.5: 9.34,\n        0.1: 15.99,\n        0.05: 18.31,\n        0.025: 20.48,\n        0.01: 23.21,\n        0.005: 25.19\n    },\n    11: {\n        0.995: 2.6,\n        0.99: 3.05,\n        0.975: 3.82,\n        0.95: 4.57,\n        0.9: 5.58,\n        0.5: 10.34,\n        0.1: 17.28,\n        0.05: 19.68,\n        0.025: 21.92,\n        0.01: 24.72,\n        0.005: 26.76\n    },\n    12: {\n        0.995: 3.07,\n        0.99: 3.57,\n        0.975: 4.4,\n        0.95: 5.23,\n        0.9: 6.3,\n        0.5: 11.34,\n        0.1: 18.55,\n        0.05: 21.03,\n        0.025: 23.34,\n        0.01: 26.22,\n        0.005: 28.3\n    },\n    13: {\n        0.995: 3.57,\n        0.99: 4.11,\n        0.975: 5.01,\n        0.95: 5.89,\n        0.9: 7.04,\n        0.5: 12.34,\n        0.1: 19.81,\n        0.05: 22.36,\n        0.025: 24.74,\n        0.01: 27.69,\n        0.005: 29.82\n    },\n    14: {\n        0.995: 4.07,\n        0.99: 4.66,\n        0.975: 5.63,\n        0.95: 6.57,\n        0.9: 7.79,\n        0.5: 13.34,\n        0.1: 21.06,\n        0.05: 23.68,\n        0.025: 26.12,\n        0.01: 29.14,\n        0.005: 31.32\n    },\n    15: {\n        0.995: 4.6,\n        0.99: 5.23,\n        0.975: 6.27,\n        0.95: 7.26,\n        0.9: 8.55,\n        0.5: 14.34,\n        0.1: 22.31,\n        0.05: 25,\n        0.025: 27.49,\n        0.01: 30.58,\n        0.005: 32.8\n    },\n    16: {\n        0.995: 5.14,\n        0.99: 5.81,\n        0.975: 6.91,\n        0.95: 7.96,\n        0.9: 9.31,\n        0.5: 15.34,\n        0.1: 23.54,\n        0.05: 26.3,\n        0.025: 28.85,\n        0.01: 32,\n        0.005: 34.27\n    },\n    17: {\n        0.995: 5.7,\n        0.99: 6.41,\n        0.975: 7.56,\n        0.95: 8.67,\n        0.9: 10.09,\n        0.5: 16.34,\n        0.1: 24.77,\n        0.05: 27.59,\n        0.025: 30.19,\n        0.01: 33.41,\n        0.005: 35.72\n    },\n    18: {\n        0.995: 6.26,\n        0.99: 7.01,\n        0.975: 8.23,\n        0.95: 9.39,\n        0.9: 10.87,\n        0.5: 17.34,\n        0.1: 25.99,\n        0.05: 28.87,\n        0.025: 31.53,\n        0.01: 34.81,\n        0.005: 37.16\n    },\n    19: {\n        0.995: 6.84,\n        0.99: 7.63,\n        0.975: 8.91,\n        0.95: 10.12,\n        0.9: 11.65,\n        0.5: 18.34,\n        0.1: 27.2,\n        0.05: 30.14,\n        0.025: 32.85,\n        0.01: 36.19,\n        0.005: 38.58\n    },\n    20: {\n        0.995: 7.43,\n        0.99: 8.26,\n        0.975: 9.59,\n        0.95: 10.85,\n        0.9: 12.44,\n        0.5: 19.34,\n        0.1: 28.41,\n        0.05: 31.41,\n        0.025: 34.17,\n        0.01: 37.57,\n        0.005: 40\n    },\n    21: {\n        0.995: 8.03,\n        0.99: 8.9,\n        0.975: 10.28,\n        0.95: 11.59,\n        0.9: 13.24,\n        0.5: 20.34,\n        0.1: 29.62,\n        0.05: 32.67,\n        0.025: 35.48,\n        0.01: 38.93,\n        0.005: 41.4\n    },\n    22: {\n        0.995: 8.64,\n        0.99: 9.54,\n        0.975: 10.98,\n        0.95: 12.34,\n        0.9: 14.04,\n        0.5: 21.34,\n        0.1: 30.81,\n        0.05: 33.92,\n        0.025: 36.78,\n        0.01: 40.29,\n        0.005: 42.8\n    },\n    23: {\n        0.995: 9.26,\n        0.99: 10.2,\n        0.975: 11.69,\n        0.95: 13.09,\n        0.9: 14.85,\n        0.5: 22.34,\n        0.1: 32.01,\n        0.05: 35.17,\n        0.025: 38.08,\n        0.01: 41.64,\n        0.005: 44.18\n    },\n    24: {\n        0.995: 9.89,\n        0.99: 10.86,\n        0.975: 12.4,\n        0.95: 13.85,\n        0.9: 15.66,\n        0.5: 23.34,\n        0.1: 33.2,\n        0.05: 36.42,\n        0.025: 39.36,\n        0.01: 42.98,\n        0.005: 45.56\n    },\n    25: {\n        0.995: 10.52,\n        0.99: 11.52,\n        0.975: 13.12,\n        0.95: 14.61,\n        0.9: 16.47,\n        0.5: 24.34,\n        0.1: 34.28,\n        0.05: 37.65,\n        0.025: 40.65,\n        0.01: 44.31,\n        0.005: 46.93\n    },\n    26: {\n        0.995: 11.16,\n        0.99: 12.2,\n        0.975: 13.84,\n        0.95: 15.38,\n        0.9: 17.29,\n        0.5: 25.34,\n        0.1: 35.56,\n        0.05: 38.89,\n        0.025: 41.92,\n        0.01: 45.64,\n        0.005: 48.29\n    },\n    27: {\n        0.995: 11.81,\n        0.99: 12.88,\n        0.975: 14.57,\n        0.95: 16.15,\n        0.9: 18.11,\n        0.5: 26.34,\n        0.1: 36.74,\n        0.05: 40.11,\n        0.025: 43.19,\n        0.01: 46.96,\n        0.005: 49.65\n    },\n    28: {\n        0.995: 12.46,\n        0.99: 13.57,\n        0.975: 15.31,\n        0.95: 16.93,\n        0.9: 18.94,\n        0.5: 27.34,\n        0.1: 37.92,\n        0.05: 41.34,\n        0.025: 44.46,\n        0.01: 48.28,\n        0.005: 50.99\n    },\n    29: {\n        0.995: 13.12,\n        0.99: 14.26,\n        0.975: 16.05,\n        0.95: 17.71,\n        0.9: 19.77,\n        0.5: 28.34,\n        0.1: 39.09,\n        0.05: 42.56,\n        0.025: 45.72,\n        0.01: 49.59,\n        0.005: 52.34\n    },\n    30: {\n        0.995: 13.79,\n        0.99: 14.95,\n        0.975: 16.79,\n        0.95: 18.49,\n        0.9: 20.6,\n        0.5: 29.34,\n        0.1: 40.26,\n        0.05: 43.77,\n        0.025: 46.98,\n        0.01: 50.89,\n        0.005: 53.67\n    },\n    40: {\n        0.995: 20.71,\n        0.99: 22.16,\n        0.975: 24.43,\n        0.95: 26.51,\n        0.9: 29.05,\n        0.5: 39.34,\n        0.1: 51.81,\n        0.05: 55.76,\n        0.025: 59.34,\n        0.01: 63.69,\n        0.005: 66.77\n    },\n    50: {\n        0.995: 27.99,\n        0.99: 29.71,\n        0.975: 32.36,\n        0.95: 34.76,\n        0.9: 37.69,\n        0.5: 49.33,\n        0.1: 63.17,\n        0.05: 67.5,\n        0.025: 71.42,\n        0.01: 76.15,\n        0.005: 79.49\n    },\n    60: {\n        0.995: 35.53,\n        0.99: 37.48,\n        0.975: 40.48,\n        0.95: 43.19,\n        0.9: 46.46,\n        0.5: 59.33,\n        0.1: 74.4,\n        0.05: 79.08,\n        0.025: 83.3,\n        0.01: 88.38,\n        0.005: 91.95\n    },\n    70: {\n        0.995: 43.28,\n        0.99: 45.44,\n        0.975: 48.76,\n        0.95: 51.74,\n        0.9: 55.33,\n        0.5: 69.33,\n        0.1: 85.53,\n        0.05: 90.53,\n        0.025: 95.02,\n        0.01: 100.42,\n        0.005: 104.22\n    },\n    80: {\n        0.995: 51.17,\n        0.99: 53.54,\n        0.975: 57.15,\n        0.95: 60.39,\n        0.9: 64.28,\n        0.5: 79.33,\n        0.1: 96.58,\n        0.05: 101.88,\n        0.025: 106.63,\n        0.01: 112.33,\n        0.005: 116.32\n    },\n    90: {\n        0.995: 59.2,\n        0.99: 61.75,\n        0.975: 65.65,\n        0.95: 69.13,\n        0.9: 73.29,\n        0.5: 89.33,\n        0.1: 107.57,\n        0.05: 113.14,\n        0.025: 118.14,\n        0.01: 124.12,\n        0.005: 128.3\n    },\n    100: {\n        0.995: 67.33,\n        0.99: 70.06,\n        0.975: 74.22,\n        0.95: 77.93,\n        0.9: 82.36,\n        0.5: 99.33,\n        0.1: 118.5,\n        0.05: 124.34,\n        0.025: 129.56,\n        0.01: 135.81,\n        0.005: 140.17\n    }\n};\n\nexport default chiSquaredDistributionTable;\n", "import chiSquaredDistributionTable from \"./chi_squared_distribution_table.js\";\nimport mean from \"./mean.js\";\n\n/**\n * The [2 (Chi-Squared) Goodness-of-Fit Test](http://en.wikipedia.org/wiki/Goodness_of_fit#Pearson.27s_chi-squared_test)\n * uses a measure of goodness of fit which is the sum of differences between observed and expected outcome frequencies\n * (that is, counts of observations), each squared and divided by the number of observations expected given the\n * hypothesized distribution. The resulting 2 statistic, `chiSquared`, can be compared to the chi-squared distribution\n * to determine the goodness of fit. In order to determine the degrees of freedom of the chi-squared distribution, one\n * takes the total number of observed frequencies and subtracts the number of estimated parameters. The test statistic\n * follows, approximately, a chi-square distribution with (k  c) degrees of freedom where `k` is the number of non-empty\n * cells and `c` is the number of estimated parameters for the distribution.\n *\n * @param {Array<number>} data\n * @param {Function} distributionType a function that returns a point in a distribution:\n * for instance, binomial, bernoulli, or poisson\n * @param {number} significance\n * @returns {number} chi squared goodness of fit\n * @example\n * // Data from Poisson goodness-of-fit example 10-19 in William W. Hines & Douglas C. Montgomery,\n * // \"Probability and Statistics in Engineering and Management Science\", Wiley (1980).\n * var data1019 = [\n *     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n *     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n *     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n *     2, 2, 2, 2, 2, 2, 2, 2, 2,\n *     3, 3, 3, 3\n * ];\n * ss.chiSquaredGoodnessOfFit(data1019, ss.poissonDistribution, 0.05); //= false\n */\nfunction chiSquaredGoodnessOfFit(data, distributionType, significance) {\n    // Estimate from the sample data, a weighted mean.\n    const inputMean = mean(data);\n    // Calculated value of the 2 statistic.\n    let chiSquared = 0;\n    // Number of hypothesized distribution parameters estimated, expected to be supplied in the distribution test.\n    // Lose one degree of freedom for estimating `lambda` from the sample data.\n    const c = 1;\n    // The hypothesized distribution.\n    // Generate the hypothesized distribution.\n    const hypothesizedDistribution = distributionType(inputMean);\n    const observedFrequencies = [];\n    const expectedFrequencies = [];\n\n    // Create an array holding a histogram from the sample data, of\n    // the form `{ value: numberOfOcurrences }`\n    for (let i = 0; i < data.length; i++) {\n        if (observedFrequencies[data[i]] === undefined) {\n            observedFrequencies[data[i]] = 0;\n        }\n        observedFrequencies[data[i]]++;\n    }\n\n    // The histogram we created might be sparse - there might be gaps\n    // between values. So we iterate through the histogram, making\n    // sure that instead of undefined, gaps have 0 values.\n    for (let i = 0; i < observedFrequencies.length; i++) {\n        if (observedFrequencies[i] === undefined) {\n            observedFrequencies[i] = 0;\n        }\n    }\n\n    // Create an array holding a histogram of expected data given the\n    // sample size and hypothesized distribution.\n    for (const k in hypothesizedDistribution) {\n        if (k in observedFrequencies) {\n            expectedFrequencies[+k] = hypothesizedDistribution[k] * data.length;\n        }\n    }\n\n    // Working backward through the expected frequencies, collapse classes\n    // if less than three observations are expected for a class.\n    // This transformation is applied to the observed frequencies as well.\n    for (let k = expectedFrequencies.length - 1; k >= 0; k--) {\n        if (expectedFrequencies[k] < 3) {\n            expectedFrequencies[k - 1] += expectedFrequencies[k];\n            expectedFrequencies.pop();\n\n            observedFrequencies[k - 1] += observedFrequencies[k];\n            observedFrequencies.pop();\n        }\n    }\n\n    // Iterate through the squared differences between observed & expected\n    // frequencies, accumulating the `chiSquared` statistic.\n    for (let k = 0; k < observedFrequencies.length; k++) {\n        chiSquared +=\n            Math.pow(observedFrequencies[k] - expectedFrequencies[k], 2) /\n            expectedFrequencies[k];\n    }\n\n    // Calculate degrees of freedom for this test and look it up in the\n    // `chiSquaredDistributionTable` in order to\n    // accept or reject the goodness-of-fit of the hypothesized distribution.\n    // Degrees of freedom, calculated as (number of class intervals -\n    // number of hypothesized distribution parameters estimated - 1)\n    const degreesOfFreedom = observedFrequencies.length - c - 1;\n    return (\n        chiSquaredDistributionTable[degreesOfFreedom][significance] < chiSquared\n    );\n}\n\nexport default chiSquaredGoodnessOfFit;\n", "import interquartileRange from \"./interquartile_range.js\";\nimport stddev from \"./sample_standard_deviation.js\";\n\nconst SQRT_2PI = Math.sqrt(2 * Math.PI);\n\n/**\n * [Well-known kernels](https://en.wikipedia.org/wiki/Kernel_(statistics)#Kernel_functions_in_common_use)\n * @private\n */\nconst kernels = {\n    /**\n     * The gaussian kernel.\n     * @private\n     */\n    gaussian: function (u) {\n        return Math.exp(-0.5 * u * u) / SQRT_2PI;\n    }\n};\n\n/**\n * Well known bandwidth selection methods\n * @private\n */\nconst bandwidthMethods = {\n    /**\n     * The [\"normal reference distribution\"\n     * rule-of-thumb](https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/bandwidth.nrd.html),\n     * a commonly used version of [Silverman's\n     * rule-of-thumb](https://en.wikipedia.org/wiki/Kernel_density_estimation#A_rule-of-thumb_bandwidth_estimator).\n     * @private\n     */\n    nrd: function (x) {\n        let s = stddev(x);\n        const iqr = interquartileRange(x);\n        if (typeof iqr === \"number\") {\n            s = Math.min(s, iqr / 1.34);\n        }\n        return 1.06 * s * Math.pow(x.length, -0.2);\n    }\n};\n\n/**\n * [Kernel density estimation](https://en.wikipedia.org/wiki/Kernel_density_estimation)\n * is a useful tool for, among other things, estimating the shape of the\n * underlying probability distribution from a sample.\n *\n * @name kernelDensityEstimation\n * @param X sample values\n * @param kernel The kernel function to use. If a function is provided, it should return non-negative values and integrate to 1. Defaults to 'gaussian'.\n * @param bandwidthMethod The \"bandwidth selection\" method to use, or a fixed bandwidth value. Defaults to \"nrd\", the commonly-used [\"normal reference distribution\" rule-of-thumb](https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/bandwidth.nrd.html).\n * @returns {Function} An estimated [probability density function](https://en.wikipedia.org/wiki/Probability_density_function) for the given sample. The returned function runs in `O(X.length)`.\n */\nfunction kernelDensityEstimation(X, kernel, bandwidthMethod) {\n    let kernelFn;\n    if (kernel === undefined) {\n        kernelFn = kernels.gaussian;\n    } else if (typeof kernel === \"string\") {\n        if (!kernels[kernel]) {\n            throw new Error('Unknown kernel \"' + kernel + '\"');\n        }\n        kernelFn = kernels[kernel];\n    } else {\n        kernelFn = kernel;\n    }\n\n    let bandwidth;\n    if (typeof bandwidthMethod === \"undefined\") {\n        bandwidth = bandwidthMethods.nrd(X);\n    } else if (typeof bandwidthMethod === \"string\") {\n        if (!bandwidthMethods[bandwidthMethod]) {\n            throw new Error(\n                'Unknown bandwidth method \"' + bandwidthMethod + '\"'\n            );\n        }\n        bandwidth = bandwidthMethods[bandwidthMethod](X);\n    } else {\n        bandwidth = bandwidthMethod;\n    }\n\n    return function (x) {\n        let i = 0;\n        let sum = 0;\n        for (i = 0; i < X.length; i++) {\n            sum += kernelFn((x - X[i]) / bandwidth);\n        }\n        return sum / bandwidth / X.length;\n    };\n}\n\nexport default kernelDensityEstimation;\n", "/**\n * The [Z-Score, or Standard Score](http://en.wikipedia.org/wiki/Standard_score).\n *\n * The standard score is the number of standard deviations an observation\n * or datum is above or below the mean. Thus, a positive standard score\n * represents a datum above the mean, while a negative standard score\n * represents a datum below the mean. It is a dimensionless quantity\n * obtained by subtracting the population mean from an individual raw\n * score and then dividing the difference by the population standard\n * deviation.\n *\n * The z-score is only defined if one knows the population parameters;\n * if one only has a sample set, then the analogous computation with\n * sample mean and sample standard deviation yields the\n * Student's t-statistic.\n *\n * @param {number} x\n * @param {number} mean\n * @param {number} standardDeviation\n * @return {number} z score\n * @example\n * zScore(78, 80, 5); // => -0.4\n */\nfunction zScore(x, mean, standardDeviation) {\n    return (x - mean) / standardDeviation;\n}\n\nexport default zScore;\n", "const SQRT_2PI = Math.sqrt(2 * Math.PI);\n\nfunction cumulativeDistribution(z) {\n    let sum = z;\n    let tmp = z;\n\n    // 15 iterations are enough for 4-digit precision\n    for (let i = 1; i < 15; i++) {\n        tmp *= (z * z) / (2 * i + 1);\n        sum += tmp;\n    }\n    return (\n        Math.round((0.5 + (sum / SQRT_2PI) * Math.exp((-z * z) / 2)) * 1e4) /\n        1e4\n    );\n}\n\n/**\n * A standard normal table, also called the unit normal table or Z table,\n * is a mathematical table for the values of  (phi), which are the values of\n * the [cumulative distribution function](https://en.wikipedia.org/wiki/Normal_distribution#Cumulative_distribution_function)\n * of the normal distribution. It is used to find the probability that a\n * statistic is observed below, above, or between values on the standard\n * normal distribution, and by extension, any normal distribution.\n */\nconst standardNormalTable = [];\n\nfor (let z = 0; z <= 3.09; z += 0.01) {\n    standardNormalTable.push(cumulativeDistribution(z));\n}\n\nexport default standardNormalTable;\n", "import standardNormalTable from \"./standard_normal_table.js\";\n\n/**\n * **[Cumulative Standard Normal Probability](http://en.wikipedia.org/wiki/Standard_normal_table)**\n *\n * Since probability tables cannot be\n * printed for every normal distribution, as there are an infinite variety\n * of normal distributions, it is common practice to convert a normal to a\n * standard normal and then use the standard normal table to find probabilities.\n *\n * You can use `.5 + .5 * errorFunction(x / Math.sqrt(2))` to calculate the probability\n * instead of looking it up in a table.\n *\n * @param {number} z\n * @returns {number} cumulative standard normal probability\n */\nfunction cumulativeStdNormalProbability(z) {\n    // Calculate the position of this value.\n    const absZ = Math.abs(z);\n    // Each row begins with a different\n    // significant digit: 0.5, 0.6, 0.7, and so on. Each value in the table\n    // corresponds to a range of 0.01 in the input values, so the value is\n    // multiplied by 100.\n    const index = Math.min(\n        Math.round(absZ * 100),\n        standardNormalTable.length - 1\n    );\n\n    // The index we calculate must be in the table as a positive value,\n    // but we still pay attention to whether the input is positive\n    // or negative, and flip the output value as a last step.\n    if (z >= 0) {\n        return standardNormalTable[index];\n    } else {\n        // due to floating-point arithmetic, values in the table with\n        // 4 significant figures can nevertheless end up as repeating\n        // fractions when they're computed here.\n        return Math.round((1 - standardNormalTable[index]) * 1e4) / 1e4;\n    }\n}\n\nexport default cumulativeStdNormalProbability;\n", "/**\n * **[Logistic Cumulative Distribution Function](https://en.wikipedia.org/wiki/Logistic_distribution)**\n *\n * @param {number} x\n * @returns {number} cumulative standard logistic probability\n */\nfunction cumulativeStdLogisticProbability(x) {\n    return 1 / (Math.exp(-x) + 1);\n}\n\nexport default cumulativeStdLogisticProbability;\n", "/**\n * **[Gaussian error function](http://en.wikipedia.org/wiki/Error_function)**\n *\n * The `errorFunction(x/(sd * Math.sqrt(2)))` is the probability that a value in a\n * normal distribution with standard deviation sd is within x of the mean.\n *\n * This function returns a numerical approximation to the exact value.\n * It uses Horner's method to evaluate the polynomial of  (tau).\n *\n * @param {number} x input\n * @return {number} error estimation\n * @example\n * errorFunction(1).toFixed(2); // => '0.84'\n */\nfunction errorFunction(x) {\n    const t = 1 / (1 + 0.5 * Math.abs(x));\n    const tau =\n        t *\n        Math.exp(\n            -x * x +\n                ((((((((0.17087277 * t - 0.82215223) * t + 1.48851587) * t -\n                    1.13520398) *\n                    t +\n                    0.27886807) *\n                    t -\n                    0.18628806) *\n                    t +\n                    0.09678418) *\n                    t +\n                    0.37409196) *\n                    t +\n                    1.00002368) *\n                    t -\n                1.26551223\n        );\n    if (x >= 0) {\n        return 1 - tau;\n    } else {\n        return tau - 1;\n    }\n}\n\nexport default errorFunction;\n", "/**\n * The Inverse [Gaussian error function](http://en.wikipedia.org/wiki/Error_function)\n * returns a numerical approximation to the value that would have caused\n * `errorFunction()` to return x.\n *\n * @param {number} x value of error function\n * @returns {number} estimated inverted value\n */\nfunction inverseErrorFunction(x) {\n    const a = (8 * (Math.PI - 3)) / (3 * Math.PI * (4 - Math.PI));\n\n    const inv = Math.sqrt(\n        Math.sqrt(\n            Math.pow(2 / (Math.PI * a) + Math.log(1 - x * x) / 2, 2) -\n                Math.log(1 - x * x) / a\n        ) -\n            (2 / (Math.PI * a) + Math.log(1 - x * x) / 2)\n    );\n\n    if (x >= 0) {\n        return inv;\n    } else {\n        return -inv;\n    }\n}\n\nexport default inverseErrorFunction;\n", "import epsilon from \"./epsilon.js\";\nimport inverseErrorFunction from \"./inverse_error_function.js\";\n\n/**\n * The [Probit](http://en.wikipedia.org/wiki/Probit)\n * is the inverse of cumulativeStdNormalProbability(),\n * and is also known as the normal quantile function.\n *\n * It returns the number of standard deviations from the mean\n * where the p'th quantile of values can be found in a normal distribution.\n * So, for example, probit(0.5 + 0.6827/2)  1 because 68.27% of values are\n * normally found within 1 standard deviation above or below the mean.\n *\n * @param {number} p\n * @returns {number} probit\n */\nfunction probit(p) {\n    if (p === 0) {\n        p = epsilon;\n    } else if (p >= 1) {\n        p = 1 - epsilon;\n    }\n    return Math.sqrt(2) * inverseErrorFunction(2 * p - 1);\n}\n\nexport default probit;\n", "/**\n * The [Logit](https://en.wikipedia.org/wiki/Logit)\n * is the inverse of cumulativeStdLogisticProbability,\n * and is also known as the logistic quantile function.\n *\n * @param {number} p\n * @returns {number} logit\n */\nfunction logit(p) {\n    if (p <= 0 || p >= 1) {\n        throw new Error(\"p must be strictly between zero and one\");\n    }\n    return Math.log(p / (1 - p));\n}\n\nexport default logit;\n", "import mean from \"./mean.js\";\nimport shuffleInPlace from \"./shuffle_in_place.js\";\n\n/**\n * Conducts a [permutation test](https://en.wikipedia.org/wiki/Resampling_(statistics)#Permutation_tests)\n * to determine if two data sets are *significantly* different from each other, using\n * the difference of means between the groups as the test statistic.\n * The function allows for the following hypotheses:\n * - two_tail = Null hypothesis: the two distributions are equal.\n * - greater = Null hypothesis: observations from sampleX tend to be smaller than those from sampleY.\n * - less = Null hypothesis: observations from sampleX tend to be greater than those from sampleY.\n * [Learn more about one-tail vs two-tail tests.](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests)\n *\n * @param {Array<number>} sampleX first dataset (e.g. treatment data)\n * @param {Array<number>} sampleY second dataset (e.g. control data)\n * @param {string} alternative alternative hypothesis, either 'two_sided' (default), 'greater', or 'less'\n * @param {number} k number of values in permutation distribution.\n * @param {Function} [randomSource=Math.random] an optional entropy source\n * @returns {number} p-value The probability of observing the difference between groups (as or more extreme than what we did), assuming the null hypothesis.\n *\n * @example\n * var control = [2, 5, 3, 6, 7, 2, 5];\n * var treatment = [20, 5, 13, 12, 7, 2, 2];\n * permutationTest(control, treatment); // ~0.1324\n */\nfunction permutationTest(sampleX, sampleY, alternative, k, randomSource) {\n    // Set default arguments\n    if (k === undefined) {\n        k = 10000;\n    }\n    if (alternative === undefined) {\n        alternative = \"two_side\";\n    }\n    if (\n        alternative !== \"two_side\" &&\n        alternative !== \"greater\" &&\n        alternative !== \"less\"\n    ) {\n        throw new Error(\n            \"`alternative` must be either 'two_side', 'greater', or 'less'.\"\n        );\n    }\n\n    // get means for each sample\n    const meanX = mean(sampleX);\n    const meanY = mean(sampleY);\n\n    // calculate initial test statistic. This will be our point of comparison with\n    // the generated test statistics.\n    const testStatistic = meanX - meanY;\n\n    // create test-statistic distribution\n    const testStatDsn = new Array(k);\n\n    // combine datsets so we can easily shuffle later\n    const allData = sampleX.concat(sampleY);\n    const midIndex = Math.floor(allData.length / 2);\n\n    for (let i = 0; i < k; i++) {\n        // 1. shuffle data assignments\n        shuffleInPlace(allData, randomSource);\n        const permLeft = allData.slice(0, midIndex);\n        const permRight = allData.slice(midIndex, allData.length);\n\n        // 2.re-calculate test statistic\n        const permTestStatistic = mean(permLeft) - mean(permRight);\n\n        // 3. store test statistic to build test statistic distribution\n        testStatDsn[i] = permTestStatistic;\n    }\n\n    // Calculate p-value depending on alternative\n    // For this test, we calculate the percentage of 'extreme' test statistics (subject to our hypothesis)\n    // more info on permutation test p-value calculations: https://onlinecourses.science.psu.edu/stat464/node/35\n    let numExtremeTStats = 0;\n    if (alternative === \"two_side\") {\n        for (let i = 0; i <= k; i++) {\n            if (Math.abs(testStatDsn[i]) >= Math.abs(testStatistic)) {\n                numExtremeTStats += 1;\n            }\n        }\n    } else if (alternative === \"greater\") {\n        for (let i = 0; i <= k; i++) {\n            if (testStatDsn[i] >= testStatistic) {\n                numExtremeTStats += 1;\n            }\n        }\n    } else {\n        // alternative === 'less'\n        for (let i = 0; i <= k; i++) {\n            /* c8 ignore start */\n            if (testStatDsn[i] <= testStatistic) {\n                numExtremeTStats += 1;\n            }\n            /* c8 ignore end */\n        }\n    }\n\n    return numExtremeTStats / k;\n}\n\nexport default permutationTest;\n", "/**\n * [Sign](https://en.wikipedia.org/wiki/Sign_function) is a function\n * that extracts the sign of a real number\n *\n * @param {number} x input value\n * @returns {number} sign value either 1, 0 or -1\n * @throws {TypeError} if the input argument x is not a number\n * @private\n *\n * @example\n * sign(2); // => 1\n */\nfunction sign(x) {\n    if (typeof x === \"number\") {\n        if (x < 0) {\n            return -1;\n        } else if (x === 0) {\n            return 0;\n        } else {\n            return 1;\n        }\n    } else {\n        throw new TypeError(\"not a number\");\n    }\n}\n\nexport default sign;\n", "import sign from \"./sign.js\";\n\n/**\n * [Bisection method](https://en.wikipedia.org/wiki/Bisection_method) is a root-finding\n * method that repeatedly bisects an interval to find the root.\n *\n * This function returns a numerical approximation to the exact value.\n *\n * @param {Function} func input function\n * @param {number} start - start of interval\n * @param {number} end - end of interval\n * @param {number} maxIterations - the maximum number of iterations\n * @param {number} errorTolerance - the error tolerance\n * @returns {number} estimated root value\n * @throws {TypeError} Argument func must be a function\n *\n * @example\n * bisect(Math.cos,0,4,100,0.003); // => 1.572265625\n */\nfunction bisect(func, start, end, maxIterations, errorTolerance) {\n    if (typeof func !== \"function\")\n        throw new TypeError(\"func must be a function\");\n\n    for (let i = 0; i < maxIterations; i++) {\n        const output = (start + end) / 2;\n\n        if (\n            func(output) === 0 ||\n            Math.abs((end - start) / 2) < errorTolerance\n        ) {\n            return output;\n        }\n\n        if (sign(func(output)) === sign(func(start))) {\n            start = output;\n        } else {\n            end = output;\n        }\n    }\n\n    throw new Error(\"maximum number of iterations exceeded\");\n}\n\nexport default bisect;\n", "/**\n * Calculate Euclidean distance between two points.\n * @param {Array<number>} left First N-dimensional point.\n * @param {Array<number>} right Second N-dimensional point.\n * @returns {number} Distance.\n */\nfunction euclideanDistance(left, right) {\n    let sum = 0;\n    for (let i = 0; i < left.length; i++) {\n        const diff = left[i] - right[i];\n        sum += diff * diff;\n    }\n    return Math.sqrt(sum);\n}\n\nexport default euclideanDistance;\n", "import euclideanDistance from \"./euclidean_distance.js\";\nimport makeMatrix from \"./make_matrix.js\";\nimport sample from \"./sample.js\";\n\n/**\n * @typedef {Object} kMeansReturn\n * @property {Array<number>} labels The labels.\n * @property {Array<Array<number>>} centroids The cluster centroids.\n */\n\n/**\n * Perform k-means clustering.\n *\n * @param {Array<Array<number>>} points N-dimensional coordinates of points to be clustered.\n * @param {number} numCluster How many clusters to create.\n * @param {Function} randomSource An optional entropy source that generates uniform values in [0, 1).\n * @return {kMeansReturn} Labels (same length as data) and centroids (same length as numCluster).\n * @throws {Error} If any centroids wind up friendless (i.e., without associated points).\n *\n * @example\n * kMeansCluster([[0.0, 0.5], [1.0, 0.5]], 2); // => {labels: [0, 1], centroids: [[0.0, 0.5], [1.0 0.5]]}\n */\nfunction kMeansCluster(points, numCluster, randomSource = Math.random) {\n    let oldCentroids = null;\n    let newCentroids = sample(points, numCluster, randomSource);\n    let labels = null;\n    let change = Number.MAX_VALUE;\n    while (change !== 0) {\n        labels = labelPoints(points, newCentroids);\n        oldCentroids = newCentroids;\n        newCentroids = calculateCentroids(points, labels, numCluster);\n        change = calculateChange(newCentroids, oldCentroids);\n    }\n    return {\n        labels: labels,\n        centroids: newCentroids\n    };\n}\n\n/**\n * Label each point according to which centroid it is closest to.\n *\n * @private\n * @param {Array<Array<number>>} points Array of XY coordinates.\n * @param {Array<Array<number>>} centroids Current centroids.\n * @return {Array<number>} Group labels.\n */\nfunction labelPoints(points, centroids) {\n    return points.map((p) => {\n        let minDist = Number.MAX_VALUE;\n        let label = -1;\n        for (let i = 0; i < centroids.length; i++) {\n            const dist = euclideanDistance(p, centroids[i]);\n            if (dist < minDist) {\n                minDist = dist;\n                label = i;\n            }\n        }\n        return label;\n    });\n}\n\n/**\n * Calculate centroids for points given labels.\n *\n * @private\n * @param {Array<Array<number>>} points Array of XY coordinates.\n * @param {Array<number>} labels Which groups points belong to.\n * @param {number} numCluster Number of clusters being created.\n * @return {Array<Array<number>>} Centroid for each group.\n * @throws {Error} If any centroids wind up friendless (i.e., without associated points).\n */\nfunction calculateCentroids(points, labels, numCluster) {\n    // Initialize accumulators.\n    const dimension = points[0].length;\n    const centroids = makeMatrix(numCluster, dimension);\n    const counts = Array(numCluster).fill(0);\n\n    // Add points to centroids' accumulators and count points per centroid.\n    const numPoints = points.length;\n    for (let i = 0; i < numPoints; i++) {\n        const point = points[i];\n        const label = labels[i];\n        const current = centroids[label];\n        for (let j = 0; j < dimension; j++) {\n            current[j] += point[j];\n        }\n        counts[label] += 1;\n    }\n\n    // Rescale centroids, checking for any that have no points.\n    for (let i = 0; i < numCluster; i++) {\n        if (counts[i] === 0) {\n            throw new Error(`Centroid ${i} has no friends`);\n        }\n        const centroid = centroids[i];\n        for (let j = 0; j < dimension; j++) {\n            centroid[j] /= counts[i];\n        }\n    }\n\n    return centroids;\n}\n\n/**\n * Calculate the difference between old centroids and new centroids.\n *\n * @private\n * @param {Array<Array<number>>} left One list of centroids.\n * @param {Array<Array<number>>} right Another list of centroids.\n * @return {number} Distance between centroids.\n */\nfunction calculateChange(left, right) {\n    let total = 0;\n    for (let i = 0; i < left.length; i++) {\n        total += euclideanDistance(left[i], right[i]);\n    }\n    return total;\n}\n\nexport default kMeansCluster;\n", "import euclideanDistance from \"./euclidean_distance.js\";\nimport makeMatrix from \"./make_matrix.js\";\nimport max from \"./max.js\";\n\n/**\n * Calculate the [silhouette values](https://en.wikipedia.org/wiki/Silhouette_(clustering))\n * for clustered data.\n *\n * @param {Array<Array<number>>} points N-dimensional coordinates of points.\n * @param {Array<number>} labels Labels of points. This must be the same length as `points`,\n * and values must lie in [0..G-1], where G is the number of groups.\n * @return {Array<number>} The silhouette value for each point.\n *\n * @example\n * silhouette([[0.25], [0.75]], [0, 0]); // => [1.0, 1.0]\n */\nfunction silhouette(points, labels) {\n    if (points.length !== labels.length) {\n        throw new Error(\"must have exactly as many labels as points\");\n    }\n    const groupings = createGroups(labels);\n    const distances = calculateAllDistances(points);\n    const result = [];\n    for (let i = 0; i < points.length; i++) {\n        let s = 0;\n        if (groupings[labels[i]].length > 1) {\n            const a = meanDistanceFromPointToGroup(\n                i,\n                groupings[labels[i]],\n                distances\n            );\n            const b = meanDistanceToNearestGroup(\n                i,\n                labels,\n                groupings,\n                distances\n            );\n            s = (b - a) / Math.max(a, b);\n        }\n        result.push(s);\n    }\n    return result;\n}\n\n/**\n * Create a lookup table mapping group IDs to point IDs.\n *\n * @private\n * @param {Array<number>} labels Labels of points. This must be the same length as `points`,\n * and values must lie in [0..G-1], where G is the number of groups.\n * @return {Array<Array<number>>} An array of length G, each of whose entries is an array\n * containing the indices of the points in that group.\n */\nfunction createGroups(labels) {\n    const numGroups = 1 + max(labels);\n    const result = Array(numGroups);\n    for (let i = 0; i < labels.length; i++) {\n        const label = labels[i];\n        if (result[label] === undefined) {\n            result[label] = [];\n        }\n        result[label].push(i);\n    }\n    return result;\n}\n\n/**\n * Create a lookup table of all inter-point distances.\n *\n * @private\n * @param {Array<Array<number>>} points N-dimensional coordinates of points.\n * @return {Array<Array<number>>} A symmetric square array of inter-point distances\n * (zero on the diagonal).\n */\nfunction calculateAllDistances(points) {\n    const numPoints = points.length;\n    const result = makeMatrix(numPoints, numPoints);\n    for (let i = 0; i < numPoints; i++) {\n        for (let j = 0; j < i; j++) {\n            result[i][j] = euclideanDistance(points[i], points[j]);\n            result[j][i] = result[i][j];\n        }\n    }\n    return result;\n}\n\n/**\n * Calculate the mean distance between this point and all the points in the\n * nearest group (as determined by which point in another group is closest).\n *\n * @private\n * @param {number} which The index of this point.\n * @param {Array<number>} labels Labels of points.\n * @param {Array<Array<number>>} groupings An array whose entries are arrays\n * containing the indices of the points in that group.\n * @param {Array<Array<number>>} distances A symmetric square array of inter-point\n * distances.\n * @return {number} The mean distance from this point to others in the nearest\n * group.\n */\nfunction meanDistanceToNearestGroup(which, labels, groupings, distances) {\n    const label = labels[which];\n    let result = Number.MAX_VALUE;\n    for (let i = 0; i < groupings.length; i++) {\n        if (i !== label) {\n            const d = meanDistanceFromPointToGroup(\n                which,\n                groupings[i],\n                distances\n            );\n            if (d < result) {\n                result = d;\n            }\n        }\n    }\n    return result;\n}\n\n/**\n * Calculate the mean distance between a point and all the points in a group\n * (possibly its own).\n *\n * @private\n * @param {number} which The index of this point.\n * @param {Array<number>} group The indices of all the points in the group in\n * question.\n * @param {Array<Array<number>>} distances A symmetric square array of inter-point\n * distances.\n * @return {number} The mean distance from this point to others in the\n * specified group.\n */\nfunction meanDistanceFromPointToGroup(which, group, distances) {\n    let total = 0;\n    for (let i = 0; i < group.length; i++) {\n        total += distances[which][group[i]];\n    }\n    return total / group.length;\n}\n\nexport default silhouette;\n", "import max from \"./max.js\";\nimport silhouette from \"./silhouette.js\";\n\n/**\n * Calculate the [silhouette metric](https://en.wikipedia.org/wiki/Silhouette_(clustering))\n * for a set of N-dimensional points arranged in groups. The metric is the largest\n * individual silhouette value for the data.\n *\n * @param {Array<Array<number>>} points N-dimensional coordinates of points.\n * @param {Array<number>} labels Labels of points. This must be the same length as `points`,\n * and values must lie in [0..G-1], where G is the number of groups.\n * @return {number} The silhouette metric for the groupings.\n *\n * @example\n * silhouetteMetric([[0.25], [0.75]], [0, 0]); // => 1.0\n */\nfunction silhouetteMetric(points, labels) {\n    const values = silhouette(points, labels);\n    return max(values);\n}\n\nexport default silhouetteMetric;\n", "/**\n * Relative error.\n *\n * This is more difficult to calculate than it first appears [1,2].  The usual\n * formula for the relative error between an actual value A and an expected\n * value E is `|(A-E)/E|`, but:\n *\n * 1. If the expected value is 0, any other value has infinite relative error,\n *    which is counter-intuitive: if the expected voltage is 0, getting 1/10th\n *    of a volt doesn't feel like an infinitely large error.\n *\n * 2. This formula does not satisfy the mathematical definition of a metric [3].\n *    [4] solved this problem by defining the relative error as `|ln(|A/E|)|`,\n *    but that formula only works if all values are positive: for example, it\n *    reports the relative error of -10 and 10 as 0.\n *\n * Our implementation sticks with convention and returns:\n *\n * - 0 if the actual and expected values are both zero\n * - Infinity if the actual value is non-zero and the expected value is zero\n * - `|(A-E)/E|` in all other cases\n *\n * [1] https://math.stackexchange.com/questions/677852/how-to-calculate-relative-error-when-true-value-is-zero\n * [2] https://en.wikipedia.org/wiki/Relative_change_and_difference\n * [3] https://en.wikipedia.org/wiki/Metric_(mathematics)#Definition\n * [4] F.W.J. Olver: \"A New Approach to Error Arithmetic.\" SIAM Journal on\n *     Numerical Analysis, 15(2), 1978, 10.1137/0715024.\n *\n * @param {number} actual The actual value.\n * @param {number} expected The expected value.\n * @return {number} The relative error.\n */\nfunction relativeError(actual, expected) {\n    // These lines are actually covered by tests, but it seems\n    // like c8 has a bug that marks them as not covered.\n    /* c8 ignore start */\n    if (actual === 0 && expected === 0) {\n        return 0;\n    }\n    /* c8 ignore end */\n    return Math.abs((actual - expected) / expected);\n}\n\nexport default relativeError;\n", "import epsilon from \"./epsilon.js\";\nimport relativeError from \"./relative_error.js\";\n\n/**\n * Approximate equality.\n *\n * @param {number} actual The value to be tested.\n * @param {number} expected The reference value.\n * @param {number} tolerance The acceptable relative difference.\n * @return {boolean} Whether numbers are within tolerance.\n */\nfunction approxEqual(actual, expected, tolerance = epsilon) {\n    return relativeError(actual, expected) <= tolerance;\n}\n\nexport default approxEqual;\n", "const LOOP = 8;\nconst FLOAT_MUL = 1 / 16777216;\nconst sh1 = 15;\nconst sh2 = 18;\nconst sh3 = 11;\nfunction multiply_uint32(n, m) {\n    n >>>= 0;\n    m >>>= 0;\n    const nlo = n & 0xffff;\n    const nhi = n - nlo;\n    return (((nhi * m) >>> 0) + nlo * m) >>> 0;\n}\nexport default class XSadd {\n    constructor(seed = Date.now()) {\n        this.state = new Uint32Array(4);\n        this.init(seed);\n        this.random = this.getFloat.bind(this);\n    }\n    /**\n     * Returns a 32-bit integer r (0 <= r < 2^32)\n     */\n    getUint32() {\n        this.nextState();\n        return (this.state[3] + this.state[2]) >>> 0;\n    }\n    /**\n     * Returns a floating point number r (0.0 <= r < 1.0)\n     */\n    getFloat() {\n        return (this.getUint32() >>> 8) * FLOAT_MUL;\n    }\n    init(seed) {\n        if (!Number.isInteger(seed)) {\n            throw new TypeError('seed must be an integer');\n        }\n        this.state[0] = seed;\n        this.state[1] = 0;\n        this.state[2] = 0;\n        this.state[3] = 0;\n        for (let i = 1; i < LOOP; i++) {\n            this.state[i & 3] ^=\n                (i +\n                    multiply_uint32(1812433253, this.state[(i - 1) & 3] ^ ((this.state[(i - 1) & 3] >>> 30) >>> 0))) >>>\n                    0;\n        }\n        this.periodCertification();\n        for (let i = 0; i < LOOP; i++) {\n            this.nextState();\n        }\n    }\n    periodCertification() {\n        if (this.state[0] === 0 &&\n            this.state[1] === 0 &&\n            this.state[2] === 0 &&\n            this.state[3] === 0) {\n            this.state[0] = 88; // X\n            this.state[1] = 83; // S\n            this.state[2] = 65; // A\n            this.state[3] = 68; // D\n        }\n    }\n    nextState() {\n        let t = this.state[0];\n        t ^= t << sh1;\n        t ^= t >>> sh2;\n        t ^= this.state[3] << sh3;\n        this.state[0] = this.state[1];\n        this.state[1] = this.state[2];\n        this.state[2] = this.state[3];\n        this.state[3] = t;\n    }\n}\n", "/**\n * Mathematical utility functions\n *\n * Basic mathematical operations used throughout the library\n * @module utils/math\n */\n\n/**\n * Calculate Euclidean distance between two points\n *\n * @param x1 - X coordinate of first point\n * @param y1 - Y coordinate of first point\n * @param x2 - X coordinate of second point\n * @param y2 - Y coordinate of second point\n * @returns Euclidean distance\n *\n * @example\n * ```ts\n * const dist = euclideanDistance(0, 0, 3, 4);\n * console.log(dist); // 5\n * ```\n */\nexport function euclideanDistance(\n  x1: number,\n  y1: number,\n  x2: number,\n  y2: number\n): number {\n  const dx = x2 - x1;\n  const dy = y2 - y1;\n  return Math.sqrt(dx * dx + dy * dy);\n}\n\n/**\n * Calculate squared Euclidean distance (faster, no sqrt)\n *\n * @param x1 - X coordinate of first point\n * @param y1 - Y coordinate of first point\n * @param x2 - X coordinate of second point\n * @param y2 - Y coordinate of second point\n * @returns Squared Euclidean distance\n */\nexport function euclideanDistanceSquared(\n  x1: number,\n  y1: number,\n  x2: number,\n  y2: number\n): number {\n  const dx = x2 - x1;\n  const dy = y2 - y1;\n  return dx * dx + dy * dy;\n}\n\n/**\n * Check if a number is valid (not null, undefined, NaN, or Infinity)\n *\n * @param value - Value to check\n * @returns true if valid number\n */\nexport function isValidNumber(value: unknown): value is number {\n  return (\n    typeof value === 'number' &&\n    !Number.isNaN(value) &&\n    Number.isFinite(value)\n  );\n}\n\n/**\n * Clamp a value between min and max\n *\n * @param value - Value to clamp\n * @param min - Minimum value\n * @param max - Maximum value\n * @returns Clamped value\n */\nexport function clamp(value: number, min: number, max: number): number {\n  return Math.min(Math.max(value, min), max);\n}\n", "/**\n * Statistical utility functions\n *\n * Core statistical operations with NA/null handling similar to R\n * @module utils/statistics\n */\n\nimport * as ss from 'simple-statistics';\n\n/**\n * Calculate mean of array, optionally removing NA/null values\n *\n * @param values - Array of values\n * @param naRm - If true, remove null/undefined/NaN before calculation\n * @returns Mean value, or NaN if array is empty or all NA\n *\n * @see R function: mean(x, na.rm = TRUE)\n *\n * @example\n * ```ts\n * mean([1, 2, 3, null, 4], true); // 2.5\n * mean([1, 2, 3, 4], false); // 2.5\n * ```\n */\nexport function mean(values: (number | null | undefined)[], naRm = false): number {\n  const filtered = naRm ? filterNA(values) : (values as number[]);\n  if (filtered.length === 0) return NaN;\n  return ss.mean(filtered);\n}\n\n/**\n * Calculate median of array, optionally removing NA/null values\n *\n * @param values - Array of values\n * @param naRm - If true, remove null/undefined/NaN before calculation\n * @returns Median value, or NaN if array is empty or all NA\n *\n * @see R function: median(x, na.rm = TRUE)\n */\nexport function median(values: (number | null | undefined)[], naRm = false): number {\n  const filtered = naRm ? filterNA(values) : (values as number[]);\n  if (filtered.length === 0) return NaN;\n  return ss.median(filtered);\n}\n\n/**\n * Calculate standard deviation of array\n *\n * @param values - Array of values\n * @param naRm - If true, remove null/undefined/NaN before calculation\n * @returns Standard deviation, or NaN if array is empty or all NA\n *\n * @see R function: sd(x, na.rm = TRUE)\n */\nexport function sd(values: (number | null | undefined)[], naRm = false): number {\n  const filtered = naRm ? filterNA(values) : (values as number[]);\n  if (filtered.length === 0) return NaN;\n  return ss.standardDeviation(filtered);\n}\n\n/**\n * Calculate Median Absolute Deviation (MAD)\n *\n * MAD = median(|x - median(x)|)\n *\n * @param values - Array of values\n * @param naRm - If true, remove null/undefined/NaN before calculation\n * @returns MAD value, or NaN if array is empty or all NA\n *\n * @see R function: mad(x, na.rm = TRUE)\n */\nexport function mad(values: (number | null | undefined)[], naRm = false): number {\n  const filtered = naRm ? filterNA(values) : (values as number[]);\n  if (filtered.length === 0) return NaN;\n\n  const med = ss.median(filtered);\n  const deviations = filtered.map(v => Math.abs(v - med));\n  return ss.median(deviations);\n}\n\n/**\n * Calculate Root Mean Square (RMS)\n *\n * RMS = sqrt(mean(x))\n *\n * @param values - Array of values\n * @param naRm - If true, remove null/undefined/NaN before calculation\n * @returns RMS value, or NaN if array is empty or all NA\n */\nexport function rms(values: (number | null | undefined)[], naRm = false): number {\n  const filtered = naRm ? filterNA(values) : (values as number[]);\n  if (filtered.length === 0) return NaN;\n\n  const sumSquares = filtered.reduce((sum, v) => sum + v * v, 0);\n  return Math.sqrt(sumSquares / filtered.length);\n}\n\n/**\n * Calculate differences between consecutive elements\n *\n * Similar to R's diff() function\n *\n * @param values - Array of values\n * @returns Array of differences, length = original length - 1\n *\n * @see R function: diff(x)\n *\n * @example\n * ```ts\n * diff([1, 3, 6, 10]); // [2, 3, 4]\n * ```\n */\nexport function diff(values: number[]): number[] {\n  if (values.length < 2) return [];\n\n  const result: number[] = [];\n  for (let i = 1; i < values.length; i++) {\n    result.push(values[i]! - values[i - 1]!);\n  }\n  return result;\n}\n\n/**\n * Filter out NA/null/undefined/NaN values from array\n *\n * @param values - Array potentially containing NA values\n * @returns Array with only valid numbers\n */\nexport function filterNA(values: (number | null | undefined)[]): number[] {\n  return values.filter((v): v is number =>\n    v !== null && v !== undefined && !Number.isNaN(v)\n  );\n}\n\n/**\n * Check if value is NA (null, undefined, or NaN)\n *\n * @param value - Value to check\n * @returns true if value is NA\n */\nexport function isNA(value: unknown): boolean {\n  return value === null || value === undefined || Number.isNaN(value);\n}\n\n/**\n * Count number of NA values in array\n *\n * @param values - Array to check\n * @returns Count of NA values\n */\nexport function countNA(values: (number | null | undefined)[]): number {\n  return values.filter(isNA).length;\n}\n\n/**\n * Calculate proportion of NA values in array\n *\n * @param values - Array to check\n * @returns Proportion of NA values [0-1]\n */\nexport function proportionNA(values: (number | null | undefined)[]): number {\n  if (values.length === 0) return 0;\n  return countNA(values) / values.length;\n}\n", "/**\n * Run-Length Encoding (RLE) utilities\n *\n * Implements R's rle() function for detecting consecutive runs of values\n * @module utils/rle\n */\n\n/**\n * Result of run-length encoding\n */\nexport interface RLEResult<T> {\n  /** Length of each run */\n  lengths: number[];\n  /** Value for each run */\n  values: T[];\n}\n\n/**\n * Run-length encoding: find consecutive runs of identical values\n *\n * Similar to R's rle() function. Detects sequences of consecutive\n * identical values and returns their lengths and values.\n *\n * @param data - Array to encode\n * @returns Object with lengths and values arrays\n *\n * @see R function: rle(x)\n *\n * @example\n * ```ts\n * rle([1, 1, 2, 2, 2, 3, 1])\n * // Returns: { lengths: [2, 3, 1, 1], values: [1, 2, 3, 1] }\n *\n * rle([true, true, false, false, false, true])\n * // Returns: { lengths: [2, 3, 1], values: [true, false, true] }\n * ```\n */\nexport function rle<T>(data: T[]): RLEResult<T> {\n  if (data.length === 0) {\n    return { lengths: [], values: [] };\n  }\n\n  const lengths: number[] = [];\n  const values: T[] = [];\n\n  let currentValue = data[0];\n  let currentLength = 1;\n\n  for (let i = 1; i < data.length; i++) {\n    const value = data[i];\n\n    // Check equality (handles NaN properly)\n    const isEqual =\n      value === currentValue ||\n      (Number.isNaN(value) && Number.isNaN(currentValue as unknown));\n\n    if (isEqual) {\n      currentLength++;\n    } else {\n      lengths.push(currentLength);\n      values.push(currentValue!);\n      currentValue = value;\n      currentLength = 1;\n    }\n  }\n\n  // Push the last run\n  lengths.push(currentLength);\n  values.push(currentValue!);\n\n  return { lengths, values };\n}\n\n/**\n * Find indices of consecutive runs matching a condition\n *\n * @param data - Array to search\n * @param predicate - Function to test each value\n * @param minLength - Minimum run length to include\n * @returns Array of {start, end, length} for each matching run\n *\n * @example\n * ```ts\n * findRuns([1, 2, 2, 2, 3, 4, 4], x => x === 2, 2)\n * // Returns: [{start: 1, end: 3, length: 3}]\n * ```\n */\nexport function findRuns<T>(\n  data: T[],\n  predicate: (value: T) => boolean,\n  minLength = 1\n): Array<{ start: number; end: number; length: number }> {\n  const matches = data.map(predicate);\n  const encoded = rle(matches);\n\n  const runs: Array<{ start: number; end: number; length: number }> = [];\n  let currentIndex = 0;\n\n  for (let i = 0; i < encoded.lengths.length; i++) {\n    const length = encoded.lengths[i]!;\n    const value = encoded.values[i];\n\n    if (value && length >= minLength) {\n      runs.push({\n        start: currentIndex,\n        end: currentIndex + length - 1,\n        length,\n      });\n    }\n\n    currentIndex += length;\n  }\n\n  return runs;\n}\n\n/**\n * Inverse run-length encoding: expand compressed runs\n *\n * @param rleData - RLE result to expand\n * @returns Expanded array\n *\n * @example\n * ```ts\n * inverseRLE({ lengths: [2, 3, 1], values: [1, 2, 3] })\n * // Returns: [1, 1, 2, 2, 2, 3]\n * ```\n */\nexport function inverseRLE<T>(rleData: RLEResult<T>): T[] {\n  const result: T[] = [];\n\n  for (let i = 0; i < rleData.lengths.length; i++) {\n    const length = rleData.lengths[i]!;\n    const value = rleData.values[i]!;\n\n    for (let j = 0; j < length; j++) {\n      result.push(value);\n    }\n  }\n\n  return result;\n}\n", "/**\n * Rolling window operations\n *\n * Implements R's zoo package rolling functions (rollmean, rollmedian)\n * with proper NA handling and alignment options\n * @module utils/rolling\n */\n\nimport { mean, median } from './statistics.js';\n\nexport type AlignType = 'left' | 'center' | 'right';\n\n/**\n * Options for rolling window operations\n */\nexport interface RollingOptions {\n  /** Window size (odd number recommended for center alignment) */\n  k: number;\n  /** Alignment: 'left', 'center', or 'right' */\n  align?: AlignType;\n  /** If true, pad output with NA. If false, use partial windows */\n  naPad?: boolean;\n  /** If true, use partial windows at edges */\n  partial?: boolean;\n}\n\n/**\n * Apply rolling window function with proper NA handling\n *\n * Mimics R's zoo::rollapply behavior\n *\n * @param data - Input array\n * @param k - Window size\n * @param fn - Function to apply to each window\n * @param options - Rolling options\n * @returns Array of rolling results\n *\n * @see R function: zoo::rollapply()\n */\nexport function rollapply(\n  data: (number | null | undefined)[],\n  k: number,\n  fn: (window: number[]) => number,\n  options: Partial<RollingOptions> = {}\n): (number | null)[] {\n  const { align = 'center', naPad = false, partial = true } = options;\n\n  if (k < 1) {\n    throw new Error('Window size k must be >= 1');\n  }\n\n  if (k > data.length) {\n    if (naPad) {\n      return new Array(data.length).fill(null);\n    }\n    throw new Error('Window size k cannot exceed data length');\n  }\n\n  const result: (number | null)[] = new Array(data.length);\n\n  for (let i = 0; i < data.length; i++) {\n    // Calculate window boundaries based on alignment\n    let start: number, end: number;\n\n    switch (align) {\n      case 'left':\n        start = i;\n        end = i + k - 1;\n        break;\n      case 'right':\n        start = i - k + 1;\n        end = i;\n        break;\n      case 'center':\n      default:\n        const halfWindow = Math.floor(k / 2);\n        start = i - halfWindow;\n        end = i + halfWindow;\n        // For even k, adjust to match R's behavior\n        if (k % 2 === 0) {\n          end = start + k - 1;\n        }\n        break;\n    }\n\n    // Check if window is out of bounds\n    const outOfBounds = start < 0 || end >= data.length;\n\n    if (outOfBounds) {\n      if (naPad) {\n        result[i] = null;\n        continue;\n      } else if (partial) {\n        // Adjust window to stay within bounds\n        start = Math.max(0, start);\n        end = Math.min(data.length - 1, end);\n      } else {\n        result[i] = null;\n        continue;\n      }\n    }\n\n    // Extract window and filter out NA values\n    const window: number[] = [];\n    for (let j = start; j <= end; j++) {\n      const value = data[j];\n      if (value !== null && value !== undefined && !Number.isNaN(value)) {\n        window.push(value);\n      }\n    }\n\n    // Apply function to window\n    if (window.length === 0) {\n      result[i] = null;\n    } else {\n      result[i] = fn(window);\n    }\n  }\n\n  return result;\n}\n\n/**\n * Rolling mean with NA handling\n *\n * Calculates moving average over a rolling window.\n * Mimics R's zoo::rollmean() behavior.\n *\n * @param data - Input array\n * @param k - Window size\n * @param align - Window alignment ('left', 'center', 'right')\n * @param naPad - If true, pad with NA instead of using partial windows\n * @param partial - If true, use partial windows at edges\n * @returns Array of rolling means\n *\n * @see R function: zoo::rollmean(x, k, align = \"center\", na.pad = FALSE)\n *\n * @example\n * ```ts\n * rollmean([1, 2, 3, 4, 5], 3, 'center')\n * // Returns: [null, 2, 3, 4, null] (with partial=false)\n * // Returns: [1.5, 2, 3, 4, 4.5] (with partial=true)\n * ```\n */\nexport function rollmean(\n  data: (number | null | undefined)[],\n  k: number,\n  align: AlignType = 'center',\n  naPad = false,\n  partial = true\n): (number | null)[] {\n  return rollapply(data, k, mean, { align, naPad, partial });\n}\n\n/**\n * Rolling median with NA handling\n *\n * Calculates moving median over a rolling window.\n * Mimics R's zoo::rollmedian() behavior.\n *\n * @param data - Input array\n * @param k - Window size (should be odd for center alignment)\n * @param align - Window alignment ('left', 'center', 'right')\n * @param naPad - If true, pad with NA instead of using partial windows\n * @param partial - If true, use partial windows at edges\n * @returns Array of rolling medians\n *\n * @see R function: zoo::rollmedian(x, k, align = \"center\", na.pad = TRUE)\n *\n * @example\n * ```ts\n * rollmedian([1, 2, 10, 4, 5], 3, 'center')\n * // Returns: [null, 2, 4, 5, null] (filters outliers)\n * ```\n */\nexport function rollmedian(\n  data: (number | null | undefined)[],\n  k: number,\n  align: AlignType = 'center',\n  naPad = true,\n  partial = false\n): (number | null)[] {\n  return rollapply(data, k, median, { align, naPad, partial });\n}\n\n/**\n * Moving mean filter that ignores NAs\n *\n * This is the exact implementation used in R's PreprocessingFunctions.R\n * Uses partial windows and ignores NA values when calculating mean.\n *\n * @param data - Input vector\n * @param k - Window size\n * @returns Filtered vector with same length as input\n *\n * @see R function: movmean.filter() in PreprocessingFunctions.R\n */\nexport function movmeanFilter(\n  data: (number | null | undefined)[],\n  k = 3\n): (number | null)[] {\n  return rollapply(data, k, mean, {\n    align: 'center',\n    naPad: false,\n    partial: true,\n  });\n}\n", "/**\n * Input validation utilities\n *\n * Helpers for validating function parameters and data structures\n * @module utils/validation\n */\n\nimport type { RawGazeData, ProcessedGazeData } from '../types/index.js';\n\n/**\n * Validate that gaze data has required fields\n *\n * @param data - Gaze data to validate\n * @param requiredFields - Fields that must be present\n * @throws Error if required fields are missing\n */\nexport function validateGazeData(\n  data: unknown[],\n  requiredFields: string[] = ['timestamp', 'x', 'y']\n): void {\n  if (!Array.isArray(data) || data.length === 0) {\n    throw new Error('Gaze data must be a non-empty array');\n  }\n\n  const firstRow = data[0] as Record<string, unknown>;\n  const missingFields = requiredFields.filter(\n    field => !(field in firstRow)\n  );\n\n  if (missingFields.length > 0) {\n    throw new Error(\n      `Missing required fields in gaze data: ${missingFields.join(', ')}`\n    );\n  }\n}\n\n/**\n * Validate that timestamps are monotonically increasing\n *\n * @param timestamps - Array of timestamps\n * @throws Error if timestamps are not increasing\n */\nexport function validateTimestamps(timestamps: number[]): void {\n  for (let i = 1; i < timestamps.length; i++) {\n    if (timestamps[i]! <= timestamps[i - 1]!) {\n      throw new Error(\n        `Timestamps must be monotonically increasing. ` +\n        `Found ${timestamps[i - 1]} followed by ${timestamps[i]} at index ${i}`\n      );\n    }\n  }\n}\n\n/**\n * Validate parameter is within valid range\n *\n * @param name - Parameter name (for error message)\n * @param value - Parameter value\n * @param min - Minimum allowed value\n * @param max - Maximum allowed value\n * @throws Error if value is out of range\n */\nexport function validateRange(\n  name: string,\n  value: number,\n  min: number,\n  max: number\n): void {\n  if (value < min || value > max) {\n    throw new Error(\n      `Parameter '${name}' must be between ${min} and ${max}, got ${value}`\n    );\n  }\n}\n\n/**\n * Validate parameter is positive\n *\n * @param name - Parameter name (for error message)\n * @param value - Parameter value\n * @throws Error if value is not positive\n */\nexport function validatePositive(name: string, value: number): void {\n  if (value <= 0) {\n    throw new Error(`Parameter '${name}' must be positive, got ${value}`);\n  }\n}\n\n/**\n * Validate that oneDegree parameter is reasonable given gaze coordinates\n *\n * @param gazeData - Gaze data\n * @param oneDegree - One degree in coordinate units\n * @param xcol - Name of x coordinate column\n * @throws Warning if oneDegree seems too large\n */\nexport function validateOneDegree(\n  gazeData: RawGazeData[] | ProcessedGazeData[],\n  oneDegree: number,\n  xcol = 'x'\n): void {\n  const xValues = gazeData\n    .map(d => (d as unknown as Record<string, number>)[xcol])\n    .filter((x): x is number => x != null && !Number.isNaN(x));\n\n  if (xValues.length === 0) {\n    console.warn('No valid x coordinates found in gaze data');\n    return;\n  }\n\n  const maxX = Math.max(...xValues);\n\n  if (maxX < oneDegree) {\n    console.warn(\n      `Warning: oneDegree (${oneDegree}) is larger than max x coordinate (${maxX}). ` +\n      `Make sure gaze coordinates are in the same scale as oneDegree parameter!`\n    );\n  }\n}\n\n/**\n * Check if gaze data has likely issues\n *\n * @param gazeData - Gaze data to check\n * @returns Object with diagnostic information\n */\nexport function diagnoseGazeData(gazeData: RawGazeData[]): {\n  sampleCount: number;\n  missingCount: number;\n  missingProportion: number;\n  medianSampleInterval: number;\n  hasNegativeTimestamps: boolean;\n  xRange: [number, number];\n  yRange: [number, number];\n} {\n  const timestamps = gazeData.map(d => d.timestamp).filter(t => !Number.isNaN(t));\n  const xValues = gazeData.map(d => d.x).filter(x => x != null && !Number.isNaN(x));\n  const yValues = gazeData.map(d => d.y).filter(y => y != null && !Number.isNaN(y));\n\n  const missingCount = gazeData.length - Math.min(xValues.length, yValues.length);\n  const missingProportion = missingCount / gazeData.length;\n\n  const intervals = [];\n  for (let i = 1; i < timestamps.length; i++) {\n    intervals.push(timestamps[i]! - timestamps[i - 1]!);\n  }\n  const medianSampleInterval = intervals.length > 0\n    ? intervals.sort((a, b) => a - b)[Math.floor(intervals.length / 2)]!\n    : 0;\n\n  return {\n    sampleCount: gazeData.length,\n    missingCount,\n    missingProportion,\n    medianSampleInterval,\n    hasNegativeTimestamps: timestamps.some(t => t < 0),\n    xRange: [Math.min(...xValues), Math.max(...xValues)],\n    yRange: [Math.min(...yValues), Math.max(...yValues)],\n  };\n}\n", "/**\n * Interpolation functions for filling gaps in gaze data\n *\n * @module preprocessing/interpolate\n */\n\nimport { rle } from '../utils/rle.js';\nimport { median } from '../utils/statistics.js';\n\n/**\n * Information about a gap in the data\n */\ninterface Gap {\n  start: number;\n  stop: number;\n  length: number;\n}\n\n/**\n * Interpolate over gaps (consecutive NAs) in a vector using margin-based approach\n *\n * This function fills gaps by calculating the median of samples before and after\n * the gap, then setting all gap samples to the mean of those medians.\n *\n * @param data - Vector to interpolate\n * @param margin - Number of samples before/after gap to use for interpolation\n * @param maxGap - Maximum gap length (in samples) to interpolate over\n * @returns Interpolated vector\n *\n * @see R function: interpolate_with_margin() in PreprocessingFunctions.R:151\n *\n * @example\n * ```ts\n * const data = [1, 2, null, null, null, 6, 7];\n * interpolateWithMargin(data, 1, 5);\n * // Fills nulls with mean of median([1,2]) and median([6,7])\n * ```\n */\nexport function interpolateWithMargin(\n  data: (number | null | undefined)[],\n  margin: number,\n  maxGap: number\n): (number | null)[] {\n  // Create copy to avoid mutating input, map undefined to null\n  const result: (number | null)[] = data.map(v => (v === undefined ? null : v));\n\n  // Find all gaps (consecutive NA values)\n  const gaps = findGaps(data, maxGap);\n\n  // Interpolate each gap\n  for (const gap of gaps) {\n    const { start, stop } = gap;\n\n    // Check if we have enough data before and after for margin\n    const hasMarginBefore = start - margin >= 0;\n    const hasMarginAfter = stop + margin < data.length;\n\n    if (!hasMarginBefore || !hasMarginAfter) {\n      // Can't interpolate - not enough surrounding data\n      continue;\n    }\n\n    // Get samples before gap\n    const beforeSamples: number[] = [];\n    for (let i = start - margin; i < start; i++) {\n      const value = data[i];\n      if (value != null && !Number.isNaN(value)) {\n        beforeSamples.push(value);\n      }\n    }\n\n    // Get samples after gap\n    const afterSamples: number[] = [];\n    for (let i = stop + 1; i <= stop + margin; i++) {\n      const value = data[i];\n      if (value != null && !Number.isNaN(value)) {\n        afterSamples.push(value);\n      }\n    }\n\n    // Calculate medians\n    if (beforeSamples.length === 0 || afterSamples.length === 0) {\n      // Not enough valid data to interpolate\n      continue;\n    }\n\n    const interpolBefore = median(beforeSamples, false);\n    const interpolAfter = median(afterSamples, false);\n\n    if (Number.isNaN(interpolBefore) || Number.isNaN(interpolAfter)) {\n      continue;\n    }\n\n    // Fill gap with mean of the two medians\n    const fillValue = (interpolBefore + interpolAfter) / 2;\n\n    for (let i = start; i <= stop; i++) {\n      result[i] = fillValue;\n    }\n  }\n\n  return result;\n}\n\n/**\n * Find gaps (consecutive NA values) in data\n *\n * @param data - Data to search\n * @param maxGap - Maximum gap length to include\n * @returns Array of gap information\n */\nfunction findGaps(\n  data: (number | null | undefined)[],\n  maxGap: number\n): Gap[] {\n  // Create boolean array: true = NA, false = valid\n  const isNA = data.map(\n    v => v === null || v === undefined || Number.isNaN(v)\n  );\n\n  // Run-length encode to find consecutive NAs\n  const encoded = rle(isNA);\n\n  const gaps: Gap[] = [];\n  let currentIndex = 0;\n\n  for (let i = 0; i < encoded.lengths.length; i++) {\n    const length = encoded.lengths[i]!;\n    const value = encoded.values[i];\n\n    // If this is a run of NAs and within maxGap\n    if (value && length <= maxGap) {\n      gaps.push({\n        start: currentIndex,\n        stop: currentIndex + length - 1,\n        length,\n      });\n    }\n\n    currentIndex += length;\n  }\n\n  return gaps;\n}\n", "/**\n * Main preprocessing pipeline for gaze data\n *\n * Interpolates over gaps and smooths x and y vectors\n *\n * @module preprocessing/preprocess\n */\n\nimport type { RawGazeData, ProcessedGazeData, PreprocessParams } from '../types/index.js';\nimport { interpolateWithMargin } from './interpolate.js';\nimport { movmeanFilter } from '../utils/rolling.js';\nimport { mean } from '../utils/statistics.js';\n\n/**\n * Default preprocessing parameters\n */\nexport const DEFAULT_PREPROCESS_PARAMS: PreprocessParams = {\n  maxGapMs: 75,\n  marginMs: 5,\n  filterMs: 15,\n  xcol: 'x',\n  ycol: 'y',\n  naIgnore: true,\n};\n\n/**\n * Preprocess gaze data: interpolation and smoothing\n *\n * This function performs two main operations:\n * 1. **Interpolation**: Fills gaps (consecutive NAs) up to maxGapMs using\n *    margin-based interpolation\n * 2. **Smoothing**: Applies moving average filter to reduce noise\n *\n * The original unprocessed coordinates are preserved for comparison.\n * A theoretical timestamp is calculated based on median sampling rate.\n *\n * @param gazeRaw - Raw gaze data from eye tracker\n * @param params - Preprocessing parameters (or use defaults)\n * @returns Processed gaze data ready for fixation detection\n *\n * @see R function: preprocess_gaze() in PreprocessingFunctions.R:72\n *\n * @example\n * ```ts\n * const processed = preprocessGaze(rawData, {\n *   maxGapMs: 75,  // Interpolate gaps up to 75ms\n *   marginMs: 5,   // Use 5ms margin for interpolation\n *   filterMs: 15,  // 15ms moving average window\n * });\n * ```\n */\nexport function preprocessGaze(\n  gazeRaw: RawGazeData[],\n  params: Partial<PreprocessParams> = {}\n): ProcessedGazeData[] {\n  const {\n    maxGapMs,\n    marginMs,\n    filterMs,\n    xcol,\n    ycol,\n    naIgnore,\n  } = { ...DEFAULT_PREPROCESS_PARAMS, ...params };\n\n  if (gazeRaw.length === 0) {\n    throw new Error('Gaze data cannot be empty');\n  }\n\n  // Calculate median sample interval\n  const timestamps = gazeRaw.map(d => d.timestamp);\n  let oneSample: number;\n\n  if (gazeRaw.length > 500) {\n    // Use first 500 samples for efficiency\n    const firstIntervals = [];\n    for (let i = 1; i < Math.min(500, timestamps.length); i++) {\n      firstIntervals.push(timestamps[i]! - timestamps[i - 1]!);\n    }\n    oneSample = mean(firstIntervals, true);\n  } else {\n    const intervals = [];\n    for (let i = 1; i < timestamps.length; i++) {\n      intervals.push(timestamps[i]! - timestamps[i - 1]!);\n    }\n    oneSample = mean(intervals, true);\n  }\n\n  // Validate timestamps\n  if (timestamps.some(t => t < 0)) {\n    console.warn('Warning: timestamp column contains negative values. Check data file.');\n  }\n\n  if (oneSample < 0.02 || oneSample > 100) {\n    console.warn(\n      'Unlikely sample-to-sample difference in timestamps. ' +\n      'Are timestamps in milliseconds?'\n    );\n  }\n\n  // Convert time parameters to sample counts\n  const maxGap = Math.round(maxGapMs / oneSample);\n  const margin = Math.round(marginMs / oneSample);\n  const filterWindow = Math.round(filterMs / oneSample);\n\n  // Extract x and y coordinates\n  const xData = gazeRaw.map(d => (d as unknown as Record<string, number>)[xcol] ?? null);\n  const yData = gazeRaw.map(d => (d as unknown as Record<string, number>)[ycol] ?? null);\n\n  // Interpolate over gaps\n  const xInterpolated = interpolateWithMargin(xData, margin, maxGap);\n  const yInterpolated = interpolateWithMargin(yData, margin, maxGap);\n\n  // Smooth the x and y vectors\n  let xSmoothed: (number | null)[];\n  let ySmoothed: (number | null)[];\n\n  if (naIgnore) {\n    xSmoothed = movmeanFilter(xInterpolated, filterWindow);\n    ySmoothed = movmeanFilter(yInterpolated, filterWindow);\n  } else {\n    // Use rolling mean without ignoring NAs (less common)\n    xSmoothed = movmeanFilter(xInterpolated, filterWindow);\n    ySmoothed = movmeanFilter(yInterpolated, filterWindow);\n  }\n\n  // Create processed data array\n  const processed: ProcessedGazeData[] = gazeRaw.map((d, i) => {\n    // Calculate theoretical timestamp\n    const timestampTheoretical = i * oneSample;\n\n    return {\n      timestamp: d.timestamp,\n      x: xSmoothed[i] ?? NaN,\n      y: ySmoothed[i] ?? NaN,\n      xUnprocessed: xData[i] ?? NaN,\n      yUnprocessed: yData[i] ?? NaN,\n      timestampTheoretical,\n      sample: i,\n    };\n  });\n\n  return processed;\n}\n", "/**\n * RMS (Root Mean Square) calculation functions\n *\n * RMS is used as a precision metric in eye tracking.\n * Lower RMS indicates higher precision/stability.\n *\n * @module preprocessing/rms\n */\n\nimport type { RawGazeData, ProcessedGazeData } from '../types/index.js';\n\n/**\n * Calculate sample-to-sample root mean square deviation (RMS)\n *\n * RMS is a measure of precision - lower values indicate more stable/precise gaze.\n * Calculates the RMS of Euclidean distances between consecutive samples.\n *\n * Formula: RMS = sqrt(mean(distance)) / oneDegree\n *\n * @param gazeData - Gaze data with x, y coordinates\n * @param xcol - Name of x coordinate column\n * @param ycol - Name of y coordinate column\n * @param oneDegree - One degree of visual field in coordinate units\n * @returns RMS deviation in degrees\n *\n * @see R function: calculate_rms() in PreprocessingFunctions.R:36\n *\n * @example\n * ```ts\n * const rms = calculateRMS(gazeData, 'x', 'y', 40);\n * console.log(`Precision: ${rms.toFixed(3)} degrees`);\n * ```\n */\nexport function calculateRMS(\n  gazeData: (RawGazeData | ProcessedGazeData)[],\n  xcol = 'x',\n  ycol = 'y',\n  oneDegree = 40\n): number {\n  if (gazeData.length < 2) {\n    return NaN;\n  }\n\n  // Calculate sample-to-sample distances\n  const distancesSquared: number[] = [];\n\n  for (let i = 1; i < gazeData.length; i++) {\n    const prev = gazeData[i - 1] as unknown as Record<string, number>;\n    const curr = gazeData[i] as unknown as Record<string, number>;\n\n    const x1 = prev[xcol];\n    const y1 = prev[ycol];\n    const x2 = curr[xcol];\n    const y2 = curr[ycol];\n\n    // Skip if any coordinate is NA\n    if (\n      x1 == null || y1 == null || x2 == null || y2 == null ||\n      Number.isNaN(x1) || Number.isNaN(y1) || Number.isNaN(x2) || Number.isNaN(y2)\n    ) {\n      continue;\n    }\n\n    // Calculate Euclidean distance\n    const dx = x2 - x1;\n    const dy = y2 - y1;\n    const distance = Math.sqrt(dx * dx + dy * dy);\n\n    distancesSquared.push(distance * distance);\n  }\n\n  if (distancesSquared.length === 0) {\n    return NaN;\n  }\n\n  // Calculate RMS\n  const meanSquared = distancesSquared.reduce((sum, d) => sum + d, 0) / distancesSquared.length;\n  const rms = Math.sqrt(meanSquared);\n\n  // Normalize to degrees\n  return rms / oneDegree;\n}\n", "/**\n * Downsampling functions for gaze data\n *\n * Used by I2MC algorithm to improve robustness to noise\n *\n * @module preprocessing/downsample\n */\n\nimport type { ProcessedGazeData } from '../types/index.js';\nimport { mean } from '../utils/statistics.js';\n\n/**\n * Downsampled gaze data\n */\nexport interface DownsampledData {\n  x: number;\n  y: number;\n  firstSample: number;\n  lastSample: number;\n}\n\n/**\n * Downsample gaze data by a specified factor\n *\n * Data are downsampled by splitting into bins and calculating the mean of each bin.\n * This is used by I2MC algorithm to make fixation detection more robust to noise.\n *\n * @param gazeData - Input gaze data\n * @param factor - Downsampling factor (e.g., 10 for 1000Hz  100Hz)\n * @param xcol - Name of x coordinate column\n * @param ycol - Name of y coordinate column\n * @returns Downsampled data with bin information\n *\n * @see R function: downsample_gaze() in FixationFilterFunctions.R:602\n *\n * @example\n * ```ts\n * // Downsample 1200Hz data to 120Hz\n * const downsampled = downsampleGaze(gazeData, 10);\n * ```\n */\nexport function downsampleGaze(\n  gazeData: ProcessedGazeData[],\n  factor: number,\n  xcol = 'x',\n  ycol = 'y'\n): DownsampledData[] {\n  if (factor < 1) {\n    throw new Error('Downsampling factor must be >= 1');\n  }\n\n  if (factor === 1) {\n    // No downsampling needed\n    return gazeData.map((d, i) => ({\n      x: (d as unknown as Record<string, number>)[xcol]!,\n      y: (d as unknown as Record<string, number>)[ycol]!,\n      firstSample: i,\n      lastSample: i,\n    }));\n  }\n\n  const nBins = Math.floor(gazeData.length / factor);\n  const result: DownsampledData[] = [];\n\n  for (let bin = 0; bin < nBins; bin++) {\n    const start = bin * factor;\n    const end = start + factor;\n\n    // Extract values for this bin\n    const xValues: number[] = [];\n    const yValues: number[] = [];\n\n    for (let i = start; i < end && i < gazeData.length; i++) {\n      const data = gazeData[i] as unknown as Record<string, number>;\n      const x = data[xcol];\n      const y = data[ycol];\n\n      if (x != null && !Number.isNaN(x)) {\n        xValues.push(x);\n      }\n      if (y != null && !Number.isNaN(y)) {\n        yValues.push(y);\n      }\n    }\n\n    // Calculate mean of bin\n    const xMean = mean(xValues, false);\n    const yMean = mean(yValues, false);\n\n    result.push({\n      x: xMean,\n      y: yMean,\n      firstSample: start,\n      lastSample: Math.min(end - 1, gazeData.length - 1),\n    });\n  }\n\n  return result;\n}\n", "/**\n * Data-driven threshold suggestion for adaptive velocity algorithm\n *\n * Based on Nystrm & Holmqvist (2010)\n *\n * @module preprocessing/threshold\n */\n\nimport type { ProcessedGazeData, ThresholdSuggestion } from '../types/index.js';\nimport { mean, sd } from '../utils/statistics.js';\nimport { rollmedian } from '../utils/rolling.js';\n\n/**\n * Find valid periods in data (consecutive samples below threshold)\n *\n * @param velocity - Velocity vector\n * @param threshold - Threshold value\n * @param minSamples - Minimum length of consecutive run\n * @param margin - Margin to shrink periods at both ends\n * @returns Boolean array marking valid samples\n *\n * @see R function: find.valid.periods() in PreprocessingFunctions.R:201\n */\nfunction findValidPeriods(\n  velocity: number[],\n  threshold: number,\n  minSamples: number,\n  margin: number\n): boolean[] {\n  const result = new Array(velocity.length).fill(false);\n\n  // Find runs of values below threshold\n  let runStart = -1;\n  let runLength = 0;\n\n  for (let i = 0; i < velocity.length; i++) {\n    const v = velocity[i];\n\n    if (v != null && !Number.isNaN(v) && v <= threshold) {\n      // Start or continue run\n      if (runStart === -1) {\n        runStart = i;\n        runLength = 1;\n      } else {\n        runLength++;\n      }\n    } else {\n      // End run\n      if (runStart !== -1 && runLength >= minSamples) {\n        // Mark this run as valid (with margins)\n        const start = runStart + margin;\n        const end = runStart + runLength - margin - 1;\n\n        if (start <= end) {\n          for (let j = start; j <= end; j++) {\n            result[j] = true;\n          }\n        }\n      }\n      runStart = -1;\n      runLength = 0;\n    }\n  }\n\n  // Handle final run\n  if (runStart !== -1 && runLength >= minSamples) {\n    const start = runStart + margin;\n    const end = runStart + runLength - margin - 1;\n\n    if (start <= end) {\n      for (let j = start; j <= end; j++) {\n        result[j] = true;\n      }\n    }\n  }\n\n  return result;\n}\n\n/**\n * Suggest velocity thresholds for adaptive saccade detection\n *\n * Implements iterative threshold determination based on Nystrm & Holmqvist (2010).\n * Peak threshold is iteratively adjusted until convergence, then onset threshold\n * is calculated.\n *\n * Algorithm:\n * 1. Start with initial peak threshold\n * 2. Find samples below threshold in consecutive runs\n * 3. Calculate M + 6*SD of those samples as new peak threshold\n * 4. Repeat until convergence (difference < 1 degree)\n * 5. Calculate onset threshold as M + onset_sd*SD\n *\n * @param gazeData - Preprocessed gaze data\n * @param xcol - Name of x coordinate column\n * @param ycol - Name of y coordinate column\n * @param oneDegree - One degree of visual field in coordinate units\n * @param velocityFilterMs - Window for velocity smoothing in milliseconds\n * @param peakThresholdStart - Initial peak threshold in degrees/second\n * @param onsetThresholdSd - SD multiplier for onset threshold (default 3)\n * @param minPeriodMs - Minimum period length for threshold estimation\n * @param marginMs - Margin around periods to exclude\n * @returns Suggested thresholds and velocity vector\n *\n * @see R function: suggest_threshold() in PreprocessingFunctions.R:256\n *\n * @example\n * ```ts\n * const thresholds = suggestThreshold(processedData);\n * console.log(`Peak: ${thresholds.peakThreshold}/s`);\n * console.log(`Onset: ${thresholds.onsetThreshold}/s`);\n * ```\n */\nexport function suggestThreshold(\n  gazeData: ProcessedGazeData[],\n  xcol = 'x',\n  ycol = 'y',\n  oneDegree = 40,\n  velocityFilterMs = 10,\n  peakThresholdStart = 130,\n  onsetThresholdSd = 3,\n  minPeriodMs = 40,\n  marginMs = 3\n): ThresholdSuggestion {\n  // Calculate sample interval\n  const timestamps = gazeData.map(d => d.timestamp);\n  const intervals = [];\n  for (let i = 1; i < timestamps.length; i++) {\n    intervals.push(timestamps[i]! - timestamps[i - 1]!);\n  }\n  const oneSample = mean(intervals, true);\n\n  if (oneSample < 0.02) {\n    console.warn(\n      'Unlikely small sample-to-sample difference in timestamps. ' +\n      'Are timestamps in milliseconds?'\n    );\n  }\n\n  // Calculate sample-to-sample velocity\n  const velocity: number[] = [];\n\n  for (let i = 0; i < gazeData.length; i++) {\n    if (i === 0) {\n      velocity.push(NaN);\n      continue;\n    }\n\n    const prev = gazeData[i - 1] as unknown as Record<string, number>;\n    const curr = gazeData[i] as unknown as Record<string, number>;\n\n    const x1 = prev[xcol];\n    const y1 = prev[ycol];\n    const x2 = curr[xcol];\n    const y2 = curr[ycol];\n\n    if (\n      x1 == null || y1 == null || x2 == null || y2 == null ||\n      Number.isNaN(x1) || Number.isNaN(y1) || Number.isNaN(x2) || Number.isNaN(y2)\n    ) {\n      velocity.push(NaN);\n      continue;\n    }\n\n    const dx = x2 - x1;\n    const dy = y2 - y1;\n    const distance = Math.sqrt(dx * dx + dy * dy);\n\n    // Convert to degrees\n    const distanceDeg = distance / oneDegree;\n\n    // Convert to degrees per second\n    const velocityDegPerSec = (distanceDeg / oneSample) * 1000;\n\n    velocity.push(velocityDegPerSec);\n  }\n\n  // Smooth velocity vector if requested\n  let smoothedVelocity = velocity;\n  if (velocityFilterMs != null && !Number.isNaN(velocityFilterMs)) {\n    const velocitySmoothWindow = Math.round(velocityFilterMs / oneSample);\n    smoothedVelocity = rollmedian(velocity, velocitySmoothWindow, 'center', true, false)\n      .map(v => v ?? NaN);\n  }\n\n  // Iteratively find peak threshold\n  const minPeriodSamples = Math.round(minPeriodMs / oneSample);\n  const marginSamples = Math.round(marginMs / oneSample);\n\n  let peakThreshold = peakThresholdStart;\n  let iteration = 0;\n  const maxIterations = 100;\n  let converged = false;\n\n  while (!converged && iteration < maxIterations) {\n    // Find valid periods (below threshold, long enough, with margins)\n    const keep = findValidPeriods(\n      smoothedVelocity,\n      peakThreshold,\n      minPeriodSamples,\n      marginSamples\n    );\n\n    // Get velocities in valid periods\n    const validVelocities = smoothedVelocity.filter((v, i) => keep[i] && !Number.isNaN(v));\n\n    if (validVelocities.length === 0) {\n      console.warn(\n        'No valid periods found for threshold estimation. ' +\n        'Check for noise/artifacts in data. ' +\n        'Try adjusting peakThresholdStart.'\n      );\n      break;\n    }\n\n    // Calculate new threshold\n    const m = mean(validVelocities, true);\n    const s = sd(validVelocities, true);\n    const proposedPeakThreshold = m + 6 * s;\n    // Note: onset threshold is calculated after convergence\n\n    // Check convergence\n    if (Math.abs(peakThreshold - proposedPeakThreshold) <= 1) {\n      converged = true;\n      peakThreshold = proposedPeakThreshold;\n    } else {\n      peakThreshold = proposedPeakThreshold;\n    }\n\n    iteration++;\n  }\n\n  if (iteration < 3) {\n    console.warn(\n      `Peak threshold algorithm stopped after only ${iteration} iterations. ` +\n      'The identified threshold may be unreliable. ' +\n      'Check for noise/artifacts. Try adjusting peakThresholdStart downwards.'\n    );\n  }\n\n  // Calculate final onset threshold\n  const finalValidPeriods = smoothedVelocity.filter(\n    v => !Number.isNaN(v) && v < peakThreshold\n  );\n  const m = mean(finalValidPeriods, true);\n  const s = sd(finalValidPeriods, true);\n  const onsetThreshold = m + onsetThresholdSd * s;\n\n  return {\n    peakThreshold,\n    onsetThreshold,\n    velocity: smoothedVelocity,\n  };\n}\n", "/**\n * Fixation utility functions\n *\n * Core functions for calculating, merging, and trimming fixations\n * Used by all fixation detection algorithms\n *\n * @module core/fixation-utils\n */\n\nimport type { Fixation, ProcessedGazeData, FilteredGazeData } from '../types/index.js';\nimport { euclideanDistance } from '../utils/math.js';\nimport { median, mad, isNA, mean } from '../utils/statistics.js';\n\n/**\n * Summarize metrics for a single fixation\n *\n * Calculates center position, duration, precision (RMSD), dispersion,\n * and proportion of missing samples for a fixation period.\n *\n * @param startIndex - First sample index in fixation\n * @param endIndex - Last sample index in fixation\n * @param x - Array of x coordinates\n * @param y - Array of y coordinates\n * @param timestamps - Array of timestamps in milliseconds\n * @param oneDegree - One degree of visual field in coordinate units\n * @returns Fixation object with all metrics\n *\n * @see R function: summarize_fixation_metrics() in FixationFilterFunctions.R:1151\n *\n * @example\n * ```ts\n * const fixation = summarizeFixationMetrics(\n *   100, 150,\n *   xCoordinates, yCoordinates, timestamps,\n *   40  // one degree = 40 pixels\n * );\n * console.log(`Fixation at (${fixation.x}, ${fixation.y})`);\n * console.log(`Duration: ${fixation.duration}ms`);\n * console.log(`Precision: ${fixation.rmsd.toFixed(3)}`);\n * ```\n */\nexport function summarizeFixationMetrics(\n  startIndex: number,\n  endIndex: number,\n  x: (number | null | undefined)[],\n  y: (number | null | undefined)[],\n  timestamps: number[],\n  oneDegree = 40\n): Fixation {\n  // Extract fixation samples\n  const xSamples: number[] = [];\n  const ySamples: number[] = [];\n  let missingCount = 0;\n\n  for (let i = startIndex; i <= endIndex; i++) {\n    const xVal = x[i];\n    const yVal = y[i];\n\n    if (isNA(xVal) || isNA(yVal)) {\n      missingCount++;\n    } else {\n      xSamples.push(xVal as number);\n      ySamples.push(yVal as number);\n    }\n  }\n\n  // Calculate fixation center\n  const fixationX = mean(xSamples, false);\n  const fixationY = mean(ySamples, false);\n\n  // Calculate RMS from fixation center (dispersion measure)\n  const distancesFromCenter: number[] = [];\n  for (let i = 0; i < xSamples.length; i++) {\n    const dx = xSamples[i]! - fixationX;\n    const dy = ySamples[i]! - fixationY;\n    distancesFromCenter.push(Math.sqrt(dx * dx + dy * dy));\n  }\n\n  const rmsFromCenter =\n    distancesFromCenter.length > 0\n      ? Math.sqrt(\n          distancesFromCenter.reduce((sum, d) => sum + d * d, 0) /\n            distancesFromCenter.length\n        ) / oneDegree\n      : NaN;\n\n  // Calculate sample-to-sample RMS (precision measure)\n  const sampleToSampleDistances: number[] = [];\n  for (let i = 1; i < xSamples.length; i++) {\n    const dx = xSamples[i]! - xSamples[i - 1]!;\n    const dy = ySamples[i]! - ySamples[i - 1]!;\n    sampleToSampleDistances.push(Math.sqrt(dx * dx + dy * dy));\n  }\n\n  const rmsd =\n    sampleToSampleDistances.length > 0\n      ? Math.sqrt(\n          sampleToSampleDistances.reduce((sum, d) => sum + d * d, 0) /\n            sampleToSampleDistances.length\n        ) / oneDegree\n      : NaN;\n\n  // Calculate duration and timing\n  const onset = timestamps[startIndex]!;\n  const offset = timestamps[endIndex]!;\n  const duration = offset - onset;\n\n  // Calculate proportion of missing samples\n  const totalSamples = endIndex - startIndex + 1;\n  const missingSamples = missingCount / totalSamples;\n\n  return {\n    x: fixationX,\n    y: fixationY,\n    onset,\n    offset,\n    duration,\n    rmsd: Number.isNaN(rmsd) ? 0 : rmsd,\n    rmsFromCenter: Number.isNaN(rmsFromCenter) ? 0 : rmsFromCenter,\n    missingSamples,\n    firstLine: startIndex,\n    lastLine: endIndex,\n  };\n}\n\n/**\n * Merge adjacent fixations that are close in space and time\n *\n * Loops through fixations and merges those within distance and time thresholds.\n * After merging, recalculates all fixation metrics.\n *\n * @param fixations - Array of fixations to merge\n * @param gazeData - Original sample-by-sample gaze data\n * @param distanceThreshold - Maximum distance between fixations to merge (degrees)\n * @param msThreshold - Maximum time between fixations to merge (milliseconds)\n * @param oneDegree - One degree of visual field in coordinate units\n * @param xcol - Name of x coordinate column\n * @param ycol - Name of y coordinate column\n * @returns Array of fixations after merging\n *\n * @see R function: merge_adjacent_fixations() in FixationFilterFunctions.R:14\n *\n * @example\n * ```ts\n * const merged = mergeAdjacentFixations(\n *   fixations,\n *   gazeData,\n *   0.5,  // Merge fixations within 0.5 degrees\n *   75,   // Merge fixations within 75ms\n *   40\n * );\n * console.log(`Merged ${fixations.length - merged.length} fixations`);\n * ```\n */\nexport function mergeAdjacentFixations(\n  fixations: Fixation[],\n  gazeData: (ProcessedGazeData | FilteredGazeData)[],\n  distanceThreshold = 0.5,\n  msThreshold = 75,\n  oneDegree = 40,\n  xcol = 'xRaw',\n  ycol = 'yRaw'\n): Fixation[] {\n  if (fixations.length <= 1) {\n    return fixations;\n  }\n\n  // Create a copy to avoid mutating input\n  const result = [...fixations];\n\n  console.log('Merging adjacent fixations');\n\n  let i = 0;\n  while (i < result.length - 1) {\n    const current = result[i]!;\n    const next = result[i + 1]!;\n\n    // Calculate distance between fixation centers (in degrees)\n    const distance =\n      euclideanDistance(current.x, current.y, next.x, next.y) / oneDegree;\n\n    // Calculate time elapsed between fixations (in ms)\n    const timeElapsed = next.onset - current.offset;\n\n    // Check if fixations should be merged\n    if (distance < distanceThreshold && timeElapsed < msThreshold) {\n      // Merge: create new fixation spanning both periods\n      const startIndex = current.firstLine;\n      const endIndex = next.lastLine;\n\n      // Extract coordinates for merged period\n      const xData = gazeData.map(d => (d as unknown as Record<string, number>)[xcol] ?? null);\n      const yData = gazeData.map(d => (d as unknown as Record<string, number>)[ycol] ?? null);\n      const timestamps = gazeData.map(d => d.timestamp);\n\n      const mergedFixation = summarizeFixationMetrics(\n        startIndex,\n        endIndex,\n        xData,\n        yData,\n        timestamps,\n        oneDegree\n      );\n\n      // Preserve algorithm and threshold info if present\n      if (current.algorithm) {\n        mergedFixation.algorithm = current.algorithm;\n      }\n      if (current.threshold) {\n        mergedFixation.threshold = current.threshold;\n      }\n\n      // Replace current with merged, remove next\n      result[i] = mergedFixation;\n      result.splice(i + 1, 1);\n\n      // Don't increment i - check if this merged fixation can merge with the next one\n    } else {\n      i++;\n    }\n  }\n\n  return result;\n}\n\n/**\n * Adjust fixation timing to exclude margin samples\n *\n * Shrinks fixation period by removing:\n * 1. NA samples at onset and offset\n * 2. Samples with excessive distance from fixation center (if threshold provided)\n *\n * @param startIndex - Current first sample index\n * @param endIndex - Current last sample index\n * @param x - Array of x coordinates\n * @param y - Array of y coordinates\n * @param threshold - Threshold in MAD units (e.g., 3). If undefined, only remove NAs\n * @returns New start and end indices\n *\n * @see R function: adjust_fixation_timing() in FixationFilterFunctions.R:1216\n *\n * @example\n * ```ts\n * const { firstLine, lastLine } = adjustFixationTiming(\n *   100, 150,\n *   xCoords, yCoords,\n *   3  // Remove samples > 3*MAD from center\n * );\n * ```\n */\nexport function adjustFixationTiming(\n  startIndex: number,\n  endIndex: number,\n  x: (number | null | undefined)[],\n  y: (number | null | undefined)[],\n  threshold?: number\n): { firstLine: number; lastLine: number } {\n  // Calculate fixation center\n  const xSamples: number[] = [];\n  const ySamples: number[] = [];\n\n  for (let i = startIndex; i <= endIndex; i++) {\n    const xVal = x[i];\n    const yVal = y[i];\n    if (!isNA(xVal) && !isNA(yVal)) {\n      xSamples.push(xVal as number);\n      ySamples.push(yVal as number);\n    }\n  }\n\n  if (xSamples.length === 0) {\n    // All samples are NA - return original indices\n    return { firstLine: startIndex, lastLine: endIndex };\n  }\n\n  const fixationX = mean(xSamples, false);\n  const fixationY = mean(ySamples, false);\n\n  // Calculate distances from center for each sample\n  const distancesFromCenter: (number | null)[] = [];\n  for (let i = startIndex; i <= endIndex; i++) {\n    const xVal = x[i];\n    const yVal = y[i];\n\n    if (isNA(xVal) || isNA(yVal)) {\n      distancesFromCenter.push(null);\n    } else {\n      const dx = (xVal as number) - fixationX;\n      const dy = (yVal as number) - fixationY;\n      // Use average of x and y distances (matches R implementation)\n      const dist = (Math.sqrt(dx * dx) + Math.sqrt(dy * dy)) / 2;\n      distancesFromCenter.push(dist);\n    }\n  }\n\n  let newStart = startIndex;\n  let newEnd = endIndex;\n\n  if (threshold !== undefined && !Number.isNaN(threshold)) {\n    // Calculate median and MAD of distances\n    const validDistances = distancesFromCenter.filter(\n      d => d !== null\n    );\n\n    if (validDistances.length > 0) {\n      const medianDist = median(validDistances, false);\n      const madDist = mad(validDistances, false);\n      const limitValue = medianDist + threshold * madDist;\n\n      // Find new start (first sample within limit)\n      let foundStart = false;\n      for (let i = 0; i < distancesFromCenter.length && !foundStart; i++) {\n        const dist = distancesFromCenter[i];\n        const actualIndex = startIndex + i;\n\n        if (dist !== null && dist! <= limitValue) {\n          newStart = actualIndex;\n          foundStart = true;\n        } else if (actualIndex >= endIndex) {\n          foundStart = true; // Give up\n        }\n      }\n\n      // Find new end (last sample within limit, working backwards)\n      let foundEnd = false;\n      for (let i = distancesFromCenter.length - 1; i >= 0 && !foundEnd; i--) {\n        const dist = distancesFromCenter[i];\n        const actualIndex = startIndex + i;\n\n        if (dist !== null && dist! <= limitValue) {\n          newEnd = actualIndex;\n          foundEnd = true;\n        } else if (actualIndex <= newStart) {\n          foundEnd = true; // Give up\n        }\n      }\n    }\n  } else {\n    // No threshold - just remove NAs at margins\n    // Find first non-NA\n    for (let i = startIndex; i <= endIndex; i++) {\n      if (!isNA(x[i]) && !isNA(y[i])) {\n        newStart = i;\n        break;\n      }\n    }\n\n    // Find last non-NA\n    for (let i = endIndex; i >= startIndex; i--) {\n      if (!isNA(x[i]) && !isNA(y[i])) {\n        newEnd = i;\n        break;\n      }\n    }\n  }\n\n  return { firstLine: newStart, lastLine: newEnd };\n}\n\n/**\n * Trim all fixations in a data frame\n *\n * Applies adjustFixationTiming to all fixations and recalculates metrics.\n * This reduces the risk of misclassifying saccade samples as fixations.\n *\n * @param fixations - Array of fixations to trim\n * @param gazeData - Original sample-by-sample gaze data\n * @param xcol - Name of x coordinate column\n * @param ycol - Name of y coordinate column\n * @param threshold - Threshold in MAD units (e.g., 3). If undefined, only remove NAs\n * @param oneDegree - One degree of visual field in coordinate units\n * @returns Array of trimmed fixations with recalculated metrics\n *\n * @see R function: trim_fixations() in FixationFilterFunctions.R:1316\n *\n * @example\n * ```ts\n * const trimmed = trimFixations(\n *   fixations,\n *   gazeData,\n *   'xRaw',\n *   'yRaw',\n *   3,  // Trim samples > 3*MAD from center\n *   40\n * );\n * ```\n */\nexport function trimFixations(\n  fixations: Fixation[],\n  gazeData: (ProcessedGazeData | FilteredGazeData)[],\n  xcol = 'xRaw',\n  ycol = 'yRaw',\n  threshold = 3,\n  oneDegree = 40\n): Fixation[] {\n  // Extract coordinate arrays\n  const xData = gazeData.map(d => (d as unknown as Record<string, number>)[xcol] ?? null);\n  const yData = gazeData.map(d => (d as unknown as Record<string, number>)[ycol] ?? null);\n  const timestamps = gazeData.map(d => d.timestamp);\n\n  if (xData.length === 0 || yData.length === 0) {\n    console.warn(\n      'Warning! No X and/or Y coordinates found in sample level data. ' +\n        'Did you misspecify the variable names in xcol and/or ycol?'\n    );\n    return fixations;\n  }\n\n  const trimmedFixations: Fixation[] = [];\n\n  for (const fixation of fixations) {\n    // Adjust timing to exclude margin samples\n    const adjusted = adjustFixationTiming(\n      fixation.firstLine,\n      fixation.lastLine,\n      xData,\n      yData,\n      threshold\n    );\n\n    // Recalculate metrics for trimmed period\n    const trimmedFixation = summarizeFixationMetrics(\n      adjusted.firstLine,\n      adjusted.lastLine,\n      xData,\n      yData,\n      timestamps,\n      oneDegree\n    );\n\n    // Preserve algorithm and threshold info\n    trimmedFixation.algorithm = fixation.algorithm ?? 'unknown';\n    trimmedFixation.threshold = fixation.threshold ?? 'unknown';\n\n    trimmedFixations.push(trimmedFixation);\n  }\n\n  return trimmedFixations;\n}\n", "/**\n * I-DT (Dispersion-Threshold) fixation detection algorithm\n *\n * Identifies fixations as samples clustering within a spatial area.\n * Based on Salvucci & Goldberg (2000).\n *\n * @module core/algorithm-idt\n */\n\nimport type {\n  ProcessedGazeData,\n  Fixation,\n  FilteredGazeData,\n  AlgorithmResult,\n  IDTParams,\n} from '../types/index.js';\nimport {\n  summarizeFixationMetrics,\n  mergeAdjacentFixations,\n} from './fixation-utils.js';\nimport { validateOneDegree } from '../utils/validation.js';\n\n/**\n * Default I-DT parameters\n */\nexport const DEFAULT_IDT_PARAMS: IDTParams = {\n  dispersionThreshold: 1, // degrees\n  minDuration: 50, // ms\n  oneDegree: 40, // pixels or screen proportion\n  xcol: 'x',\n  ycol: 'y',\n  distanceThreshold: 0.7, // degrees\n  mergeMsThreshold: 75, // ms\n  missingSamplesThreshold: 0.5, // proportion [0-1]\n};\n\n/**\n * I-DT fixation detection algorithm\n *\n * The I-DT (Dispersion-Threshold) algorithm identifies fixations as groups of\n * consecutive samples that cluster within a spatial threshold. It uses a\n * sliding window approach to detect when samples fall within a circular area.\n *\n * **Algorithm:**\n * 1. Start with two consecutive samples\n * 2. Check if they fall within dispersion threshold\n * 3. If yes, grow the fixation candidate by adding more samples\n * 4. Continue while samples stay within threshold from fixation center\n * 5. When threshold is exceeded, classify as fixation if duration is sufficient\n * 6. Merge adjacent fixations that are close in space and time\n * 7. Filter by minimum duration and missing samples threshold\n *\n * **Reference:**\n * Salvucci, D. D., & Goldberg, J. H. (2000). Identifying fixations and saccades\n * in eye-tracking protocols. *Proceedings of the 2000 symposium on Eye tracking\n * research & applications*, 71-78.\n *\n * @param gazeData - Preprocessed gaze data (after interpolation/smoothing)\n * @param params - Algorithm parameters (or use defaults)\n * @returns Object with fixations and filtered gaze data\n *\n * @see R function: algorithm_idt() in FixationFilterFunctions.R:125\n *\n * @example\n * ```ts\n * const result = algorithmIDT(processedData, {\n *   dispersionThreshold: 1,  // 1 degree maximum dispersion\n *   minDuration: 50,         // 50ms minimum fixation duration\n *   oneDegree: 40,          // 40 pixels = 1 degree\n * });\n *\n * console.log(`Detected ${result.fixations.length} fixations`);\n * console.log(`Mean duration: ${mean(result.fixations.map(f => f.duration))}ms`);\n * ```\n */\nexport function algorithmIDT(\n  gazeData: ProcessedGazeData[],\n  params: Partial<IDTParams> = {}\n): AlgorithmResult {\n  const {\n    dispersionThreshold,\n    minDuration,\n    oneDegree,\n    xcol,\n    ycol,\n    distanceThreshold,\n    mergeMsThreshold,\n    missingSamplesThreshold,\n  } = { ...DEFAULT_IDT_PARAMS, ...params };\n\n  if (gazeData.length < 2) {\n    return {\n      fixations: [],\n      filteredGaze: [],\n    };\n  }\n\n  // Validate oneDegree parameter\n  validateOneDegree(gazeData, oneDegree, xcol);\n\n  // Extract coordinates\n  const xData = gazeData.map(d => (d as unknown as Record<string, number>)[xcol]);\n  const yData = gazeData.map(d => (d as unknown as Record<string, number>)[ycol]);\n  const timestamps = gazeData.map(d => d.timestamp);\n\n  // Initialize output structures\n  const fixations: Fixation[] = [];\n  const filteredGaze: FilteredGazeData[] = gazeData.map(d => ({\n    timestamp: d.timestamp,\n    xRaw: (d as unknown as Record<string, number>)[xcol]!,\n    yRaw: (d as unknown as Record<string, number>)[ycol]!,\n    x: null,\n    y: null,\n  }));\n\n  // State variables\n  let sampleIndex = 1; // Start at second sample\n  let fixationCandidate = false;\n  let fixationCandidateStart = 0;\n  let fixationCandidateX = 0;\n  let fixationCandidateY = 0;\n\n  while (sampleIndex < gazeData.length) {\n    if (!fixationCandidate) {\n      // Not currently in a fixation candidate\n      // Check if this sample and previous sample are within threshold\n\n      const x1 = xData[sampleIndex - 1];\n      const y1 = yData[sampleIndex - 1];\n      const x2 = xData[sampleIndex];\n      const y2 = yData[sampleIndex];\n\n      if (\n        x1 != null &&\n        y1 != null &&\n        x2 != null &&\n        y2 != null &&\n        !Number.isNaN(x1) &&\n        !Number.isNaN(y1) &&\n        !Number.isNaN(x2) &&\n        !Number.isNaN(y2)\n      ) {\n        const distance = Math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2);\n\n        if (distance <= dispersionThreshold * oneDegree) {\n          // Start a fixation candidate\n          fixationCandidate = true;\n          fixationCandidateStart = sampleIndex - 1;\n\n          // Calculate tentative center\n          fixationCandidateX = (x1 + x2) / 2;\n          fixationCandidateY = (y1 + y2) / 2;\n        }\n      }\n    } else {\n      // Currently in a fixation candidate\n      // Check if current sample is within threshold from center\n\n      const xCurr = xData[sampleIndex];\n      const yCurr = yData[sampleIndex];\n\n      if (xCurr != null && yCurr != null && !Number.isNaN(xCurr) && !Number.isNaN(yCurr)) {\n        const distanceFromCenter = Math.sqrt(\n          (xCurr - fixationCandidateX) ** 2 + (yCurr - fixationCandidateY) ** 2\n        );\n\n        if (distanceFromCenter <= dispersionThreshold * oneDegree) {\n          // Sample is within threshold - update center to include this sample\n          // Recalculate mean of all samples in candidate\n          let sumX = 0;\n          let sumY = 0;\n          let count = 0;\n\n          for (let i = fixationCandidateStart; i <= sampleIndex; i++) {\n            const x = xData[i];\n            const y = yData[i];\n            if (x != null && y != null && !Number.isNaN(x) && !Number.isNaN(y)) {\n              sumX += x;\n              sumY += y;\n              count++;\n            }\n          }\n\n          if (count > 0) {\n            fixationCandidateX = sumX / count;\n            fixationCandidateY = sumY / count;\n          }\n        } else {\n          // Sample exceeds threshold - fixation has ended\n          // Summarize and save the fixation\n          const thisFixation = summarizeFixationMetrics(\n            fixationCandidateStart,\n            sampleIndex - 1, // Don't include current sample\n            xData,\n            yData,\n            timestamps,\n            oneDegree\n          );\n\n          fixations.push(thisFixation);\n\n          // Reset state\n          fixationCandidate = false;\n          fixationCandidateStart = 0;\n          fixationCandidateX = 0;\n          fixationCandidateY = 0;\n        }\n      } else {\n        // NA value - end fixation\n        // Summarize and save if we had a candidate\n        if (fixationCandidateStart < sampleIndex - 1) {\n          const thisFixation = summarizeFixationMetrics(\n            fixationCandidateStart,\n            sampleIndex - 1,\n            xData,\n            yData,\n            timestamps,\n            oneDegree\n          );\n\n          fixations.push(thisFixation);\n        }\n\n        // Reset state\n        fixationCandidate = false;\n        fixationCandidateStart = 0;\n        fixationCandidateX = 0;\n        fixationCandidateY = 0;\n      }\n    }\n\n    sampleIndex++;\n  }\n\n  // Handle case where recording ends with a fixation\n  if (fixationCandidate && fixationCandidateStart < gazeData.length - 1) {\n    const thisFixation = summarizeFixationMetrics(\n      fixationCandidateStart,\n      gazeData.length - 1,\n      xData,\n      yData,\n      timestamps,\n      oneDegree\n    );\n\n    fixations.push(thisFixation);\n  }\n\n  // Merge adjacent fixations if requested\n  let mergedFixations = fixations;\n  if (distanceThreshold > 0) {\n    mergedFixations = mergeAdjacentFixations(\n      fixations,\n      filteredGaze,\n      distanceThreshold,\n      mergeMsThreshold,\n      oneDegree,\n      'xRaw',\n      'yRaw'\n    );\n  }\n\n  // Filter fixations by duration and missing samples\n  const filteredFixations = mergedFixations.filter(\n    f => f.duration > minDuration && f.missingSamples < missingSamplesThreshold\n  );\n\n  // Add algorithm metadata\n  const finalFixations = filteredFixations.map(f => ({\n    ...f,\n    algorithm: 'idt',\n    threshold: `${Math.round(dispersionThreshold)} deg.`,\n  }));\n\n  // Fill in filtered gaze coordinates\n  for (const fixation of finalFixations) {\n    for (let i = fixation.firstLine; i <= fixation.lastLine; i++) {\n      filteredGaze[i]!.x = fixation.x;\n      filteredGaze[i]!.y = fixation.y;\n    }\n  }\n\n  return {\n    fixations: finalFixations,\n    filteredGaze,\n  };\n}\n", "/**\n * I-VT (Velocity-Threshold) fixation and saccade detection algorithm\n *\n * Identifies saccades as periods with high velocity and fixations as\n * periods between saccades. Based on Salvucci & Goldberg (2000).\n *\n * @module core/algorithm-ivt\n */\n\nimport type {\n  ProcessedGazeData,\n  Fixation,\n  Saccade,\n  FilteredGazeData,\n  VelocityData,\n  AlgorithmResult,\n  IVTParams,\n} from '../types/index.js';\nimport {\n  summarizeFixationMetrics,\n  mergeAdjacentFixations,\n  trimFixations,\n} from './fixation-utils.js';\nimport { rollmedian } from '../utils/rolling.js';\nimport { rle } from '../utils/rle.js';\nimport { mean } from '../utils/statistics.js';\nimport { validateOneDegree } from '../utils/validation.js';\n\n/**\n * Default I-VT parameters\n */\nexport const DEFAULT_IVT_PARAMS: IVTParams = {\n  velocityThreshold: 35, // degrees/second\n  velocityFilterMs: 20, // ms\n  minSaccadeDuration: 10, // ms\n  minSaccadeAmplitude: 1, // degrees\n  minFixationDuration: 40, // ms\n  oneDegree: 40, // pixels\n  xcol: 'x',\n  ycol: 'y',\n  distanceThreshold: 0.7, // degrees\n  mergeMsThreshold: 75, // ms\n  missingSamplesThreshold: 0.5, // [0-1]\n  trimFixations: false,\n  trimDispersionThreshold: undefined,\n  saveVelocityProfiles: false,\n};\n\n/**\n * I-VT fixation and saccade detection algorithm\n *\n * The I-VT (Velocity-Threshold) algorithm detects saccades as periods where\n * sample-to-sample velocity exceeds a threshold, and identifies fixations as\n * the periods between saccades.\n *\n * **Algorithm:**\n * 1. Calculate sample-to-sample velocity\n * 2. Smooth velocity vector with moving median filter\n * 3. Detect saccades (velocity > threshold)\n * 4. Identify fixations (periods between saccades)\n * 5. Optionally trim fixation margins\n * 6. Merge adjacent fixations close in space and time\n * 7. Filter by minimum duration and missing samples\n *\n * **Reference:**\n * Salvucci, D. D., & Goldberg, J. H. (2000). Identifying fixations and saccades\n * in eye-tracking protocols. *Proceedings of the 2000 symposium on Eye tracking\n * research & applications*, 71-78.\n *\n * @param gazeData - Preprocessed gaze data\n * @param params - Algorithm parameters (or use defaults)\n * @returns Object with fixations, saccades, filtered gaze, and velocity\n *\n * @see R function: algorithm_ivt() in FixationFilterFunctions.R:289\n *\n * @example\n * ```ts\n * const result = algorithmIVT(processedData, {\n *   velocityThreshold: 30,   // 30/s threshold\n *   minFixationDuration: 40, // 40ms minimum\n *   oneDegree: 40,          // 40 pixels = 1\n * });\n *\n * console.log(`Fixations: ${result.fixations.length}`);\n * console.log(`Saccades: ${result.saccades?.length}`);\n * ```\n */\nexport function algorithmIVT(\n  gazeData: ProcessedGazeData[],\n  params: Partial<IVTParams> = {}\n): AlgorithmResult {\n  const {\n    velocityThreshold,\n    velocityFilterMs,\n    minSaccadeDuration,\n    minSaccadeAmplitude,\n    minFixationDuration,\n    oneDegree,\n    xcol,\n    ycol,\n    distanceThreshold,\n    mergeMsThreshold,\n    missingSamplesThreshold,\n    trimFixations: shouldTrimFixations,\n    trimDispersionThreshold,\n    saveVelocityProfiles,\n  } = { ...DEFAULT_IVT_PARAMS, ...params };\n\n  if (gazeData.length < 2) {\n    return {\n      fixations: [],\n      filteredGaze: [],\n      saccades: [],\n      velocity: [],\n    };\n  }\n\n  // Validate oneDegree\n  validateOneDegree(gazeData, oneDegree, xcol);\n\n  // Extract data\n  const xData = gazeData.map(d => (d as unknown as Record<string, number>)[xcol]);\n  const yData = gazeData.map(d => (d as unknown as Record<string, number>)[ycol]);\n  const timestamps = gazeData.map(d => d.timestamp);\n\n  // Calculate sample interval\n  const intervals = [];\n  for (let i = 1; i < timestamps.length; i++) {\n    intervals.push(timestamps[i]! - timestamps[i - 1]!);\n  }\n  const oneSample = mean(intervals, true);\n\n  if (oneSample < 0.02) {\n    console.warn(\n      'Unlikely small sample-to-sample difference in timestamps. ' +\n        'Are timestamps in milliseconds?'\n    );\n  }\n\n  // Calculate sample-to-sample velocity\n  console.log('Calculating saccades');\n\n  const distance: number[] = [NaN]; // First sample has no previous\n  const velocity: number[] = [NaN];\n\n  for (let i = 1; i < gazeData.length; i++) {\n    const x1 = xData[i - 1];\n    const y1 = yData[i - 1];\n    const x2 = xData[i];\n    const y2 = yData[i];\n\n    if (\n      x1 == null || y1 == null || x2 == null || y2 == null ||\n      Number.isNaN(x1) || Number.isNaN(y1) || Number.isNaN(x2) || Number.isNaN(y2)\n    ) {\n      distance.push(NaN);\n      velocity.push(NaN);\n      continue;\n    }\n\n    const dx = x2 - x1;\n    const dy = y2 - y1;\n    const dist = Math.sqrt(dx * dx + dy * dy);\n\n    // Convert to degrees\n    const distDeg = dist / oneDegree;\n    distance.push(distDeg);\n\n    // Convert to degrees per second\n    const vel = (distDeg / oneSample) * 1000;\n    velocity.push(vel);\n  }\n\n  // Smooth velocity vector\n  const velocitySmoothWindow = Math.round(velocityFilterMs / oneSample);\n  const smoothedVelocity = rollmedian(\n    velocity,\n    velocitySmoothWindow,\n    'center',\n    true,\n    false\n  );\n\n  // Detect saccades (velocity > threshold)\n  const aboveThreshold = smoothedVelocity.map(v =>\n    v !== null && !Number.isNaN(v) ? v > velocityThreshold : false\n  );\n\n  // Find runs of samples above threshold\n  const encoded = rle(aboveThreshold);\n\n  const saccadeStarts: number[] = [];\n  const saccadeEnds: number[] = [];\n\n  let currentIndex = 0;\n  for (let i = 0; i < encoded.lengths.length; i++) {\n    const length = encoded.lengths[i]!;\n    const value = encoded.values[i];\n\n    if (value === true) {\n      saccadeStarts.push(currentIndex);\n      saccadeEnds.push(currentIndex + length - 1);\n    }\n\n    currentIndex += length;\n  }\n\n  // Process saccades\n  const saccades: Saccade[] = [];\n  const velocityProfiles: number[][] = [];\n\n  for (let i = 0; i < saccadeStarts.length; i++) {\n    const start = saccadeStarts[i]!;\n    const end = saccadeEnds[i]!;\n\n    const xOnset = xData[start];\n    const yOnset = yData[start];\n    const xOffset = xData[end];\n    const yOffset = yData[end];\n\n    if (\n      xOnset == null || yOnset == null || xOffset == null || yOffset == null ||\n      Number.isNaN(xOnset) || Number.isNaN(yOnset) ||\n      Number.isNaN(xOffset) || Number.isNaN(yOffset)\n    ) {\n      continue;\n    }\n\n    // Calculate amplitude\n    const amplitude =\n      Math.sqrt((xOffset - xOnset) ** 2 + (yOffset - yOnset) ** 2) / oneDegree;\n\n    // Calculate peak velocity\n    const saccadeVelocities = smoothedVelocity\n      .slice(start, end + 1)\n      .filter(v => v !== null && !Number.isNaN(v)) as number[];\n\n    const peakVelocity =\n      saccadeVelocities.length > 0 ? Math.max(...saccadeVelocities) : NaN;\n\n    // Calculate missing samples\n    const saccadeX = xData.slice(start, end + 1);\n    const missingCount = saccadeX.filter(x => x == null || Number.isNaN(x)).length;\n    const missingSamples = missingCount / saccadeX.length;\n\n    const saccade: Saccade = {\n      onset: timestamps[start]!,\n      xOnset,\n      yOnset,\n      offset: timestamps[end]!,\n      xOffset,\n      yOffset,\n      duration: timestamps[end]! - timestamps[start]!,\n      amplitude,\n      peakVelocity,\n      missingSamples,\n    };\n\n    saccades.push(saccade);\n\n    if (saveVelocityProfiles) {\n      velocityProfiles.push(saccadeVelocities);\n    }\n  }\n\n  // Filter saccades by duration and amplitude\n  const filteredSaccades = saccades.filter(\n    s => s.duration >= minSaccadeDuration && s.amplitude >= minSaccadeAmplitude\n  );\n\n  // Add velocity profiles if requested\n  if (saveVelocityProfiles) {\n    filteredSaccades.forEach((s, i) => {\n      s.velocityProfile = velocityProfiles[i];\n    });\n  }\n\n  // Identify fixations (periods between saccades)\n  console.log('Calculating fixations');\n\n  const fixations: Fixation[] = [];\n  const fixationStarts = saccadeEnds;\n\n  // Handle case where recording ends with a fixation\n  let saccadeStartsAdjusted = saccadeStarts;\n  if (fixationStarts.length >= saccadeStarts.length) {\n    saccadeStartsAdjusted = [...saccadeStarts, gazeData.length - 1];\n  }\n\n  for (let i = 0; i < fixationStarts.length; i++) {\n    const fixStart = fixationStarts[i]!;\n    const fixEnd = saccadeStartsAdjusted[i + 1]! - 1;\n\n    if (fixEnd <= fixStart) continue;\n\n    const thisFixation = summarizeFixationMetrics(\n      fixStart,\n      fixEnd,\n      xData,\n      yData,\n      timestamps,\n      oneDegree\n    );\n\n    fixations.push(thisFixation);\n  }\n\n  // Trim fixations if requested\n  const filteredGaze: FilteredGazeData[] = gazeData.map(d => ({\n    timestamp: d.timestamp,\n    xRaw: (d as unknown as Record<string, number>)[xcol]!,\n    yRaw: (d as unknown as Record<string, number>)[ycol]!,\n    x: null,\n    y: null,\n  }));\n\n  let processedFixations = fixations;\n\n  if (shouldTrimFixations) {\n    processedFixations = trimFixations(\n      fixations,\n      filteredGaze,\n      'xRaw',\n      'yRaw',\n      trimDispersionThreshold,\n      oneDegree\n    );\n  }\n\n  // Merge adjacent fixations\n  if (distanceThreshold > 0) {\n    processedFixations = mergeAdjacentFixations(\n      processedFixations,\n      filteredGaze,\n      distanceThreshold,\n      mergeMsThreshold,\n      oneDegree,\n      'xRaw',\n      'yRaw'\n    );\n  }\n\n  // Filter by duration and missing samples\n  const finalFixations = processedFixations\n    .filter(\n      f => f.duration >= minFixationDuration && f.missingSamples < missingSamplesThreshold\n    )\n    .map(f => ({\n      ...f,\n      algorithm: 'ivt',\n      threshold: `${Math.round(velocityThreshold)} deg.`,\n    }));\n\n  // Fill in filtered gaze coordinates\n  for (const fixation of finalFixations) {\n    for (let i = fixation.firstLine; i <= fixation.lastLine; i++) {\n      filteredGaze[i]!.x = fixation.x;\n      filteredGaze[i]!.y = fixation.y;\n    }\n  }\n\n  // Create velocity output\n  const velocityOutput: VelocityData[] = timestamps.map((t, i) => ({\n    timestamp: t,\n    velocity: smoothedVelocity[i] ?? NaN,\n  }));\n\n  return {\n    fixations: finalFixations,\n    saccades: filteredSaccades,\n    filteredGaze,\n    velocity: velocityOutput,\n  };\n}\n", "/**\n * I2MC (Identification by Two-Means Clustering) fixation detection algorithm\n *\n * Uses k-means clustering (k=2) to identify fixations based on transition weights.\n * Based on Hessels et al. (2017).\n *\n * @module core/algorithm-i2mc\n */\n\nimport type {\n  ProcessedGazeData,\n  Fixation,\n  FilteredGazeData,\n  AlgorithmResult,\n  I2MCParams,\n} from '../types/index.js';\nimport {\n  summarizeFixationMetrics,\n  mergeAdjacentFixations,\n  trimFixations,\n} from './fixation-utils.js';\nimport { downsampleGaze } from '../preprocessing/downsample.js';\nimport { mean, sd } from '../utils/statistics.js';\nimport { validateOneDegree } from '../utils/validation.js';\nimport { kmeans } from 'ml-kmeans';\n\n/**\n * Default I2MC parameters\n */\nexport const DEFAULT_I2MC_PARAMS: I2MCParams = {\n  windowLengthMs: 200, // ms\n  windowStepSize: 6, // samples\n  weightThreshold: 2, // SD units\n  minFixationDuration: 40, // ms\n  oneDegree: 40, // pixels\n  xcol: 'x',\n  ycol: 'y',\n  distanceThreshold: 0.7, // degrees\n  mergeMsThreshold: 40, // ms\n  missingSamplesThreshold: 0.5, // [0-1]\n  downsamplingFactors: undefined, // e.g., [2, 5, 10]\n  thresholdOnOff: 3, // MAD units for trimming\n};\n\n/**\n * Find transition weights for samples using k-means clustering\n *\n * Applies a sliding window and calculates transition weights based on\n * k-means clustering (k=2) within each window.\n *\n * @param dataWithSample - Data with sample indices\n * @param windowStepSize - Step size between windows\n * @param windowSize - Size of analysis window in samples\n * @returns Array of transition weights (one per sample)\n *\n * @see R function: find.transition.weights() in FixationFilterFunctions.R:556\n */\nfunction findTransitionWeights(\n  dataWithSample: Array<{ x: number; y: number; sample: number }>,\n  windowStepSize: number,\n  windowSize: number\n): (number | null)[] {\n  const transitionWeights: (number | null)[] = new Array(dataWithSample.length).fill(null);\n\n  let thisOnset = 0;\n\n  while (thisOnset < dataWithSample.length) {\n    const thisOffset = thisOnset + windowSize;\n\n    if (thisOffset <= dataWithSample.length) {\n      // Extract window\n      const window = dataWithSample.slice(thisOnset, thisOffset);\n\n      // Check for NAs\n      const hasNA = window.some(d => Number.isNaN(d.x) || Number.isNaN(d.y));\n\n      if (!hasNA && window.length >= 2) {\n        // Perform k-means clustering with k=2\n        const points = window.map(d => [d.x, d.y]);\n\n        try {\n          // ml-kmeans expects data as array of arrays\n          const result = kmeans(points, 2, {});\n\n          const clusters = result.clusters;\n\n          // Calculate transitions\n          const transitions: number[] = [];\n          for (let i = 1; i < clusters.length; i++) {\n            transitions.push(Math.abs(clusters[i]! - clusters[i - 1]!));\n          }\n\n          // Count transitions\n          const nTransitions = transitions.reduce((sum, t) => sum + (t !== 0 ? 1 : 0), 0);\n\n          // Calculate transition weights\n          const weights =\n            nTransitions > 0 ? transitions.map(t => t / nTransitions) : transitions;\n\n          // Assign weights to samples\n          for (let i = 0; i < weights.length; i++) {\n            const sampleIndex = thisOnset + i + 1; // +1 because transitions start at second sample\n            if (sampleIndex < transitionWeights.length) {\n              if (transitionWeights[sampleIndex] === null) {\n                transitionWeights[sampleIndex] = weights[i]!;\n              } else {\n                // Average with existing weight\n                transitionWeights[sampleIndex] =\n                  ((transitionWeights[sampleIndex] as number) + weights[i]!) / 2;\n              }\n            }\n          }\n        } catch (error) {\n          // K-means failed (e.g., all points identical) - skip this window\n          console.warn(`K-means failed for window at ${thisOnset}: ${error}`);\n        }\n      } else if (hasNA) {\n        // Window contains NAs - move past them\n        const lastNAIndex = window.findIndex(d => !Number.isNaN(d.x) && !Number.isNaN(d.y));\n        if (lastNAIndex > 0) {\n          thisOnset = thisOnset + lastNAIndex;\n          continue;\n        }\n      }\n    }\n\n    thisOnset += windowStepSize;\n  }\n\n  return transitionWeights;\n}\n\n/**\n * I2MC fixation detection algorithm\n *\n * The I2MC (Identification by Two-Means Clustering) algorithm uses k-means\n * clustering to identify fixations based on transition weights. It's particularly\n * robust to noise in the data.\n *\n * **Algorithm:**\n * 1. Apply sliding window across data\n * 2. For each window, perform k-means clustering (k=2)\n * 3. Calculate transition weights from cluster assignments\n * 4. Identify fixations where weights are below threshold\n * 5. Optionally downsample data for robustness\n * 6. Trim fixation margins\n * 7. Merge adjacent fixations\n * 8. Filter by duration and missing samples\n *\n * **Reference:**\n * Hessels, R. S., Niehorster, D. C., Kemner, C., & Hooge, I. T. C. (2017).\n * Noise-robust fixation detection in eye movement data: Identification by\n * two-means clustering (I2MC). *Behavior Research Methods*, 49(5), 1802-1823.\n *\n * @param gazeData - Preprocessed gaze data\n * @param params - Algorithm parameters (or use defaults)\n * @returns Object with fixations and filtered gaze data\n *\n * @see R function: algorithm_i2mc() in FixationFilterFunctions.R:655\n *\n * @example\n * ```ts\n * const result = algorithmI2MC(processedData, {\n *   windowLengthMs: 200,        // 200ms analysis window\n *   weightThreshold: 2,          // 2 SD threshold\n *   downsamplingFactors: [2, 5], // Multi-scale analysis\n * });\n *\n * console.log(`Detected ${result.fixations.length} fixations`);\n * ```\n */\nexport function algorithmI2MC(\n  gazeData: ProcessedGazeData[],\n  params: Partial<I2MCParams> = {}\n): AlgorithmResult {\n  const {\n    windowLengthMs,\n    windowStepSize,\n    weightThreshold,\n    minFixationDuration,\n    oneDegree,\n    xcol,\n    ycol,\n    distanceThreshold,\n    mergeMsThreshold,\n    missingSamplesThreshold,\n    downsamplingFactors,\n    thresholdOnOff,\n  } = { ...DEFAULT_I2MC_PARAMS, ...params };\n\n  if (gazeData.length < 2) {\n    return {\n      fixations: [],\n      filteredGaze: [],\n    };\n  }\n\n  // Validate\n  if (!gazeData[0]?.timestamp) {\n    console.warn('Variable timestamp missing in gaze matrix');\n  }\n\n  validateOneDegree(gazeData, oneDegree, xcol);\n\n  // Calculate sampling rate\n  const intervals = [];\n  for (let i = 1; i < Math.min(500, gazeData.length); i++) {\n    intervals.push(gazeData[i]!.timestamp - gazeData[i - 1]!.timestamp);\n  }\n  const oneSample = mean(intervals, true);\n  const windowSize = Math.round(windowLengthMs / oneSample);\n\n  // Prepare data with sample indices\n  const dataWithSample = gazeData.map((d, i) => ({\n    x: (d as unknown as Record<string, number>)[xcol]!,\n    y: (d as unknown as Record<string, number>)[ycol]!,\n    sample: i,\n  }));\n\n  console.log('Searching for fixations');\n\n  // Step 1: Calculate transition weights at original sampling rate\n  console.log('Calculating transition weights at original sampling rate');\n  const transitionWeights = findTransitionWeights(dataWithSample, windowStepSize, windowSize);\n\n  // Step 2: Calculate transition weights for downsampled data\n  if (downsamplingFactors && downsamplingFactors.length > 0) {\n    console.log('Calculating fixation weights in downsampled data');\n\n    for (const dsFactor of downsamplingFactors) {\n      console.log(`Downsampling by factor: ${dsFactor}`);\n\n      const downsampled = downsampleGaze(gazeData, dsFactor, xcol, ycol);\n\n      const dsData = downsampled.map((d, i) => ({\n        x: d.x,\n        y: d.y,\n        sample: i,\n        firstSample: d.firstSample,\n        lastSample: d.lastSample,\n      }));\n\n      const windowSizeDs = Math.floor(windowSize / dsFactor);\n      const dsWeights = findTransitionWeights(dsData, windowStepSize, windowSizeDs);\n\n      // Map downsampled weights back to original samples\n      for (let binIdx = 0; binIdx < dsData.length; binIdx++) {\n        const weight = dsWeights[binIdx];\n        if (weight !== null && weight !== undefined && !Number.isNaN(weight)) {\n          const bin = downsampled[binIdx]!;\n          for (let sampleIdx = bin.firstSample; sampleIdx <= bin.lastSample; sampleIdx++) {\n            if (transitionWeights[sampleIdx] === null) {\n              transitionWeights[sampleIdx] = weight;\n            } else {\n              // Average weights\n              transitionWeights[sampleIdx] =\n                ((transitionWeights[sampleIdx] as number) + weight) / 2;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  // Step 3: Calculate fixation threshold\n  const validWeights = transitionWeights.filter(w => w !== null && !Number.isNaN(w)) as number[];\n  const weightMean = mean(validWeights, false);\n  const weightSd = sd(validWeights, false);\n  const fixationThreshold = weightMean + weightThreshold * weightSd;\n\n  // Find samples below threshold (fixation candidates)\n  const underThreshold: number[] = [];\n  const aboveThreshold: number[] = [];\n\n  for (let i = 0; i < transitionWeights.length; i++) {\n    const w = transitionWeights[i];\n    if (w !== null && w !== undefined && !Number.isNaN(w)) {\n      if (w < fixationThreshold) {\n        underThreshold.push(i);\n      } else {\n        aboveThreshold.push(i);\n      }\n    }\n  }\n\n  // Extract coordinates and timestamps\n  const xData = gazeData.map(d => (d as unknown as Record<string, number>)[xcol] ?? null);\n  const yData = gazeData.map(d => (d as unknown as Record<string, number>)[ycol] ?? null);\n  const timestamps = gazeData.map(d => d.timestamp);\n\n  // Identify fixation periods\n  const fixations: Fixation[] = [];\n\n  if (underThreshold.length > 0) {\n    let fixationCandidateStart = underThreshold[0]!;\n\n    for (let i = 0; i < underThreshold.length; i++) {\n      const currentIndex = underThreshold[i]!;\n      const nextIndex = underThreshold[i + 1];\n\n      // Check if this is the last sample or if there's a gap\n      const isLast = i === underThreshold.length - 1;\n      const hasGap = !isLast && nextIndex! - currentIndex > 1;\n\n      if (isLast || hasGap) {\n        // End of fixation period\n        const fixationCandidateStop = currentIndex;\n\n        const thisFixation = summarizeFixationMetrics(\n          fixationCandidateStart,\n          fixationCandidateStop,\n          xData,\n          yData,\n          timestamps,\n          oneDegree\n        );\n\n        fixations.push(thisFixation);\n\n        // Start new fixation if not at end\n        if (!isLast) {\n          fixationCandidateStart = nextIndex!;\n        }\n      }\n    }\n  }\n\n  // Create filtered gaze structure\n  const filteredGaze: FilteredGazeData[] = gazeData.map(d => ({\n    timestamp: d.timestamp,\n    xRaw: (d as unknown as Record<string, number>)[xcol]!,\n    yRaw: (d as unknown as Record<string, number>)[ycol]!,\n    x: null,\n    y: null,\n  }));\n\n  // Step 4: Trim fixations\n  let processedFixations = fixations;\n\n  if (thresholdOnOff !== undefined && !Number.isNaN(thresholdOnOff)) {\n    processedFixations = trimFixations(\n      fixations,\n      filteredGaze,\n      'xRaw',\n      'yRaw',\n      thresholdOnOff,\n      oneDegree\n    );\n  }\n\n  // Step 5: Merge adjacent fixations\n  if (distanceThreshold > 0) {\n    processedFixations = mergeAdjacentFixations(\n      processedFixations,\n      filteredGaze,\n      distanceThreshold,\n      mergeMsThreshold,\n      oneDegree,\n      'xRaw',\n      'yRaw'\n    );\n  }\n\n  // Step 6: Filter by duration and missing samples\n  const finalFixations = processedFixations\n    .filter(\n      f => f.duration >= minFixationDuration && f.missingSamples < missingSamplesThreshold\n    )\n    .map(f => ({\n      ...f,\n      algorithm: 'i2mc',\n      threshold: `${Math.round(weightThreshold)} SD`,\n    }));\n\n  // Fill in filtered gaze coordinates\n  for (const fixation of finalFixations) {\n    for (let i = fixation.firstLine; i <= fixation.lastLine; i++) {\n      filteredGaze[i]!.x = fixation.x;\n      filteredGaze[i]!.y = fixation.y;\n    }\n  }\n\n  return {\n    fixations: finalFixations,\n    filteredGaze,\n  };\n}\n", "/**\n * Adaptive velocity threshold fixation and saccade detection algorithm\n *\n * Uses data-driven adaptive thresholds for saccade onset and offset.\n * Based on Nystrm & Holmqvist (2010).\n *\n * @module core/algorithm-adaptive\n */\n\nimport type {\n  ProcessedGazeData,\n  Fixation,\n  Saccade,\n  FilteredGazeData,\n  VelocityData,\n  AlgorithmResult,\n  AdaptiveParams,\n} from '../types/index.js';\nimport {\n  summarizeFixationMetrics,\n  mergeAdjacentFixations,\n  trimFixations,\n} from './fixation-utils.js';\nimport { suggestThreshold } from '../preprocessing/threshold.js';\nimport { mean } from '../utils/statistics.js';\n\n/**\n * Default Adaptive algorithm parameters\n */\nexport const DEFAULT_ADAPTIVE_PARAMS: AdaptiveParams = {\n  peakThresholdStart: 200, // degrees/second\n  onsetThresholdSd: 3, // SD multiplier\n  minFixationDuration: 40, // ms\n  minSaccadeDuration: 10, // ms\n  minSaccadeAmplitude: 1, // degrees\n  oneDegree: 40, // pixels\n  xcol: 'x',\n  ycol: 'y',\n  velocityFilterMs: 10, // ms\n  alpha: 0.7, // weight of onset threshold in offset\n  beta: 0.3, // weight of local noise in offset\n  distanceThreshold: 0.7, // degrees\n  mergeMsThreshold: 75, // ms\n  missingSamplesThreshold: 0.5, // [0-1]\n  minPeriodMs: 40, // ms\n  marginMs: 3, // ms\n  trimFixations: true,\n  trimDispersionThreshold: undefined,\n  saveVelocityProfiles: false,\n};\n\n/**\n * Adaptive velocity threshold fixation and saccade detection\n *\n * The Adaptive algorithm determines velocity thresholds in a data-driven way,\n * adapting to the specific properties of each recording. It uses different\n * thresholds for saccade onset and offset, with the offset threshold incorporating\n * local noise levels.\n *\n * **Algorithm:**\n * 1. Iteratively determine peak velocity threshold (M + 6*SD)\n * 2. Calculate onset threshold (M + onset_sd*SD)\n * 3. For each saccade:\n *    - Find onset: first sample > onset threshold with increasing velocity\n *    - Calculate local noise factor before saccade\n *    - Calculate offset threshold: weighted combination of onset threshold and local noise\n *    - Find offset: first sample < offset threshold with decreasing velocity\n * 4. Identify fixations as periods between saccades\n * 5. Trim, merge, and filter fixations\n *\n * **Reference:**\n * Nystrm, M., & Holmqvist, K. (2010). An adaptive algorithm for fixation,\n * saccade, and glissade detection in eyetracking data. *Behavior Research\n * Methods*, 42(1), 188-204.\n *\n * @param gazeData - Preprocessed gaze data\n * @param params - Algorithm parameters (or use defaults)\n * @returns Object with fixations, saccades, filtered gaze, and velocity\n *\n * @see R function: algorithm_adaptive() in FixationFilterFunctions.R:913\n *\n * @example\n * ```ts\n * const result = algorithmAdaptive(processedData, {\n *   onsetThresholdSd: 3,  // 3 SD for onset\n *   alpha: 0.7,           // 70% onset threshold\n *   beta: 0.3,            // 30% local noise\n * });\n *\n * console.log(`Fixations: ${result.fixations.length}`);\n * console.log(`Saccades: ${result.saccades?.length}`);\n * ```\n */\nexport function algorithmAdaptive(\n  gazeData: ProcessedGazeData[],\n  params: Partial<AdaptiveParams> = {}\n): AlgorithmResult {\n  const {\n    peakThresholdStart,\n    onsetThresholdSd,\n    minFixationDuration,\n    minSaccadeDuration,\n    minSaccadeAmplitude,\n    oneDegree,\n    xcol,\n    ycol,\n    velocityFilterMs,\n    alpha,\n    beta,\n    distanceThreshold,\n    mergeMsThreshold,\n    missingSamplesThreshold,\n    minPeriodMs,\n    marginMs,\n    trimFixations: shouldTrimFixations,\n    trimDispersionThreshold,\n    saveVelocityProfiles,\n  } = { ...DEFAULT_ADAPTIVE_PARAMS, ...params };\n\n  if (gazeData.length < 2) {\n    return {\n      fixations: [],\n      filteredGaze: [],\n      saccades: [],\n      velocity: [],\n    };\n  }\n\n  // Step 1: Suggest thresholds using adaptive algorithm\n  const thresholds = suggestThreshold(\n    gazeData,\n    xcol,\n    ycol,\n    oneDegree,\n    velocityFilterMs,\n    peakThresholdStart,\n    onsetThresholdSd,\n    minPeriodMs,\n    marginMs\n  );\n\n  const { peakThreshold, onsetThreshold, velocity: velocityVector } = thresholds;\n\n  // Calculate sample interval\n  const timestamps = gazeData.map(d => d.timestamp);\n  const intervals = [];\n  for (let i = 1; i < timestamps.length; i++) {\n    intervals.push(timestamps[i]! - timestamps[i - 1]!);\n  }\n  const oneSample = mean(intervals, true);\n\n  // Extract coordinates\n  const xData = gazeData.map(d => (d as unknown as Record<string, number>)[xcol]);\n  const yData = gazeData.map(d => (d as unknown as Record<string, number>)[ycol]);\n\n  // Step 2: Find saccades\n  console.log('Searching for saccades');\n\n  const saccades: Saccade[] = [];\n  const velocityProfiles: number[][] = [];\n\n  // Find transitions to periods above peak threshold\n  const abovePeakThreshold = velocityVector.map(v =>\n    v !== null && !Number.isNaN(v) ? v > peakThreshold : false\n  );\n\n  // Calculate acceleration/deceleration\n  const acceleration: (number | null)[] = [null];\n  const deceleration: boolean[] = [false];\n\n  for (let i = 1; i < velocityVector.length; i++) {\n    const v1 = velocityVector[i - 1];\n    const v2 = velocityVector[i];\n\n    if (v1 !== null && v2 !== null && !Number.isNaN(v1) && !Number.isNaN(v2)) {\n      const accel = v2! - v1!;\n      acceleration.push(accel);\n      deceleration.push(accel < 0);\n    } else {\n      acceleration.push(null);\n      deceleration.push(false);\n    }\n  }\n\n  // Find peak onsets (transitions to above threshold)\n  const peakOnsets: number[] = [];\n  for (let i = 1; i < abovePeakThreshold.length; i++) {\n    if (!abovePeakThreshold[i - 1] && abovePeakThreshold[i]) {\n      peakOnsets.push(i);\n    }\n  }\n\n  const nonvalidSaccadeOnset = 0; // Track last invalid onset to avoid duplicates\n\n  for (let peakOnsetIdx = 0; peakOnsetIdx < peakOnsets.length; peakOnsetIdx++) {\n    const peakOnset = peakOnsets[peakOnsetIdx]!;\n\n    // FIND SACCADE ONSET\n    // Search backwards for onset: velocity < onset threshold and not decelerating\n    let saccadeStart = peakOnset;\n\n    for (let i = peakOnset - 1; i >= 0; i--) {\n      const v = velocityVector[i];\n      const decel = deceleration[i];\n\n      if (\n        v !== null &&\n        !Number.isNaN(v) &&\n        v! < onsetThreshold &&\n        decel === false\n      ) {\n        saccadeStart = i;\n        break;\n      }\n    }\n\n    // CALCULATE LOCAL NOISE FACTOR\n    // Look at period before saccade onset\n    const periodLength = Math.round(minFixationDuration / oneSample);\n    const p2 = saccadeStart - 1;\n    const p1 = Math.max(0, p2 - periodLength);\n\n    const localVelocities = velocityVector\n      .slice(p1, p2 + 1)\n      .filter(v => v !== null && !Number.isNaN(v));\n\n    const localMean = localVelocities.length > 0 ? mean(localVelocities, false) : 0;\n    const localSd =\n      localVelocities.length > 1\n        ? Math.sqrt(\n            localVelocities.reduce(\n              (sum, v) => sum + (v - localMean) ** 2,\n              0\n            ) / (localVelocities.length - 1)\n          )\n        : 0;\n\n    const localNoiseFactor = localMean + 3 * localSd;\n\n    // FIND SACCADE OFFSET\n    const offsetThreshold = alpha * onsetThreshold + beta * localNoiseFactor;\n\n    // Find end of peak period\n    let peakPeriodOffset: number | null = null;\n    for (let i = peakOnset; i < abovePeakThreshold.length; i++) {\n      if (abovePeakThreshold[i] && !abovePeakThreshold[i + 1]) {\n        peakPeriodOffset = i;\n        break;\n      }\n    }\n\n    if (peakPeriodOffset === null) {\n      // No offset found - skip this saccade\n      continue;\n    }\n\n    // Check if this offset is before the next peak onset\n    if (peakOnsetIdx < peakOnsets.length - 1) {\n      const nextPeakOnset = peakOnsets[peakOnsetIdx + 1]!;\n      if (peakPeriodOffset > nextPeakOnset) {\n        peakPeriodOffset = null;\n      }\n    }\n\n    if (peakPeriodOffset === null) {\n      continue;\n    }\n\n    // Search forward for offset: velocity < offset threshold and decelerating\n    let saccadeEnd = peakPeriodOffset;\n    let foundOffset = false;\n\n    for (let i = peakPeriodOffset; i < velocityVector.length; i++) {\n      const v = velocityVector[i];\n      const decel = deceleration[i];\n\n      if (\n        v !== null &&\n        !Number.isNaN(v) &&\n        v! < offsetThreshold &&\n        decel === true\n      ) {\n        saccadeEnd = i;\n        foundOffset = true;\n        break;\n      }\n    }\n\n    // If couldn't find with deceleration, try without\n    if (!foundOffset) {\n      for (let i = peakPeriodOffset; i < velocityVector.length; i++) {\n        const v = velocityVector[i];\n        if (v !== null && !Number.isNaN(v) && v! < offsetThreshold) {\n          saccadeEnd = i;\n          foundOffset = true;\n          break;\n        }\n      }\n    }\n\n    if (!foundOffset) {\n      continue;\n    }\n\n    // Calculate saccade metrics\n    const xOnset = xData[saccadeStart];\n    const yOnset = yData[saccadeStart];\n    const xOffset = xData[saccadeEnd];\n    const yOffset = yData[saccadeEnd];\n\n    if (\n      xOnset == null || yOnset == null || xOffset == null || yOffset == null ||\n      Number.isNaN(xOnset) || Number.isNaN(yOnset) ||\n      Number.isNaN(xOffset) || Number.isNaN(yOffset)\n    ) {\n      continue;\n    }\n\n    const duration = timestamps[saccadeEnd]! - timestamps[saccadeStart]!;\n    const onset = timestamps[saccadeStart]!;\n\n    // Calculate amplitude\n    const amplitude =\n      Math.sqrt((xOffset - xOnset) ** 2 + (yOffset - yOnset) ** 2) / oneDegree;\n\n    // Check for duplicates\n    const isDuplicate =\n      saccades.length > 0 && saccades[saccades.length - 1]!.onset === onset;\n\n    if (duration > minSaccadeDuration && !isDuplicate && onset !== nonvalidSaccadeOnset) {\n      // Calculate peak velocity\n      const saccadeVelocities = velocityVector\n        .slice(saccadeStart, saccadeEnd + 1)\n        .filter(v => v !== null && !Number.isNaN(v));\n\n      const peakVelocity =\n        saccadeVelocities.length > 0 ? Math.max(...saccadeVelocities) : NaN;\n\n      // Calculate missing samples\n      const saccadeX = xData.slice(saccadeStart, saccadeEnd + 1);\n      const missingCount = saccadeX.filter(x => x == null || Number.isNaN(x)).length;\n      const missingSamples = missingCount / saccadeX.length;\n\n      const saccade: Saccade = {\n        onset,\n        xOnset,\n        yOnset,\n        offset: timestamps[saccadeEnd]!,\n        xOffset,\n        yOffset,\n        duration,\n        amplitude,\n        peakVelocity,\n        missingSamples,\n        firstLine: saccadeStart,\n        lastLine: saccadeEnd,\n      };\n\n      saccades.push(saccade);\n\n      if (saveVelocityProfiles) {\n        velocityProfiles.push(saccadeVelocities);\n      }\n    }\n  }\n\n  // Filter saccades by amplitude\n  const filteredSaccades = saccades.filter(s => s.amplitude >= minSaccadeAmplitude);\n\n  if (saveVelocityProfiles) {\n    filteredSaccades.forEach((s, i) => {\n      s.velocityProfile = velocityProfiles[i];\n    });\n  }\n\n  // IDENTIFY FIXATIONS\n  console.log('Searching for fixations');\n\n  const fixations: Fixation[] = [];\n\n  if (filteredSaccades.length === 0) {\n    console.warn('No saccades detected. Check data format!');\n  } else {\n    for (let i = 0; i < filteredSaccades.length - 1; i++) {\n      const fixStart = filteredSaccades[i]!.lastLine! + 1;\n      const fixEnd = filteredSaccades[i + 1]!.firstLine! - 1;\n\n      if (fixEnd > fixStart) {\n        const thisFixation = summarizeFixationMetrics(\n          fixStart,\n          fixEnd,\n          xData,\n          yData,\n          timestamps,\n          oneDegree\n        );\n\n        fixations.push(thisFixation);\n      }\n    }\n  }\n\n  // Create filtered gaze structure\n  const filteredGaze: FilteredGazeData[] = gazeData.map(d => ({\n    timestamp: d.timestamp,\n    xRaw: (d as unknown as Record<string, number>)[xcol]!,\n    yRaw: (d as unknown as Record<string, number>)[ycol]!,\n    x: null,\n    y: null,\n  }));\n\n  // Trim fixations if requested\n  let processedFixations = fixations;\n\n  if (shouldTrimFixations) {\n    processedFixations = trimFixations(\n      fixations,\n      filteredGaze,\n      'xRaw',\n      'yRaw',\n      trimDispersionThreshold,\n      oneDegree\n    );\n  }\n\n  // Merge adjacent fixations\n  if (distanceThreshold > 0) {\n    processedFixations = mergeAdjacentFixations(\n      processedFixations,\n      filteredGaze,\n      distanceThreshold,\n      mergeMsThreshold,\n      oneDegree,\n      'xRaw',\n      'yRaw'\n    );\n  }\n\n  // Filter fixations\n  const finalFixations = processedFixations\n    .filter(\n      f => f.duration >= minFixationDuration && f.missingSamples < missingSamplesThreshold\n    )\n    .map(f => ({\n      ...f,\n      algorithm: 'adaptive',\n      threshold: `${Math.round(peakThreshold)} deg. (peak); ${Math.round(onsetThreshold)} deg. (onset)`,\n    }));\n\n  // Fill in filtered gaze coordinates\n  for (const fixation of finalFixations) {\n    for (let i = fixation.firstLine; i <= fixation.lastLine; i++) {\n      filteredGaze[i]!.x = fixation.x;\n      filteredGaze[i]!.y = fixation.y;\n    }\n  }\n\n  // Create velocity output\n  const velocityOutput: VelocityData[] = timestamps.map((t, i) => ({\n    timestamp: t,\n    velocity: velocityVector[i] ?? NaN,\n  }));\n\n  return {\n    fixations: finalFixations,\n    saccades: filteredSaccades,\n    filteredGaze,\n    velocity: velocityOutput,\n  };\n}\n", "/**\n * Area of Interest (AOI) analysis functions\n *\n * Functions for analyzing gaze behavior within defined spatial regions\n *\n * @module analysis/aoi\n */\n\nimport type {\n  AOI,\n  AOIResult,\n  Fixation,\n  ProcessedGazeData,\n  FilteredGazeData,\n} from '../types/index.js';\n\n/**\n * Check if a point is inside a rectangular AOI\n *\n * @param x - X coordinate\n * @param y - Y coordinate\n * @param aoi - AOI definition\n * @returns True if point is inside AOI\n */\nfunction isInRectangularAOI(x: number, y: number, aoi: AOI): boolean {\n  return x >= aoi.x0 && x <= aoi.x1 && y >= aoi.y0 && y <= aoi.y1;\n}\n\n/**\n * Check if a point is inside a circular/elliptical AOI\n *\n * The AOI bounds (x0, x1, y0, y1) define the bounding box of the ellipse\n *\n * @param x - X coordinate\n * @param y - Y coordinate\n * @param aoi - AOI definition\n * @returns True if point is inside AOI\n */\nfunction isInCircularAOI(x: number, y: number, aoi: AOI): boolean {\n  // Calculate ellipse center and radii\n  const centerX = (aoi.x0 + aoi.x1) / 2;\n  const centerY = (aoi.y0 + aoi.y1) / 2;\n  const radiusX = (aoi.x1 - aoi.x0) / 2;\n  const radiusY = (aoi.y1 - aoi.y0) / 2;\n\n  // Ellipse equation: (x-cx)/rx + (y-cy)/ry <= 1\n  const dx = x - centerX;\n  const dy = y - centerY;\n\n  return (dx * dx) / (radiusX * radiusX) + (dy * dy) / (radiusY * radiusY) <= 1;\n}\n\n/**\n * Check if a point is inside an AOI\n *\n * @param x - X coordinate\n * @param y - Y coordinate\n * @param aoi - AOI definition\n * @returns True if point is inside AOI\n *\n * @example\n * ```ts\n * const aoi = {\n *   x0: 100, x1: 200,\n *   y0: 100, y1: 200,\n *   type: 'rect' as const,\n *   name: 'Button'\n * };\n *\n * const isInside = isPointInAOI(150, 150, aoi); // true\n * ```\n */\nexport function isPointInAOI(x: number, y: number, aoi: AOI): boolean {\n  if (Number.isNaN(x) || Number.isNaN(y)) {\n    return false;\n  }\n\n  switch (aoi.type) {\n    case 'rect':\n      return isInRectangularAOI(x, y, aoi);\n    case 'circle':\n      return isInCircularAOI(x, y, aoi);\n    default:\n      throw new Error(`Unknown AOI type: ${aoi.type}`);\n  }\n}\n\n/**\n * Classify gaze samples by AOI\n *\n * Returns an array of AOI identifiers for each sample, or null if outside all AOIs\n *\n * @param gazeData - Gaze data samples\n * @param aois - Array of AOI definitions\n * @param xcol - Name of x coordinate column\n * @param ycol - Name of y coordinate column\n * @returns Array of AOI identifiers (one per sample)\n *\n * @example\n * ```ts\n * const aois = [\n *   { x0: 0, x1: 100, y0: 0, y1: 100, type: 'rect', name: 'Left' },\n *   { x0: 200, x1: 300, y0: 0, y1: 100, type: 'rect', name: 'Right' }\n * ];\n *\n * const classifications = classifyGazeSamples(gazeData, aois);\n * console.log(classifications[0]); // 'Left', 'Right', or null\n * ```\n */\nexport function classifyGazeSamples(\n  gazeData: (ProcessedGazeData | FilteredGazeData)[],\n  aois: AOI[],\n  xcol = 'x',\n  ycol = 'y'\n): (string | number | null)[] {\n  const classifications: (string | number | null)[] = [];\n\n  for (const sample of gazeData) {\n    const x = (sample as unknown as Record<string, number>)[xcol];\n    const y = (sample as unknown as Record<string, number>)[ycol];\n\n    if (x == null || y == null || Number.isNaN(x) || Number.isNaN(y)) {\n      classifications.push(null);\n      continue;\n    }\n\n    // Find first matching AOI\n    let matchedAOI: string | number | null = null;\n    for (const aoi of aois) {\n      if (isPointInAOI(x, y, aoi)) {\n        matchedAOI = aoi.name ?? aois.indexOf(aoi);\n        break;\n      }\n    }\n\n    classifications.push(matchedAOI);\n  }\n\n  return classifications;\n}\n\n/**\n * Classify fixations by AOI\n *\n * Returns an array of AOI identifiers for each fixation based on fixation center\n *\n * @param fixations - Array of fixations\n * @param aois - Array of AOI definitions\n * @returns Array of AOI identifiers (one per fixation)\n *\n * @example\n * ```ts\n * const aoiLabels = classifyFixations(fixations, aois);\n * fixations.forEach((fix, i) => {\n *   console.log(`Fixation ${i} in AOI: ${aoiLabels[i]}`);\n * });\n * ```\n */\nexport function classifyFixations(\n  fixations: Fixation[],\n  aois: AOI[]\n): (string | number | null)[] {\n  const classifications: (string | number | null)[] = [];\n\n  for (const fixation of fixations) {\n    let matchedAOI: string | number | null = null;\n\n    for (const aoi of aois) {\n      if (isPointInAOI(fixation.x, fixation.y, aoi)) {\n        matchedAOI = aoi.name ?? aois.indexOf(aoi);\n        break;\n      }\n    }\n\n    classifications.push(matchedAOI);\n  }\n\n  return classifications;\n}\n\n/**\n * Calculate total dwell time in an AOI from gaze samples\n *\n * @param gazeData - Gaze data samples\n * @param aoi - AOI definition\n * @param xcol - Name of x coordinate column\n * @param ycol - Name of y coordinate column\n * @returns Total dwell time in milliseconds\n *\n * @example\n * ```ts\n * const dwellTime = calculateDwellTime(gazeData, buttonAOI);\n * console.log(`User looked at button for ${dwellTime}ms`);\n * ```\n */\nexport function calculateDwellTime(\n  gazeData: (ProcessedGazeData | FilteredGazeData)[],\n  aoi: AOI,\n  xcol = 'x',\n  ycol = 'y'\n): number {\n  if (gazeData.length === 0) {\n    return 0;\n  }\n\n  let totalDuration = 0;\n  let lastTimestamp: number | null = null;\n\n  for (const sample of gazeData) {\n    const x = (sample as unknown as Record<string, number>)[xcol];\n    const y = (sample as unknown as Record<string, number>)[ycol];\n\n    if (x != null && y != null && !Number.isNaN(x) && !Number.isNaN(y)) {\n      if (isPointInAOI(x, y, aoi)) {\n        if (lastTimestamp !== null) {\n          totalDuration += sample.timestamp - lastTimestamp;\n        }\n      }\n    }\n\n    lastTimestamp = sample.timestamp;\n  }\n\n  return totalDuration;\n}\n\n/**\n * Calculate first fixation latency to an AOI\n *\n * Time from start of recording to first fixation in AOI\n *\n * @param fixations - Array of fixations\n * @param aoi - AOI definition\n * @param startTime - Recording start time (default: 0)\n * @returns Latency in milliseconds, or Infinity if AOI never fixated\n *\n * @example\n * ```ts\n * const latency = calculateFirstFixationLatency(fixations, targetAOI);\n * if (latency < Infinity) {\n *   console.log(`First fixation after ${latency}ms`);\n * } else {\n *   console.log('AOI never fixated');\n * }\n * ```\n */\nexport function calculateFirstFixationLatency(\n  fixations: Fixation[],\n  aoi: AOI,\n  startTime = 0\n): number {\n  for (const fixation of fixations) {\n    if (isPointInAOI(fixation.x, fixation.y, aoi)) {\n      return fixation.onset - startTime;\n    }\n  }\n\n  return Infinity;\n}\n\n/**\n * Calculate total fixation duration within an AOI\n *\n * @param fixations - Array of fixations\n * @param aoi - AOI definition\n * @returns Total fixation duration in milliseconds\n *\n * @example\n * ```ts\n * const totalFix = calculateFixationDuration(fixations, imageAOI);\n * console.log(`Total fixation time: ${totalFix}ms`);\n * ```\n */\nexport function calculateFixationDuration(fixations: Fixation[], aoi: AOI): number {\n  let totalDuration = 0;\n\n  for (const fixation of fixations) {\n    if (isPointInAOI(fixation.x, fixation.y, aoi)) {\n      totalDuration += fixation.duration;\n    }\n  }\n\n  return totalDuration;\n}\n\n/**\n * Count fixations within an AOI\n *\n * @param fixations - Array of fixations\n * @param aoi - AOI definition\n * @returns Number of fixations in AOI\n *\n * @example\n * ```ts\n * const count = countFixationsInAOI(fixations, buttonAOI);\n * console.log(`${count} fixations on button`);\n * ```\n */\nexport function countFixationsInAOI(fixations: Fixation[], aoi: AOI): number {\n  let count = 0;\n\n  for (const fixation of fixations) {\n    if (isPointInAOI(fixation.x, fixation.y, aoi)) {\n      count++;\n    }\n  }\n\n  return count;\n}\n\n/**\n * Analyze fixations for a single AOI\n *\n * Comprehensive analysis including dwell time, count, and latency\n *\n * @param fixations - Array of fixations\n * @param aoi - AOI definition\n * @param startTime - Recording start time (default: 0)\n * @returns AOI analysis result\n *\n * @example\n * ```ts\n * const result = analyzeAOI(fixations, targetAOI);\n * console.log(`Duration: ${result.totalDuration}ms`);\n * console.log(`Count: ${result.count} fixations`);\n * console.log(`Latency: ${result.latency}ms`);\n * ```\n */\nexport function analyzeAOI(\n  fixations: Fixation[],\n  aoi: AOI,\n  startTime = 0\n): AOIResult {\n  const totalDuration = calculateFixationDuration(fixations, aoi);\n  const count = countFixationsInAOI(fixations, aoi);\n  const latency = calculateFirstFixationLatency(fixations, aoi, startTime);\n\n  return {\n    totalDuration,\n    count,\n    latency,\n    aoi: aoi.name ?? 'unnamed',\n  };\n}\n\n/**\n * Analyze fixations for multiple AOIs\n *\n * @param fixations - Array of fixations\n * @param aois - Array of AOI definitions\n * @param startTime - Recording start time (default: 0)\n * @returns Array of AOI analysis results\n *\n * @example\n * ```ts\n * const aois = [\n *   { x0: 0, x1: 100, y0: 0, y1: 100, type: 'rect', name: 'Left' },\n *   { x0: 200, x1: 300, y0: 0, y1: 100, type: 'rect', name: 'Right' }\n * ];\n *\n * const results = analyzeMultipleAOIs(fixations, aois);\n * results.forEach(r => {\n *   console.log(`${r.aoi}: ${r.count} fixations, ${r.totalDuration}ms`);\n * });\n * ```\n */\nexport function analyzeMultipleAOIs(\n  fixations: Fixation[],\n  aois: AOI[],\n  startTime = 0\n): AOIResult[] {\n  return aois.map(aoi => analyzeAOI(fixations, aoi, startTime));\n}\n\n/**\n * Calculate proportion of total fixation time spent in each AOI\n *\n * @param fixations - Array of fixations\n * @param aois - Array of AOI definitions\n * @returns Object mapping AOI names to proportions [0-1]\n *\n * @example\n * ```ts\n * const proportions = calculateAOIProportions(fixations, aois);\n * console.log(`Left: ${(proportions.Left * 100).toFixed(1)}%`);\n * console.log(`Right: ${(proportions.Right * 100).toFixed(1)}%`);\n * ```\n */\nexport function calculateAOIProportions(\n  fixations: Fixation[],\n  aois: AOI[]\n): Record<string | number, number> {\n  const totalFixationTime = fixations.reduce((sum, fix) => sum + fix.duration, 0);\n\n  if (totalFixationTime === 0) {\n    const result: Record<string | number, number> = {};\n    aois.forEach(aoi => {\n      result[aoi.name ?? aois.indexOf(aoi)] = 0;\n    });\n    return result;\n  }\n\n  const results = analyzeMultipleAOIs(fixations, aois);\n  const proportions: Record<string | number, number> = {};\n\n  results.forEach(result => {\n    proportions[result.aoi] = result.totalDuration / totalFixationTime;\n  });\n\n  return proportions;\n}\n\n/**\n * Create a transition matrix showing gaze movements between AOIs\n *\n * Returns a matrix where entry [i][j] represents the number of transitions\n * from AOI i to AOI j\n *\n * @param fixations - Array of fixations\n * @param aois - Array of AOI definitions\n * @returns Transition matrix and AOI names\n *\n * @example\n * ```ts\n * const { matrix, aoiNames } = calculateAOITransitionMatrix(fixations, aois);\n * console.log(`Transitions from ${aoiNames[0]} to ${aoiNames[1]}: ${matrix[0][1]}`);\n * ```\n */\nexport function calculateAOITransitionMatrix(\n  fixations: Fixation[],\n  aois: AOI[]\n): { matrix: number[][]; aoiNames: (string | number)[] } {\n  const aoiNames = aois.map((aoi, i) => aoi.name ?? i);\n\n  // Initialize matrix with zeros\n  const matrix: number[][] = Array(aois.length)\n    .fill(0)\n    .map(() => Array(aois.length).fill(0));\n\n  // Classify fixations\n  const classifications = classifyFixations(fixations, aois);\n\n  // Count transitions\n  for (let i = 1; i < classifications.length; i++) {\n    const fromAOI = classifications[i - 1];\n    const toAOI = classifications[i];\n\n    if (fromAOI !== null && toAOI !== null && fromAOI !== undefined && toAOI !== undefined) {\n      const fromIndex = aoiNames.indexOf(fromAOI);\n      const toIndex = aoiNames.indexOf(toAOI);\n\n      if (fromIndex >= 0 && toIndex >= 0) {\n        matrix[fromIndex]![toIndex]!++;\n      }\n    }\n  }\n\n  return { matrix, aoiNames };\n}\n\n/**\n * Calculate average fixation duration within an AOI\n *\n * @param fixations - Array of fixations\n * @param aoi - AOI definition\n * @returns Average fixation duration in milliseconds\n *\n * @example\n * ```ts\n * const avgDuration = calculateAverageFixationDuration(fixations, imageAOI);\n * console.log(`Average fixation: ${avgDuration.toFixed(1)}ms`);\n * ```\n */\nexport function calculateAverageFixationDuration(\n  fixations: Fixation[],\n  aoi: AOI\n): number {\n  const aoiFixations = fixations.filter(fix => isPointInAOI(fix.x, fix.y, aoi));\n\n  if (aoiFixations.length === 0) {\n    return 0;\n  }\n\n  const totalDuration = aoiFixations.reduce((sum, fix) => sum + fix.duration, 0);\n  return totalDuration / aoiFixations.length;\n}\n\n/**\n * Get all fixations within an AOI\n *\n * @param fixations - Array of fixations\n * @param aoi - AOI definition\n * @returns Array of fixations within AOI\n *\n * @example\n * ```ts\n * const buttonFixations = getFixationsInAOI(fixations, buttonAOI);\n * console.log(`${buttonFixations.length} fixations on button`);\n * ```\n */\nexport function getFixationsInAOI(fixations: Fixation[], aoi: AOI): Fixation[] {\n  return fixations.filter(fix => isPointInAOI(fix.x, fix.y, aoi));\n}\n\n/**\n * Check if any fixation occurs within an AOI\n *\n * @param fixations - Array of fixations\n * @param aoi - AOI definition\n * @returns True if at least one fixation is in AOI\n *\n * @example\n * ```ts\n * if (hasFixationInAOI(fixations, targetAOI)) {\n *   console.log('Target was fixated');\n * }\n * ```\n */\nexport function hasFixationInAOI(fixations: Fixation[], aoi: AOI): boolean {\n  return fixations.some(fix => isPointInAOI(fix.x, fix.y, aoi));\n}\n", "/**\n * Fixation Detection Web Worker\n *\n * Runs I-VT and I-DT algorithms in a background thread to prevent\n * blocking the main UI thread during real-time processing.\n *\n * This worker receives gaze data buffers from the main thread and\n * returns fixation results asynchronously.\n */\n\n/* eslint-disable no-restricted-globals */\n// 'self' is the correct global in Web Worker context\n\nimport { preprocessGaze, algorithmIVT, algorithmIDT } from 'kollar-ts';\n\n/**\n * Message types for worker communication\n */\nexport type WorkerMessageType = 'process' | 'reset';\n\nexport interface RawGazeData {\n  timestamp: number;\n  x: number;\n  y: number;\n}\n\nexport interface RealtimeFixation {\n  algorithm: 'ivt' | 'idt';\n  x: number;\n  y: number;\n  duration: number;\n  timestamp: number;\n}\n\nexport interface WorkerInputMessage {\n  type: WorkerMessageType;\n  buffer?: RawGazeData[];\n  enableIVT?: boolean;\n  enableIDT?: boolean;\n  oneDegree?: number;\n}\n\nexport interface WorkerOutputMessage {\n  type: 'result' | 'error' | 'ready';\n  fixationIVT?: RealtimeFixation | null;\n  fixationIDT?: RealtimeFixation | null;\n  error?: string;\n}\n\nconst MIN_SAMPLES_FOR_DETECTION = 60;\n\n/**\n * Process buffer with I-VT algorithm\n */\nfunction processIVT(buffer: RawGazeData[], oneDegree: number): RealtimeFixation | null {\n  try {\n    // Calculate sampling rate from buffer\n    const bufferDuration = buffer[buffer.length - 1].timestamp - buffer[0].timestamp;\n    const samplingRate = buffer.length / (bufferDuration / 1000); // Hz\n\n    // Adaptive smoothing - use smaller window for low sample rates\n    const filterMs = samplingRate > 50 ? 15 : Math.max(5, Math.floor(1000 / samplingRate));\n\n    const processed = preprocessGaze(buffer, {\n      maxGapMs: 75,\n      marginMs: 5,\n      filterMs, // Adaptive smoothing window\n    });\n\n    const result = algorithmIVT(processed, {\n      velocityThreshold: 30, // degrees/second\n      minFixationDuration: 100, // ms\n      minSaccadeDuration: 20,\n      minSaccadeAmplitude: 0.5,\n      oneDegree,\n      saveVelocityProfiles: false,\n    });\n\n    // Get the most recent fixation\n    if (result.fixations.length > 0) {\n      const latestFixation = result.fixations[result.fixations.length - 1];\n\n      // Check if this fixation is still ongoing (includes current time)\n      const fixationEndTime = latestFixation.onset + latestFixation.duration;\n      const currentTime = buffer[buffer.length - 1].timestamp;\n\n      if (fixationEndTime >= currentTime - 100) {\n        return {\n          algorithm: 'ivt',\n          x: latestFixation.x,\n          y: latestFixation.y,\n          duration: latestFixation.duration,\n          timestamp: latestFixation.onset,\n        };\n      }\n    }\n\n    return null;\n  } catch (error) {\n    console.warn('I-VT processing error in worker:', error);\n    return null;\n  }\n}\n\n/**\n * Process buffer with I-DT algorithm\n */\nfunction processIDT(buffer: RawGazeData[], oneDegree: number): RealtimeFixation | null {\n  try {\n    // Calculate sampling rate from buffer\n    const bufferDuration = buffer[buffer.length - 1].timestamp - buffer[0].timestamp;\n    const samplingRate = buffer.length / (bufferDuration / 1000); // Hz\n\n    // Adaptive smoothing - use smaller window for low sample rates\n    const filterMs = samplingRate > 50 ? 15 : Math.max(5, Math.floor(1000 / samplingRate));\n\n    const processed = preprocessGaze(buffer, {\n      maxGapMs: 75,\n      marginMs: 5,\n      filterMs, // Adaptive smoothing window\n    });\n\n    const result = algorithmIDT(processed, {\n      dispersionThreshold: 1.0, // degrees\n      minDuration: 100, // ms\n      oneDegree,\n    });\n\n    // Get the most recent fixation\n    if (result.fixations.length > 0) {\n      const latestFixation = result.fixations[result.fixations.length - 1];\n\n      // Check if this fixation is still ongoing\n      const fixationEndTime = latestFixation.onset + latestFixation.duration;\n      const currentTime = buffer[buffer.length - 1].timestamp;\n\n      if (fixationEndTime >= currentTime - 100) {\n        return {\n          algorithm: 'idt',\n          x: latestFixation.x,\n          y: latestFixation.y,\n          duration: latestFixation.duration,\n          timestamp: latestFixation.onset,\n        };\n      }\n    }\n\n    return null;\n  } catch (error) {\n    console.warn('I-DT processing error in worker:', error);\n    return null;\n  }\n}\n\n/**\n * Main message handler\n */\nself.onmessage = (event: MessageEvent<WorkerInputMessage>) => {\n  const { type, buffer, enableIVT, enableIDT, oneDegree } = event.data;\n\n  try {\n    switch (type) {\n      case 'process': {\n        if (!buffer || buffer.length < MIN_SAMPLES_FOR_DETECTION) {\n          // Not enough data - send null results\n          const response: WorkerOutputMessage = {\n            type: 'result',\n            fixationIVT: null,\n            fixationIDT: null,\n          };\n          self.postMessage(response);\n          return;\n        }\n\n        // Validate buffer duration (defensive check)\n        const bufferDuration = buffer[buffer.length - 1].timestamp - buffer[0].timestamp;\n        if (bufferDuration < 100) {\n          // Suspicious buffer - skip processing\n          const response: WorkerOutputMessage = {\n            type: 'result',\n            fixationIVT: null,\n            fixationIDT: null,\n          };\n          self.postMessage(response);\n          return;\n        }\n\n        // Process algorithms in parallel (non-blocking in worker thread)\n        const fixationIVT = enableIVT ? processIVT(buffer, oneDegree || 40) : null;\n        const fixationIDT = enableIDT ? processIDT(buffer, oneDegree || 40) : null;\n\n        // Send results back to main thread\n        const response: WorkerOutputMessage = {\n          type: 'result',\n          fixationIVT,\n          fixationIDT,\n        };\n        self.postMessage(response);\n        break;\n      }\n\n      case 'reset': {\n        // Reset state (nothing to do in stateless worker)\n        const response: WorkerOutputMessage = {\n          type: 'ready',\n        };\n        self.postMessage(response);\n        break;\n      }\n\n      default:\n        console.warn('Unknown message type:', type);\n    }\n  } catch (error) {\n    // Send error back to main thread\n    const response: WorkerOutputMessage = {\n      type: 'error',\n      error: error instanceof Error ? error.message : String(error),\n    };\n    self.postMessage(response);\n  }\n};\n\n// Signal that worker is ready\nconst readyMessage: WorkerOutputMessage = {\n  type: 'ready',\n};\nself.postMessage(readyMessage);\n"],
  "mappings": ";;;AEkBA,WAAS,IAAI,GAAG;AAEZ,QAAI,EAAE,WAAW,GAAG;AAChB,aAAO;IACf;AAGIA,QAAIC,OAAM,EAAE,CAAC;AAGbD,QAAI,aAAa;AAEjBA,QAAI;AAEJ,QAAI,OAAOC,SAAQ,UAAU;AACzB,aAAO,OAAO;IACtB;AAEI,aAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAK;AAC/B,UAAI,OAAO,EAAE,CAAC,MAAM,UAAU;AAC1B,eAAO,OAAO;MAC1B;AACQ,mBAAaA,OAAM,EAAE,CAAC;AAItB,UAAI,KAAK,IAAIA,IAAG,KAAK,KAAK,IAAI,EAAE,CAAC,CAAC,GAAG;AACjC,sBAAcA,OAAM,aAAa,EAAE,CAAC;MAChD,OAAe;AACH,sBAAc,EAAE,CAAC,IAAI,aAAaA;MAC9C;AAEQ,MAAAA,OAAM;IACd;AAGI,WAAOA,OAAM;EACjB;ACvCA,WAAS,KAAK,GAAG;AACb,QAAI,EAAE,WAAW,GAAG;AAChB,YAAM,IAAI,MAAM,uCAAuC;IAC/D;AAEI,WAAO,IAAI,CAAC,IAAI,EAAE;EACtB;AiBTA,WAAS,eAAe,GAAG,GAAG;AAC1BC,QAAM,MAAM,EAAE,SAAS;AACvB,QAAI,EAAE,WAAW,GAAG;AAChB,YAAM,IAAI,MAAM,4CAA4C;IACpE,WAAe,IAAI,KAAK,IAAI,GAAG;AACvB,YAAM,IAAI,MAAM,mCAAmC;IAC3D,WAAe,MAAM,GAAG;AAEhB,aAAO,EAAE,EAAE,SAAS,CAAC;IAC7B,WAAe,MAAM,GAAG;AAEhB,aAAO,EAAE,CAAC;IAClB,WAAe,MAAM,MAAM,GAAG;AAEtB,aAAO,EAAE,KAAK,KAAK,GAAG,IAAI,CAAC;IACnC,WAAe,EAAE,SAAS,MAAM,GAAG;AAG3B,cAAQ,EAAE,MAAM,CAAC,IAAI,EAAE,GAAG,KAAK;IACvC,OAAW;AAGH,aAAO,EAAE,GAAG;IACpB;EACA;ACrBA,WAAS,YAAY,KAAK,GAAG,MAAM,OAAO;AACtC,WAAO,QAAQ;AACf,YAAQ,SAAS,IAAI,SAAS;AAE9B,WAAO,QAAQ,MAAM;AAEjB,UAAI,QAAQ,OAAO,KAAK;AACpBA,YAAM,IAAI,QAAQ,OAAO;AACzBA,YAAM,IAAI,IAAI,OAAO;AACrBA,YAAM,IAAI,KAAK,IAAI,CAAC;AACpBA,YAAM,IAAI,MAAM,KAAK,IAAK,IAAI,IAAK,CAAC;AACpCC,YAAI,KAAK,MAAM,KAAK,KAAM,IAAI,KAAK,IAAI,KAAM,CAAC;AAC9C,YAAI,IAAI,IAAI,IAAI,GAAG;AAAA,gBAAM;QAAG;AAC5BD,YAAM,UAAU,KAAK,IAAI,MAAM,KAAK,MAAM,IAAK,IAAI,IAAK,IAAI,EAAE,CAAC;AAC/DA,YAAM,WAAW,KAAK;UAClB;UACA,KAAK,MAAM,KAAM,IAAI,KAAK,IAAK,IAAI,EAAE;QACrD;AACY,oBAAY,KAAK,GAAG,SAAS,QAAQ;MACjD;AAEQA,UAAM,IAAI,IAAI,CAAC;AACfC,UAAI,IAAI;AACRA,UAAI,IAAI;AAER,WAAK,KAAK,MAAM,CAAC;AACjB,UAAI,IAAI,KAAK,IAAI,GAAC;AAAE,aAAK,KAAK,MAAM,KAAK;MAAE;AAE3C,aAAO,IAAI,GAAG;AACV,aAAK,KAAK,GAAG,CAAC;AACd;AACA;AACA,eAAO,IAAI,CAAC,IAAI,GAAC;AAAE;QAAI;AACvB,eAAO,IAAI,CAAC,IAAI,GAAC;AAAE;QAAI;MACnC;AAEQ,UAAI,IAAI,IAAI,MAAM,GAAC;AAAE,aAAK,KAAK,MAAM,CAAC;MAAE,OACnC;AACD;AACA,aAAK,KAAK,GAAG,KAAK;MAC9B;AAEQ,UAAI,KAAK,GAAC;AAAE,eAAO,IAAI;MAAE;AACzB,UAAI,KAAK,GAAC;AAAE,gBAAQ,IAAI;MAAE;IAClC;EACA;AAEA,WAAS,KAAK,KAAK,GAAG,GAAG;AACrBD,QAAM,MAAM,IAAI,CAAC;AACjB,QAAI,CAAC,IAAI,IAAI,CAAC;AACd,QAAI,CAAC,IAAI;EACb;AC3CA,WAAS,SAAS,GAAG,GAAG;AACpBA,QAAM,OAAO,EAAE,MAAK;AAEpB,QAAI,MAAM,QAAQ,CAAC,GAAG;AAGlB,0BAAoB,MAAM,CAAC;AAE3BA,UAAM,UAAU,CAAA;AAEhB,eAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAK;AAC/B,gBAAQ,CAAC,IAAI,eAAe,MAAM,EAAE,CAAC,CAAC;MAClD;AACQ,aAAO;IACf,OAAW;AACHA,UAAM,MAAM,cAAc,KAAK,QAAQ,CAAC;AACxC,qBAAe,MAAM,KAAK,GAAG,KAAK,SAAS,CAAC;AAC5C,aAAO,eAAe,MAAM,CAAC;IACrC;EACA;AAEA,WAAS,eAAe,KAAK,GAAG,MAAM,OAAO;AACzC,QAAI,IAAI,MAAM,GAAG;AACb,kBAAY,KAAK,GAAG,MAAM,KAAK;IACvC,OAAW;AACH,UAAI,KAAK,MAAM,CAAC;AAChB,kBAAY,KAAK,GAAG,MAAM,KAAK;AAC/B,kBAAY,KAAK,IAAI,GAAG,IAAI,GAAG,KAAK;IAC5C;EACA;AAEA,WAAS,oBAAoB,KAAK,GAAG;AACjCA,QAAM,UAAU,CAAC,CAAC;AAClB,aAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAK;AAC/B,cAAQ,KAAK,cAAc,IAAI,QAAQ,EAAE,CAAC,CAAC,CAAC;IACpD;AACI,YAAQ,KAAK,IAAI,SAAS,CAAC;AAC3B,YAAQ,KAAK,OAAO;AAEpBA,QAAM,QAAQ,CAAC,GAAG,QAAQ,SAAS,CAAC;AAEpC,WAAO,MAAM,QAAQ;AACjBA,UAAM,IAAI,KAAK,KAAK,MAAM,IAAG,CAAE;AAC/BA,UAAM,IAAI,KAAK,MAAM,MAAM,IAAG,CAAE;AAChC,UAAI,IAAI,KAAK,GAAC;AAAE;MAAS;AAEzBA,UAAM,IAAI,KAAK,OAAO,IAAI,KAAK,CAAC;AAChC;QACI;QACA,QAAQ,CAAC;QACT,KAAK,MAAM,QAAQ,CAAC,CAAC;QACrB,KAAK,KAAK,QAAQ,CAAC,CAAC;MAChC;AAEQ,YAAM,KAAK,GAAG,GAAG,GAAG,CAAC;IAC7B;EACA;AAEA,WAAS,QAAQ,GAAG,GAAG;AACnB,WAAO,IAAI;EACf;AAEA,WAAS,cAAc,KAAK,GAAG;AAC3BA,QAAM,MAAM,MAAM;AAClB,QAAI,MAAM,GAAG;AAET,aAAO,MAAM;IACrB,WAAe,MAAM,GAAG;AAEhB,aAAO;IACf,WAAe,MAAM,MAAM,GAAG;AAEtB,aAAO,KAAK,KAAK,GAAG,IAAI;IAChC,WAAe,MAAM,MAAM,GAAG;AAGtB,aAAO,MAAM;IACrB,OAAW;AAGH,aAAO;IACf;EACA;AIxFA,WAAS,OAAO,GAAG;AACf,WAAO,CAAC,SAAS,GAAG,GAAG;EAC3B;AsCAM,MAAA,qBAGF,SAAAE,sBAAc;AAGV,SAAK,aAAa;AAElB,SAAK,OAAO,CAAA;EAChB;AAUA,qBAAA,UAAA,QAAA,SAAA,MAAM,MAAM,UAAU;AAGlB,QAAI,CAAC,KAAK,KAAK,QAAQ,GAAG;AACtB,WAAK,KAAK,QAAQ,IAAI,CAAA;IAClC;AAGQ,aAAW,KAAK,MAAM;AAClBC,UAAM,IAAI,KAAK,CAAC;AAGhB,UAAI,KAAK,KAAK,QAAQ,EAAE,CAAC,MAAM,QAAW;AACtC,aAAK,KAAK,QAAQ,EAAE,CAAC,IAAI,CAAA;MACzC;AACY,UAAI,KAAK,KAAK,QAAQ,EAAE,CAAC,EAAE,CAAC,MAAM,QAAW;AACzC,aAAK,KAAK,QAAQ,EAAE,CAAC,EAAE,CAAC,IAAI;MAC5C;AAGY,WAAK,KAAK,QAAQ,EAAE,CAAC,EAAE,CAAC;IACpC;AAGQ,SAAK;EACT;+BAUA,QAAK,SAAA,MAAC,MAAM;AAERA,QAAM,OAAO,CAAA;AACbC,QAAI;AAIJ,aAAW,KAAK,MAAM;AAClBD,UAAM,IAAI,KAAK,CAAC;AAChB,WAAK,YAAY,KAAK,MAAM;AAGxB,aAAK,QAAQ,IAAI,CAAA;AAMjB,YAAI,KAAK,KAAK,QAAQ,EAAE,CAAC,GAAG;AACxB,eAAK,QAAQ,EAAE,IAAI,MAAM,CAAC,KACrB,KAAK,KAAK,QAAQ,EAAE,CAAC,EAAE,CAAC,KAAK,KAAK,KAAK;QAChE,OAAuB;AACH,eAAK,QAAQ,EAAE,IAAI,MAAM,CAAC,IAAI;QAClD;MACA;IACA;AAGQA,QAAM,WAAW,CAAA;AAEjB,SAAK,YAAY,MAAM;AAInB,eAAS,QAAQ,IAAI;AACrB,eAAW,eAAe,KAAK,QAAQ,GAAG;AACtC,iBAAS,QAAQ,KAAK,KAAK,QAAQ,EAAE,WAAW;MAChE;IACA;AAEQ,WAAO;EACX;AC/FE,MAAA,kBAGF,SAAAE,mBAAc;AAGV,SAAK,UAAU,CAAA;AAIf,SAAK,OAAO;EAChB;4BAQA,UAAO,SAAA,QAAC,UAAU;AAGd,QAAI,SAAS,WAAW,KAAK,QAAQ,QAAQ;AACzC,aAAO;IACnB;AAIQD,QAAIE,SAAQ;AACZ,aAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,QAAQ,KAAK;AAC1C,MAAAA,UAAS,KAAK,QAAQ,CAAC,IAAI,SAAS,CAAC;IACjD;AACQ,IAAAA,UAAS,KAAK;AAGd,QAAIA,SAAQ,GAAG;AACX,aAAO;IACnB,OAAe;AACH,aAAO;IACnB;EACI;AAUA,kBAAA,UAAA,QAAA,SAAAC,OAAM,UAAU,OAAO;AAEnB,QAAI,UAAU,KAAK,UAAU,GAAG;AAC5B,aAAO;IACnB;AAMQ,QAAI,SAAS,WAAW,KAAK,QAAQ,QAAQ;AACzC,WAAK,UAAU;AACf,WAAK,OAAO;IACxB;AAEQJ,QAAM,aAAa,KAAK,QAAQ,QAAQ;AAExC,QAAI,OAAO,eAAe,YAAY,eAAe,OAAO;AACxDA,UAAM,WAAW,QAAQ;AACzB,eAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,QAAQ,KAAK;AAC1C,aAAK,QAAQ,CAAC,KAAK,WAAW,SAAS,CAAC;MACxD;AACY,WAAK,QAAQ;IACzB;AACQ,WAAO;EACX;AIpFJK,MAAM,IAAI,MAAM;AAChBA,MAAM,aAAa,KAAK,IAAI,KAAK,KAAK,IAAI,KAAK,EAAE,CAAC;AMTlDC,MAAMC,aAAW,KAAK,KAAK,IAAI,KAAK,EAAE;AEHtCC,MAAM,WAAW,KAAK,KAAK,IAAI,KAAK,EAAE;AAEtC,WAAS,uBAAuB,GAAG;AAC/BC,QAAIC,OAAM;AACVD,QAAI,MAAM;AAGV,aAAS,IAAI,GAAG,IAAI,IAAI,KAAK;AACzB,aAAQ,IAAI,KAAM,IAAI,IAAI;AAC1B,MAAAC,QAAO;IACf;AACI,WACI,KAAK,OAAO,MAAOA,OAAM,WAAY,KAAK,IAAK,CAAC,IAAI,IAAK,CAAC,KAAK,GAAG,IAClE;EAER;AAUK,MAAC,sBAAsB,CAAA;AAE5B,OAAS,IAAI,GAAG,KAAK,MAAM,KAAK,MAAM;AAClC,wBAAoB,KAAK,uBAAuB,CAAC,CAAC;EACtD;AAFS;;;AgB1BT,MAAM,YAAY,IAAI;;;ACqBf,WAAS,kBACd,IACA,IACA,IACA,IACQ;AACR,UAAM,KAAK,KAAK;AAChB,UAAM,KAAK,KAAK;AAChB,WAAO,KAAK,KAAK,KAAK,KAAK,KAAK,EAAE;EACpC;ACPO,WAASC,MAAK,QAAuC,OAAO,OAAe;AAChF,UAAM,WAAW,OAAO,SAAS,MAAM,IAAK;AAC5C,QAAI,SAAS,WAAW,EAAG,QAAO;AAClC,WAAU,KAAK,QAAQ;EACzB;AAWO,WAASC,QAAO,QAAuC,OAAO,OAAe;AAClF,UAAM,WAAW,OAAO,SAAS,MAAM,IAAK;AAC5C,QAAI,SAAS,WAAW,EAAG,QAAO;AAClC,WAAU,OAAO,QAAQ;EAC3B;AA4BO,WAAS,IAAI,QAAuC,OAAO,OAAe;AAC/E,UAAM,WAAW,OAAO,SAAS,MAAM,IAAK;AAC5C,QAAI,SAAS,WAAW,EAAG,QAAO;AAElC,UAAM,MAAS,OAAO,QAAQ;AAC9B,UAAM,aAAa,SAAS,IAAI,CAAA,MAAK,KAAK,IAAI,IAAI,GAAG,CAAC;AACtD,WAAU,OAAO,UAAU;EAC7B;AAkDO,WAAS,SAAS,QAAiD;AACxE,WAAO,OAAO;MAAO,CAAC,MACpB,MAAM,QAAQ,MAAM,UAAa,CAAC,OAAO,MAAM,CAAC;IAAA;EAEpD;AAQO,WAAS,KAAK,OAAyB;AAC5C,WAAO,UAAU,QAAQ,UAAU,UAAa,OAAO,MAAM,KAAK;EACpE;ACzGO,WAAS,IAAO,MAAyB;AAC9C,QAAI,KAAK,WAAW,GAAG;AACrB,aAAO,EAAE,SAAS,CAAA,GAAI,QAAQ,CAAA,EAAC;IACjC;AAEA,UAAM,UAAoB,CAAA;AAC1B,UAAM,SAAc,CAAA;AAEpB,QAAI,eAAe,KAAK,CAAC;AACzB,QAAI,gBAAgB;AAEpB,aAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACpC,YAAM,QAAQ,KAAK,CAAC;AAGpB,YAAM,UACJ,UAAU,gBACT,OAAO,MAAM,KAAK,KAAK,OAAO,MAAM,YAAuB;AAE9D,UAAI,SAAS;AACX;MACF,OAAO;AACL,gBAAQ,KAAK,aAAa;AAC1B,eAAO,KAAK,YAAa;AACzB,uBAAe;AACf,wBAAgB;MAClB;IACF;AAGA,YAAQ,KAAK,aAAa;AAC1B,WAAO,KAAK,YAAa;AAEzB,WAAO,EAAE,SAAS,OAAA;EACpB;AChCO,WAAS,UACd,MACA,GACA,IACA,UAAmC,CAAA,GAChB;AACnB,UAAM,EAAE,QAAQ,UAAU,QAAQ,OAAO,UAAU,KAAA,IAAS;AAE5D,QAAI,IAAI,GAAG;AACT,YAAM,IAAI,MAAM,4BAA4B;IAC9C;AAEA,QAAI,IAAI,KAAK,QAAQ;AACnB,UAAI,OAAO;AACT,eAAO,IAAI,MAAM,KAAK,MAAM,EAAE,KAAK,IAAI;MACzC;AACA,YAAM,IAAI,MAAM,yCAAyC;IAC3D;AAEA,UAAM,SAA4B,IAAI,MAAM,KAAK,MAAM;AAEvD,aAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AAEpC,UAAI,OAAe;AAEnB,cAAQ,OAAA;QACN,KAAK;AACH,kBAAQ;AACR,gBAAM,IAAI,IAAI;AACd;QACF,KAAK;AACH,kBAAQ,IAAI,IAAI;AAChB,gBAAM;AACN;QACF,KAAK;QACL;AACE,gBAAM,aAAa,KAAK,MAAM,IAAI,CAAC;AACnC,kBAAQ,IAAI;AACZ,gBAAM,IAAI;AAEV,cAAI,IAAI,MAAM,GAAG;AACf,kBAAM,QAAQ,IAAI;UACpB;AACA;MAAA;AAIJ,YAAM,cAAc,QAAQ,KAAK,OAAO,KAAK;AAE7C,UAAI,aAAa;AACf,YAAI,OAAO;AACT,iBAAO,CAAC,IAAI;AACZ;QACF,WAAW,SAAS;AAElB,kBAAQ,KAAK,IAAI,GAAG,KAAK;AACzB,gBAAM,KAAK,IAAI,KAAK,SAAS,GAAG,GAAG;QACrC,OAAO;AACL,iBAAO,CAAC,IAAI;AACZ;QACF;MACF;AAGA,YAAM,SAAmB,CAAA;AACzB,eAAS,IAAI,OAAO,KAAK,KAAK,KAAK;AACjC,cAAM,QAAQ,KAAK,CAAC;AACpB,YAAI,UAAU,QAAQ,UAAU,UAAa,CAAC,OAAO,MAAM,KAAK,GAAG;AACjE,iBAAO,KAAK,KAAK;QACnB;MACF;AAGA,UAAI,OAAO,WAAW,GAAG;AACvB,eAAO,CAAC,IAAI;MACd,OAAO;AACL,eAAO,CAAC,IAAI,GAAG,MAAM;MACvB;IACF;AAEA,WAAO;EACT;AAuDO,WAAS,WACd,MACA,GACA,QAAmB,UACnB,QAAQ,MACR,UAAU,OACS;AACnB,WAAO,UAAU,MAAM,GAAGC,SAAQ,EAAE,OAAO,OAAO,QAAA,CAAS;EAC7D;AAcO,WAAS,cACd,MACA,IAAI,GACe;AACnB,WAAO,UAAU,MAAM,GAAGC,OAAM;MAC9B,OAAO;MACP,OAAO;MACP,SAAS;IAAA,CACV;EACH;AC9GO,WAAS,kBACd,UACA,WACA,OAAO,KACD;AACN,UAAM,UAAU,SACb,IAAI,CAAA,MAAM,EAAwC,IAAI,CAAC,EACvD,OAAO,CAAC,MAAmB,KAAK,QAAQ,CAAC,OAAO,MAAM,CAAC,CAAC;AAE3D,QAAI,QAAQ,WAAW,GAAG;AACxB,cAAQ,KAAK,2CAA2C;AACxD;IACF;AAEA,UAAM,OAAO,KAAK,IAAI,GAAG,OAAO;AAEhC,QAAI,OAAO,WAAW;AACpB,cAAQ;QACN,uBAAuB,SAAS,sCAAsC,IAAI;MAAA;IAG9E;EACF;AChFO,WAAS,sBACd,MACA,QACA,QACmB;AAEnB,UAAM,SAA4B,KAAK,IAAI,CAAA,MAAM,MAAM,SAAY,OAAO,CAAE;AAG5E,UAAM,OAAO,SAAS,MAAM,MAAM;AAGlC,eAAW,OAAO,MAAM;AACtB,YAAM,EAAE,OAAO,KAAA,IAAS;AAGxB,YAAM,kBAAkB,QAAQ,UAAU;AAC1C,YAAM,iBAAiB,OAAO,SAAS,KAAK;AAE5C,UAAI,CAAC,mBAAmB,CAAC,gBAAgB;AAEvC;MACF;AAGA,YAAM,gBAA0B,CAAA;AAChC,eAAS,IAAI,QAAQ,QAAQ,IAAI,OAAO,KAAK;AAC3C,cAAM,QAAQ,KAAK,CAAC;AACpB,YAAI,SAAS,QAAQ,CAAC,OAAO,MAAM,KAAK,GAAG;AACzC,wBAAc,KAAK,KAAK;QAC1B;MACF;AAGA,YAAM,eAAyB,CAAA;AAC/B,eAAS,IAAI,OAAO,GAAG,KAAK,OAAO,QAAQ,KAAK;AAC9C,cAAM,QAAQ,KAAK,CAAC;AACpB,YAAI,SAAS,QAAQ,CAAC,OAAO,MAAM,KAAK,GAAG;AACzC,uBAAa,KAAK,KAAK;QACzB;MACF;AAGA,UAAI,cAAc,WAAW,KAAK,aAAa,WAAW,GAAG;AAE3D;MACF;AAEA,YAAM,iBAAiBC,QAAO,eAAe,KAAK;AAClD,YAAM,gBAAgBA,QAAO,cAAc,KAAK;AAEhD,UAAI,OAAO,MAAM,cAAc,KAAK,OAAO,MAAM,aAAa,GAAG;AAC/D;MACF;AAGA,YAAM,aAAa,iBAAiB,iBAAiB;AAErD,eAAS,IAAI,OAAO,KAAK,MAAM,KAAK;AAClC,eAAO,CAAC,IAAI;MACd;IACF;AAEA,WAAO;EACT;AASA,WAAS,SACP,MACA,QACO;AAEP,UAAMC,QAAO,KAAK;MAChB,CAAA,MAAK,MAAM,QAAQ,MAAM,UAAa,OAAO,MAAM,CAAC;IAAA;AAItD,UAAM,UAAU,IAAIA,KAAI;AAExB,UAAM,OAAc,CAAA;AACpB,QAAI,eAAe;AAEnB,aAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,QAAQ,KAAK;AAC/C,YAAM,SAAS,QAAQ,QAAQ,CAAC;AAChC,YAAM,QAAQ,QAAQ,OAAO,CAAC;AAG9B,UAAI,SAAS,UAAU,QAAQ;AAC7B,aAAK,KAAK;UACR,OAAO;UACP,MAAM,eAAe,SAAS;UAC9B;QAAA,CACD;MACH;AAEA,sBAAgB;IAClB;AAEA,WAAO;EACT;AC/HO,MAAM,4BAA8C;IACzD,UAAU;IACV,UAAU;IACV,UAAU;IACV,MAAM;IACN,MAAM;IACN,UAAU;EACZ;AA4BO,WAAS,eACd,SACA,SAAoC,CAAA,GACf;AACrB,UAAM;MACJ;MACA;MACA;MACA;MACA;MACA;IAAA,IACE,EAAE,GAAG,2BAA2B,GAAG,OAAA;AAEvC,QAAI,QAAQ,WAAW,GAAG;AACxB,YAAM,IAAI,MAAM,2BAA2B;IAC7C;AAGA,UAAM,aAAa,QAAQ,IAAI,CAAA,MAAK,EAAE,SAAS;AAC/C,QAAI;AAEJ,QAAI,QAAQ,SAAS,KAAK;AAExB,YAAM,iBAAiB,CAAA;AACvB,eAAS,IAAI,GAAG,IAAI,KAAK,IAAI,KAAK,WAAW,MAAM,GAAG,KAAK;AACzD,uBAAe,KAAK,WAAW,CAAC,IAAK,WAAW,IAAI,CAAC,CAAE;MACzD;AACA,kBAAYC,MAAK,gBAAgB,IAAI;IACvC,OAAO;AACL,YAAM,YAAY,CAAA;AAClB,eAAS,IAAI,GAAG,IAAI,WAAW,QAAQ,KAAK;AAC1C,kBAAU,KAAK,WAAW,CAAC,IAAK,WAAW,IAAI,CAAC,CAAE;MACpD;AACA,kBAAYA,MAAK,WAAW,IAAI;IAClC;AAGA,QAAI,WAAW,KAAK,CAAA,MAAK,IAAI,CAAC,GAAG;AAC/B,cAAQ,KAAK,sEAAsE;IACrF;AAEA,QAAI,YAAY,QAAQ,YAAY,KAAK;AACvC,cAAQ;QACN;MAAA;IAGJ;AAGA,UAAM,SAAS,KAAK,MAAM,WAAW,SAAS;AAC9C,UAAM,SAAS,KAAK,MAAM,WAAW,SAAS;AAC9C,UAAM,eAAe,KAAK,MAAM,WAAW,SAAS;AAGpD,UAAM,QAAQ,QAAQ,IAAI,CAAA,MAAM,EAAwC,IAAI,KAAK,IAAI;AACrF,UAAM,QAAQ,QAAQ,IAAI,CAAA,MAAM,EAAwC,IAAI,KAAK,IAAI;AAGrF,UAAM,gBAAgB,sBAAsB,OAAO,QAAQ,MAAM;AACjE,UAAM,gBAAgB,sBAAsB,OAAO,QAAQ,MAAM;AAGjE,QAAI;AACJ,QAAI;AAEJ,QAAI,UAAU;AACZ,kBAAY,cAAc,eAAe,YAAY;AACrD,kBAAY,cAAc,eAAe,YAAY;IACvD,OAAO;AAEL,kBAAY,cAAc,eAAe,YAAY;AACrD,kBAAY,cAAc,eAAe,YAAY;IACvD;AAGA,UAAM,YAAiC,QAAQ,IAAI,CAAC,GAAG,MAAM;AAE3D,YAAM,uBAAuB,IAAI;AAEjC,aAAO;QACL,WAAW,EAAE;QACb,GAAG,UAAU,CAAC,KAAK;QACnB,GAAG,UAAU,CAAC,KAAK;QACnB,cAAc,MAAM,CAAC,KAAK;QAC1B,cAAc,MAAM,CAAC,KAAK;QAC1B;QACA,QAAQ;MAAA;IAEZ,CAAC;AAED,WAAO;EACT;AIrGO,WAAS,yBACd,YACA,UACA,GACA,GACA,YACA,YAAY,IACF;AAEV,UAAM,WAAqB,CAAA;AAC3B,UAAM,WAAqB,CAAA;AAC3B,QAAI,eAAe;AAEnB,aAAS,IAAI,YAAY,KAAK,UAAU,KAAK;AAC3C,YAAM,OAAO,EAAE,CAAC;AAChB,YAAM,OAAO,EAAE,CAAC;AAEhB,UAAI,KAAK,IAAI,KAAK,KAAK,IAAI,GAAG;AAC5B;MACF,OAAO;AACL,iBAAS,KAAK,IAAc;AAC5B,iBAAS,KAAK,IAAc;MAC9B;IACF;AAGA,UAAM,YAAYC,MAAK,UAAU,KAAK;AACtC,UAAM,YAAYA,MAAK,UAAU,KAAK;AAGtC,UAAM,sBAAgC,CAAA;AACtC,aAAS,IAAI,GAAG,IAAI,SAAS,QAAQ,KAAK;AACxC,YAAM,KAAK,SAAS,CAAC,IAAK;AAC1B,YAAM,KAAK,SAAS,CAAC,IAAK;AAC1B,0BAAoB,KAAK,KAAK,KAAK,KAAK,KAAK,KAAK,EAAE,CAAC;IACvD;AAEA,UAAM,gBACJ,oBAAoB,SAAS,IACzB,KAAK;MACH,oBAAoB,OAAO,CAACC,MAAK,MAAMA,OAAM,IAAI,GAAG,CAAC,IACnD,oBAAoB;IAAA,IACpB,YACJ;AAGN,UAAM,0BAAoC,CAAA;AAC1C,aAAS,IAAI,GAAG,IAAI,SAAS,QAAQ,KAAK;AACxC,YAAM,KAAK,SAAS,CAAC,IAAK,SAAS,IAAI,CAAC;AACxC,YAAM,KAAK,SAAS,CAAC,IAAK,SAAS,IAAI,CAAC;AACxC,8BAAwB,KAAK,KAAK,KAAK,KAAK,KAAK,KAAK,EAAE,CAAC;IAC3D;AAEA,UAAM,OACJ,wBAAwB,SAAS,IAC7B,KAAK;MACH,wBAAwB,OAAO,CAACA,MAAK,MAAMA,OAAM,IAAI,GAAG,CAAC,IACvD,wBAAwB;IAAA,IACxB,YACJ;AAGN,UAAM,QAAQ,WAAW,UAAU;AACnC,UAAM,SAAS,WAAW,QAAQ;AAClC,UAAM,WAAW,SAAS;AAG1B,UAAM,eAAe,WAAW,aAAa;AAC7C,UAAM,iBAAiB,eAAe;AAEtC,WAAO;MACL,GAAG;MACH,GAAG;MACH;MACA;MACA;MACA,MAAM,OAAO,MAAM,IAAI,IAAI,IAAI;MAC/B,eAAe,OAAO,MAAM,aAAa,IAAI,IAAI;MACjD;MACA,WAAW;MACX,UAAU;IAAA;EAEd;AA+BO,WAAS,uBACd,WACA,UACA,oBAAoB,KACpB,cAAc,IACd,YAAY,IACZ,OAAO,QACP,OAAO,QACK;AACZ,QAAI,UAAU,UAAU,GAAG;AACzB,aAAO;IACT;AAGA,UAAM,SAAS,CAAC,GAAG,SAAS;AAE5B,YAAQ,IAAI,4BAA4B;AAExC,QAAI,IAAI;AACR,WAAO,IAAI,OAAO,SAAS,GAAG;AAC5B,YAAM,UAAU,OAAO,CAAC;AACxB,YAAM,OAAO,OAAO,IAAI,CAAC;AAGzB,YAAM,WACJ,kBAAkB,QAAQ,GAAG,QAAQ,GAAG,KAAK,GAAG,KAAK,CAAC,IAAI;AAG5D,YAAM,cAAc,KAAK,QAAQ,QAAQ;AAGzC,UAAI,WAAW,qBAAqB,cAAc,aAAa;AAE7D,cAAM,aAAa,QAAQ;AAC3B,cAAM,WAAW,KAAK;AAGtB,cAAM,QAAQ,SAAS,IAAI,CAAA,MAAM,EAAwC,IAAI,KAAK,IAAI;AACtF,cAAM,QAAQ,SAAS,IAAI,CAAA,MAAM,EAAwC,IAAI,KAAK,IAAI;AACtF,cAAM,aAAa,SAAS,IAAI,CAAA,MAAK,EAAE,SAAS;AAEhD,cAAM,iBAAiB;UACrB;UACA;UACA;UACA;UACA;UACA;QAAA;AAIF,YAAI,QAAQ,WAAW;AACrB,yBAAe,YAAY,QAAQ;QACrC;AACA,YAAI,QAAQ,WAAW;AACrB,yBAAe,YAAY,QAAQ;QACrC;AAGA,eAAO,CAAC,IAAI;AACZ,eAAO,OAAO,IAAI,GAAG,CAAC;MAGxB,OAAO;AACL;MACF;IACF;AAEA,WAAO;EACT;AA2BO,WAAS,qBACd,YACA,UACA,GACA,GACA,WACyC;AAEzC,UAAM,WAAqB,CAAA;AAC3B,UAAM,WAAqB,CAAA;AAE3B,aAAS,IAAI,YAAY,KAAK,UAAU,KAAK;AAC3C,YAAM,OAAO,EAAE,CAAC;AAChB,YAAM,OAAO,EAAE,CAAC;AAChB,UAAI,CAAC,KAAK,IAAI,KAAK,CAAC,KAAK,IAAI,GAAG;AAC9B,iBAAS,KAAK,IAAc;AAC5B,iBAAS,KAAK,IAAc;MAC9B;IACF;AAEA,QAAI,SAAS,WAAW,GAAG;AAEzB,aAAO,EAAE,WAAW,YAAY,UAAU,SAAA;IAC5C;AAEA,UAAM,YAAYD,MAAK,UAAU,KAAK;AACtC,UAAM,YAAYA,MAAK,UAAU,KAAK;AAGtC,UAAM,sBAAyC,CAAA;AAC/C,aAAS,IAAI,YAAY,KAAK,UAAU,KAAK;AAC3C,YAAM,OAAO,EAAE,CAAC;AAChB,YAAM,OAAO,EAAE,CAAC;AAEhB,UAAI,KAAK,IAAI,KAAK,KAAK,IAAI,GAAG;AAC5B,4BAAoB,KAAK,IAAI;MAC/B,OAAO;AACL,cAAM,KAAM,OAAkB;AAC9B,cAAM,KAAM,OAAkB;AAE9B,cAAM,QAAQ,KAAK,KAAK,KAAK,EAAE,IAAI,KAAK,KAAK,KAAK,EAAE,KAAK;AACzD,4BAAoB,KAAK,IAAI;MAC/B;IACF;AAEA,QAAI,WAAW;AACf,QAAI,SAAS;AAEb,QAAI,cAAc,UAAa,CAAC,OAAO,MAAM,SAAS,GAAG;AAEvD,YAAM,iBAAiB,oBAAoB;QACzC,CAAA,MAAK,MAAM;MAAA;AAGb,UAAI,eAAe,SAAS,GAAG;AAC7B,cAAM,aAAaE,QAAO,gBAAgB,KAAK;AAC/C,cAAM,UAAU,IAAI,gBAAgB,KAAK;AACzC,cAAM,aAAa,aAAa,YAAY;AAG5C,YAAI,aAAa;AACjB,iBAAS,IAAI,GAAG,IAAI,oBAAoB,UAAU,CAAC,YAAY,KAAK;AAClE,gBAAM,OAAO,oBAAoB,CAAC;AAClC,gBAAM,cAAc,aAAa;AAEjC,cAAI,SAAS,QAAQ,QAAS,YAAY;AACxC,uBAAW;AACX,yBAAa;UACf,WAAW,eAAe,UAAU;AAClC,yBAAa;UACf;QACF;AAGA,YAAI,WAAW;AACf,iBAAS,IAAI,oBAAoB,SAAS,GAAG,KAAK,KAAK,CAAC,UAAU,KAAK;AACrE,gBAAM,OAAO,oBAAoB,CAAC;AAClC,gBAAM,cAAc,aAAa;AAEjC,cAAI,SAAS,QAAQ,QAAS,YAAY;AACxC,qBAAS;AACT,uBAAW;UACb,WAAW,eAAe,UAAU;AAClC,uBAAW;UACb;QACF;MACF;IACF,OAAO;AAGL,eAAS,IAAI,YAAY,KAAK,UAAU,KAAK;AAC3C,YAAI,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC,CAAC,GAAG;AAC9B,qBAAW;AACX;QACF;MACF;AAGA,eAAS,IAAI,UAAU,KAAK,YAAY,KAAK;AAC3C,YAAI,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC,CAAC,GAAG;AAC9B,mBAAS;AACT;QACF;MACF;IACF;AAEA,WAAO,EAAE,WAAW,UAAU,UAAU,OAAA;EAC1C;AA8BO,WAAS,cACd,WACA,UACA,OAAO,QACP,OAAO,QACP,YAAY,GACZ,YAAY,IACA;AAEZ,UAAM,QAAQ,SAAS,IAAI,CAAA,MAAM,EAAwC,IAAI,KAAK,IAAI;AACtF,UAAM,QAAQ,SAAS,IAAI,CAAA,MAAM,EAAwC,IAAI,KAAK,IAAI;AACtF,UAAM,aAAa,SAAS,IAAI,CAAA,MAAK,EAAE,SAAS;AAEhD,QAAI,MAAM,WAAW,KAAK,MAAM,WAAW,GAAG;AAC5C,cAAQ;QACN;MAAA;AAGF,aAAO;IACT;AAEA,UAAM,mBAA+B,CAAA;AAErC,eAAW,YAAY,WAAW;AAEhC,YAAM,WAAW;QACf,SAAS;QACT,SAAS;QACT;QACA;QACA;MAAA;AAIF,YAAM,kBAAkB;QACtB,SAAS;QACT,SAAS;QACT;QACA;QACA;QACA;MAAA;AAIF,sBAAgB,YAAY,SAAS,aAAa;AAClD,sBAAgB,YAAY,SAAS,aAAa;AAElD,uBAAiB,KAAK,eAAe;IACvC;AAEA,WAAO;EACT;AC7ZO,MAAM,qBAAgC;IAC3C,qBAAqB;;IACrB,aAAa;;IACb,WAAW;;IACX,MAAM;IACN,MAAM;IACN,mBAAmB;;IACnB,kBAAkB;;IAClB,yBAAyB;;EAC3B;AAyCO,WAAS,aACd,UACA,SAA6B,CAAA,GACZ;AACjB,UAAM;MACJ;MACA;MACA;MACA;MACA;MACA;MACA;MACA;IAAA,IACE,EAAE,GAAG,oBAAoB,GAAG,OAAA;AAEhC,QAAI,SAAS,SAAS,GAAG;AACvB,aAAO;QACL,WAAW,CAAA;QACX,cAAc,CAAA;MAAC;IAEnB;AAGA,sBAAkB,UAAU,WAAW,IAAI;AAG3C,UAAM,QAAQ,SAAS,IAAI,CAAA,MAAM,EAAwC,IAAI,CAAC;AAC9E,UAAM,QAAQ,SAAS,IAAI,CAAA,MAAM,EAAwC,IAAI,CAAC;AAC9E,UAAM,aAAa,SAAS,IAAI,CAAA,MAAK,EAAE,SAAS;AAGhD,UAAM,YAAwB,CAAA;AAC9B,UAAM,eAAmC,SAAS,IAAI,CAAA,OAAM;MAC1D,WAAW,EAAE;MACb,MAAO,EAAwC,IAAI;MACnD,MAAO,EAAwC,IAAI;MACnD,GAAG;MACH,GAAG;IAAA,EACH;AAGF,QAAI,cAAc;AAClB,QAAI,oBAAoB;AACxB,QAAI,yBAAyB;AAC7B,QAAI,qBAAqB;AACzB,QAAI,qBAAqB;AAEzB,WAAO,cAAc,SAAS,QAAQ;AACpC,UAAI,CAAC,mBAAmB;AAItB,cAAM,KAAK,MAAM,cAAc,CAAC;AAChC,cAAM,KAAK,MAAM,cAAc,CAAC;AAChC,cAAM,KAAK,MAAM,WAAW;AAC5B,cAAM,KAAK,MAAM,WAAW;AAE5B,YACE,MAAM,QACN,MAAM,QACN,MAAM,QACN,MAAM,QACN,CAAC,OAAO,MAAM,EAAE,KAChB,CAAC,OAAO,MAAM,EAAE,KAChB,CAAC,OAAO,MAAM,EAAE,KAChB,CAAC,OAAO,MAAM,EAAE,GAChB;AACA,gBAAM,WAAW,KAAK,MAAM,KAAK,OAAO,KAAK,KAAK,OAAO,CAAC;AAE1D,cAAI,YAAY,sBAAsB,WAAW;AAE/C,gCAAoB;AACpB,qCAAyB,cAAc;AAGvC,kCAAsB,KAAK,MAAM;AACjC,kCAAsB,KAAK,MAAM;UACnC;QACF;MACF,OAAO;AAIL,cAAM,QAAQ,MAAM,WAAW;AAC/B,cAAM,QAAQ,MAAM,WAAW;AAE/B,YAAI,SAAS,QAAQ,SAAS,QAAQ,CAAC,OAAO,MAAM,KAAK,KAAK,CAAC,OAAO,MAAM,KAAK,GAAG;AAClF,gBAAM,qBAAqB,KAAK;aAC7B,QAAQ,uBAAuB,KAAK,QAAQ,uBAAuB;UAAA;AAGtE,cAAI,sBAAsB,sBAAsB,WAAW;AAGzD,gBAAI,OAAO;AACX,gBAAI,OAAO;AACX,gBAAI,QAAQ;AAEZ,qBAAS,IAAI,wBAAwB,KAAK,aAAa,KAAK;AAC1D,oBAAM,IAAI,MAAM,CAAC;AACjB,oBAAM,IAAI,MAAM,CAAC;AACjB,kBAAI,KAAK,QAAQ,KAAK,QAAQ,CAAC,OAAO,MAAM,CAAC,KAAK,CAAC,OAAO,MAAM,CAAC,GAAG;AAClE,wBAAQ;AACR,wBAAQ;AACR;cACF;YACF;AAEA,gBAAI,QAAQ,GAAG;AACb,mCAAqB,OAAO;AAC5B,mCAAqB,OAAO;YAC9B;UACF,OAAO;AAGL,kBAAM,eAAe;cACnB;cACA,cAAc;;cACd;cACA;cACA;cACA;YAAA;AAGF,sBAAU,KAAK,YAAY;AAG3B,gCAAoB;AACpB,qCAAyB;AACzB,iCAAqB;AACrB,iCAAqB;UACvB;QACF,OAAO;AAGL,cAAI,yBAAyB,cAAc,GAAG;AAC5C,kBAAM,eAAe;cACnB;cACA,cAAc;cACd;cACA;cACA;cACA;YAAA;AAGF,sBAAU,KAAK,YAAY;UAC7B;AAGA,8BAAoB;AACpB,mCAAyB;AACzB,+BAAqB;AACrB,+BAAqB;QACvB;MACF;AAEA;IACF;AAGA,QAAI,qBAAqB,yBAAyB,SAAS,SAAS,GAAG;AACrE,YAAM,eAAe;QACnB;QACA,SAAS,SAAS;QAClB;QACA;QACA;QACA;MAAA;AAGF,gBAAU,KAAK,YAAY;IAC7B;AAGA,QAAI,kBAAkB;AACtB,QAAI,oBAAoB,GAAG;AACzB,wBAAkB;QAChB;QACA;QACA;QACA;QACA;QACA;QACA;MAAA;IAEJ;AAGA,UAAM,oBAAoB,gBAAgB;MACxC,CAAA,MAAK,EAAE,WAAW,eAAe,EAAE,iBAAiB;IAAA;AAItD,UAAM,iBAAiB,kBAAkB,IAAI,CAAA,OAAM;MACjD,GAAG;MACH,WAAW;MACX,WAAW,GAAG,KAAK,MAAM,mBAAmB,CAAC;IAAA,EAC7C;AAGF,eAAW,YAAY,gBAAgB;AACrC,eAAS,IAAI,SAAS,WAAW,KAAK,SAAS,UAAU,KAAK;AAC5D,qBAAa,CAAC,EAAG,IAAI,SAAS;AAC9B,qBAAa,CAAC,EAAG,IAAI,SAAS;MAChC;IACF;AAEA,WAAO;MACL,WAAW;MACX;IAAA;EAEJ;AC/PO,MAAM,qBAAgC;IAC3C,mBAAmB;;IACnB,kBAAkB;;IAClB,oBAAoB;;IACpB,qBAAqB;;IACrB,qBAAqB;;IACrB,WAAW;;IACX,MAAM;IACN,MAAM;IACN,mBAAmB;;IACnB,kBAAkB;;IAClB,yBAAyB;;IACzB,eAAe;IACf,yBAAyB;IACzB,sBAAsB;EACxB;AAyCO,WAAS,aACd,UACA,SAA6B,CAAA,GACZ;AACjB,UAAM;MACJ;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA,eAAe;MACf;MACA;IAAA,IACE,EAAE,GAAG,oBAAoB,GAAG,OAAA;AAEhC,QAAI,SAAS,SAAS,GAAG;AACvB,aAAO;QACL,WAAW,CAAA;QACX,cAAc,CAAA;QACd,UAAU,CAAA;QACV,UAAU,CAAA;MAAC;IAEf;AAGA,sBAAkB,UAAU,WAAW,IAAI;AAG3C,UAAM,QAAQ,SAAS,IAAI,CAAA,MAAM,EAAwC,IAAI,CAAC;AAC9E,UAAM,QAAQ,SAAS,IAAI,CAAA,MAAM,EAAwC,IAAI,CAAC;AAC9E,UAAM,aAAa,SAAS,IAAI,CAAA,MAAK,EAAE,SAAS;AAGhD,UAAM,YAAY,CAAA;AAClB,aAAS,IAAI,GAAG,IAAI,WAAW,QAAQ,KAAK;AAC1C,gBAAU,KAAK,WAAW,CAAC,IAAK,WAAW,IAAI,CAAC,CAAE;IACpD;AACA,UAAM,YAAYF,MAAK,WAAW,IAAI;AAEtC,QAAI,YAAY,MAAM;AACpB,cAAQ;QACN;MAAA;IAGJ;AAGA,YAAQ,IAAI,sBAAsB;AAGlC,UAAM,WAAqB,CAAC,GAAG;AAE/B,aAAS,IAAI,GAAG,IAAI,SAAS,QAAQ,KAAK;AACxC,YAAM,KAAK,MAAM,IAAI,CAAC;AACtB,YAAM,KAAK,MAAM,IAAI,CAAC;AACtB,YAAM,KAAK,MAAM,CAAC;AAClB,YAAM,KAAK,MAAM,CAAC;AAElB,UACE,MAAM,QAAQ,MAAM,QAAQ,MAAM,QAAQ,MAAM,QAChD,OAAO,MAAM,EAAE,KAAK,OAAO,MAAM,EAAE,KAAK,OAAO,MAAM,EAAE,KAAK,OAAO,MAAM,EAAE,GAC3E;AAEA,iBAAS,KAAK,GAAG;AACjB;MACF;AAEA,YAAM,KAAK,KAAK;AAChB,YAAM,KAAK,KAAK;AAChB,YAAM,OAAO,KAAK,KAAK,KAAK,KAAK,KAAK,EAAE;AAGxC,YAAM,UAAU,OAAO;AAIvB,YAAM,MAAO,UAAU,YAAa;AACpC,eAAS,KAAK,GAAG;IACnB;AAGA,UAAM,uBAAuB,KAAK,MAAM,mBAAmB,SAAS;AACpE,UAAM,mBAAmB;MACvB;MACA;MACA;MACA;MACA;IAAA;AAIF,UAAM,iBAAiB,iBAAiB;MAAI,CAAA,MAC1C,MAAM,QAAQ,CAAC,OAAO,MAAM,CAAC,IAAI,IAAI,oBAAoB;IAAA;AAI3D,UAAM,UAAU,IAAI,cAAc;AAElC,UAAM,gBAA0B,CAAA;AAChC,UAAM,cAAwB,CAAA;AAE9B,QAAI,eAAe;AACnB,aAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,QAAQ,KAAK;AAC/C,YAAM,SAAS,QAAQ,QAAQ,CAAC;AAChC,YAAM,QAAQ,QAAQ,OAAO,CAAC;AAE9B,UAAI,UAAU,MAAM;AAClB,sBAAc,KAAK,YAAY;AAC/B,oBAAY,KAAK,eAAe,SAAS,CAAC;MAC5C;AAEA,sBAAgB;IAClB;AAGA,UAAM,WAAsB,CAAA;AAC5B,UAAM,mBAA+B,CAAA;AAErC,aAAS,IAAI,GAAG,IAAI,cAAc,QAAQ,KAAK;AAC7C,YAAM,QAAQ,cAAc,CAAC;AAC7B,YAAM,MAAM,YAAY,CAAC;AAEzB,YAAM,SAAS,MAAM,KAAK;AAC1B,YAAM,SAAS,MAAM,KAAK;AAC1B,YAAM,UAAU,MAAM,GAAG;AACzB,YAAM,UAAU,MAAM,GAAG;AAEzB,UACE,UAAU,QAAQ,UAAU,QAAQ,WAAW,QAAQ,WAAW,QAClE,OAAO,MAAM,MAAM,KAAK,OAAO,MAAM,MAAM,KAC3C,OAAO,MAAM,OAAO,KAAK,OAAO,MAAM,OAAO,GAC7C;AACA;MACF;AAGA,YAAM,YACJ,KAAK,MAAM,UAAU,WAAW,KAAK,UAAU,WAAW,CAAC,IAAI;AAGjE,YAAM,oBAAoB,iBACvB,MAAM,OAAO,MAAM,CAAC,EACpB,OAAO,CAAA,MAAK,MAAM,QAAQ,CAAC,OAAO,MAAM,CAAC,CAAC;AAE7C,YAAM,eACJ,kBAAkB,SAAS,IAAI,KAAK,IAAI,GAAG,iBAAiB,IAAI;AAGlE,YAAM,WAAW,MAAM,MAAM,OAAO,MAAM,CAAC;AAC3C,YAAM,eAAe,SAAS,OAAO,CAAA,MAAK,KAAK,QAAQ,OAAO,MAAM,CAAC,CAAC,EAAE;AACxE,YAAM,iBAAiB,eAAe,SAAS;AAE/C,YAAM,UAAmB;QACvB,OAAO,WAAW,KAAK;QACvB;QACA;QACA,QAAQ,WAAW,GAAG;QACtB;QACA;QACA,UAAU,WAAW,GAAG,IAAK,WAAW,KAAK;QAC7C;QACA;QACA;MAAA;AAGF,eAAS,KAAK,OAAO;AAErB,UAAI,sBAAsB;AACxB,yBAAiB,KAAK,iBAAiB;MACzC;IACF;AAGA,UAAM,mBAAmB,SAAS;MAChC,CAAA,MAAK,EAAE,YAAY,sBAAsB,EAAE,aAAa;IAAA;AAI1D,QAAI,sBAAsB;AACxB,uBAAiB,QAAQ,CAAC,GAAG,MAAM;AACjC,UAAE,kBAAkB,iBAAiB,CAAC;MACxC,CAAC;IACH;AAGA,YAAQ,IAAI,uBAAuB;AAEnC,UAAM,YAAwB,CAAA;AAC9B,UAAM,iBAAiB;AAGvB,QAAI,wBAAwB;AAC5B,QAAI,eAAe,UAAU,cAAc,QAAQ;AACjD,8BAAwB,CAAC,GAAG,eAAe,SAAS,SAAS,CAAC;IAChE;AAEA,aAAS,IAAI,GAAG,IAAI,eAAe,QAAQ,KAAK;AAC9C,YAAM,WAAW,eAAe,CAAC;AACjC,YAAM,SAAS,sBAAsB,IAAI,CAAC,IAAK;AAE/C,UAAI,UAAU,SAAU;AAExB,YAAM,eAAe;QACnB;QACA;QACA;QACA;QACA;QACA;MAAA;AAGF,gBAAU,KAAK,YAAY;IAC7B;AAGA,UAAM,eAAmC,SAAS,IAAI,CAAA,OAAM;MAC1D,WAAW,EAAE;MACb,MAAO,EAAwC,IAAI;MACnD,MAAO,EAAwC,IAAI;MACnD,GAAG;MACH,GAAG;IAAA,EACH;AAEF,QAAI,qBAAqB;AAEzB,QAAI,qBAAqB;AACvB,2BAAqB;QACnB;QACA;QACA;QACA;QACA;QACA;MAAA;IAEJ;AAGA,QAAI,oBAAoB,GAAG;AACzB,2BAAqB;QACnB;QACA;QACA;QACA;QACA;QACA;QACA;MAAA;IAEJ;AAGA,UAAM,iBAAiB,mBACpB;MACC,CAAA,MAAK,EAAE,YAAY,uBAAuB,EAAE,iBAAiB;IAAA,EAE9D,IAAI,CAAA,OAAM;MACT,GAAG;MACH,WAAW;MACX,WAAW,GAAG,KAAK,MAAM,iBAAiB,CAAC;IAAA,EAC3C;AAGJ,eAAW,YAAY,gBAAgB;AACrC,eAAS,IAAI,SAAS,WAAW,KAAK,SAAS,UAAU,KAAK;AAC5D,qBAAa,CAAC,EAAG,IAAI,SAAS;AAC9B,qBAAa,CAAC,EAAG,IAAI,SAAS;MAChC;IACF;AAGA,UAAM,iBAAiC,WAAW,IAAI,CAAC,GAAG,OAAO;MAC/D,WAAW;MACX,UAAU,iBAAiB,CAAC,KAAK;IAAA,EACjC;AAEF,WAAO;MACL,WAAW;MACX,UAAU;MACV;MACA,UAAU;IAAA;EAEd;;;AIpUA,MAAM,4BAA4B;AAKlC,WAAS,WAAW,QAAuB,WAA4C;AACrF,QAAI;AAEF,YAAM,iBAAiB,OAAO,OAAO,SAAS,CAAC,EAAE,YAAY,OAAO,CAAC,EAAE;AACvE,YAAM,eAAe,OAAO,UAAU,iBAAiB;AAGvD,YAAM,WAAW,eAAe,KAAK,KAAK,KAAK,IAAI,GAAG,KAAK,MAAM,MAAO,YAAY,CAAC;AAErF,YAAM,YAAY,eAAe,QAAQ;AAAA,QACvC,UAAU;AAAA,QACV,UAAU;AAAA,QACV;AAAA;AAAA,MACF,CAAC;AAED,YAAM,SAAS,aAAa,WAAW;AAAA,QACrC,mBAAmB;AAAA;AAAA,QACnB,qBAAqB;AAAA;AAAA,QACrB,oBAAoB;AAAA,QACpB,qBAAqB;AAAA,QACrB;AAAA,QACA,sBAAsB;AAAA,MACxB,CAAC;AAGD,UAAI,OAAO,UAAU,SAAS,GAAG;AAC/B,cAAM,iBAAiB,OAAO,UAAU,OAAO,UAAU,SAAS,CAAC;AAGnE,cAAM,kBAAkB,eAAe,QAAQ,eAAe;AAC9D,cAAM,cAAc,OAAO,OAAO,SAAS,CAAC,EAAE;AAE9C,YAAI,mBAAmB,cAAc,KAAK;AACxC,iBAAO;AAAA,YACL,WAAW;AAAA,YACX,GAAG,eAAe;AAAA,YAClB,GAAG,eAAe;AAAA,YAClB,UAAU,eAAe;AAAA,YACzB,WAAW,eAAe;AAAA,UAC5B;AAAA,QACF;AAAA,MACF;AAEA,aAAO;AAAA,IACT,SAAS,OAAO;AACd,cAAQ,KAAK,oCAAoC,KAAK;AACtD,aAAO;AAAA,IACT;AAAA,EACF;AAKA,WAAS,WAAW,QAAuB,WAA4C;AACrF,QAAI;AAEF,YAAM,iBAAiB,OAAO,OAAO,SAAS,CAAC,EAAE,YAAY,OAAO,CAAC,EAAE;AACvE,YAAM,eAAe,OAAO,UAAU,iBAAiB;AAGvD,YAAM,WAAW,eAAe,KAAK,KAAK,KAAK,IAAI,GAAG,KAAK,MAAM,MAAO,YAAY,CAAC;AAErF,YAAM,YAAY,eAAe,QAAQ;AAAA,QACvC,UAAU;AAAA,QACV,UAAU;AAAA,QACV;AAAA;AAAA,MACF,CAAC;AAED,YAAM,SAAS,aAAa,WAAW;AAAA,QACrC,qBAAqB;AAAA;AAAA,QACrB,aAAa;AAAA;AAAA,QACb;AAAA,MACF,CAAC;AAGD,UAAI,OAAO,UAAU,SAAS,GAAG;AAC/B,cAAM,iBAAiB,OAAO,UAAU,OAAO,UAAU,SAAS,CAAC;AAGnE,cAAM,kBAAkB,eAAe,QAAQ,eAAe;AAC9D,cAAM,cAAc,OAAO,OAAO,SAAS,CAAC,EAAE;AAE9C,YAAI,mBAAmB,cAAc,KAAK;AACxC,iBAAO;AAAA,YACL,WAAW;AAAA,YACX,GAAG,eAAe;AAAA,YAClB,GAAG,eAAe;AAAA,YAClB,UAAU,eAAe;AAAA,YACzB,WAAW,eAAe;AAAA,UAC5B;AAAA,QACF;AAAA,MACF;AAEA,aAAO;AAAA,IACT,SAAS,OAAO;AACd,cAAQ,KAAK,oCAAoC,KAAK;AACtD,aAAO;AAAA,IACT;AAAA,EACF;AAKA,OAAK,YAAY,CAAC,UAA4C;AAC5D,UAAM,EAAE,MAAM,QAAQ,WAAW,WAAW,UAAU,IAAI,MAAM;AAEhE,QAAI;AACF,cAAQ,MAAM;AAAA,QACZ,KAAK,WAAW;AACd,cAAI,CAAC,UAAU,OAAO,SAAS,2BAA2B;AAExD,kBAAMG,YAAgC;AAAA,cACpC,MAAM;AAAA,cACN,aAAa;AAAA,cACb,aAAa;AAAA,YACf;AACA,iBAAK,YAAYA,SAAQ;AACzB;AAAA,UACF;AAGA,gBAAM,iBAAiB,OAAO,OAAO,SAAS,CAAC,EAAE,YAAY,OAAO,CAAC,EAAE;AACvE,cAAI,iBAAiB,KAAK;AAExB,kBAAMA,YAAgC;AAAA,cACpC,MAAM;AAAA,cACN,aAAa;AAAA,cACb,aAAa;AAAA,YACf;AACA,iBAAK,YAAYA,SAAQ;AACzB;AAAA,UACF;AAGA,gBAAM,cAAc,YAAY,WAAW,QAAQ,aAAa,EAAE,IAAI;AACtE,gBAAM,cAAc,YAAY,WAAW,QAAQ,aAAa,EAAE,IAAI;AAGtE,gBAAM,WAAgC;AAAA,YACpC,MAAM;AAAA,YACN;AAAA,YACA;AAAA,UACF;AACA,eAAK,YAAY,QAAQ;AACzB;AAAA,QACF;AAAA,QAEA,KAAK,SAAS;AAEZ,gBAAM,WAAgC;AAAA,YACpC,MAAM;AAAA,UACR;AACA,eAAK,YAAY,QAAQ;AACzB;AAAA,QACF;AAAA,QAEA;AACE,kBAAQ,KAAK,yBAAyB,IAAI;AAAA,MAC9C;AAAA,IACF,SAAS,OAAO;AAEd,YAAM,WAAgC;AAAA,QACpC,MAAM;AAAA,QACN,OAAO,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,MAC9D;AACA,WAAK,YAAY,QAAQ;AAAA,IAC3B;AAAA,EACF;AAGA,MAAM,eAAoC;AAAA,IACxC,MAAM;AAAA,EACR;AACA,OAAK,YAAY,YAAY;",
  "names": ["let", "sum", "const", "let", "BayesianClassifier", "const", "let", "PerceptronModel", "score", "train", "const", "const", "SQRT_2PI", "const", "let", "sum", "mean", "median", "median", "mean", "median", "isNA", "mean", "mean", "sum", "median", "response"]
}
